{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json, re, torch, time, math, random, os\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from torch.utils.data import TensorDataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Hyperparameters\n",
    "EMB_DIM = 400\n",
    "HIDDEN_DIM = 512\n",
    "BATCH_SIZE = 64\n",
    "N_LAYERS = 2\n",
    "LR = 0.0004\n",
    "RNN_EPOCHS = 50\n",
    "TRUNCATE_LENGTH = 20\n",
    "KERNEL_SIZE = 5\n",
    "# Define device for computation\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of valid Cornell pairs: 1500\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Paths to Cornell dataset files\n",
    "lines_path = \"movie_lines.txt\"\n",
    "conversations_path = \"movie_conversations.txt\"\n",
    "intents_path = \"intents.json\"\n",
    "\n",
    "# Preprocess a sentence: lowercase and remove unwanted characters\n",
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip()\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", sentence)\n",
    "    return sentence\n",
    "\n",
    "def preprocess_cornell(lines_path, conversations_path):\n",
    "    # Load lines and map them to their IDs\n",
    "    id2line = {}\n",
    "    with open(lines_path, encoding='utf-8', errors='ignore') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split(\" +++$+++ \")\n",
    "            if len(parts) == 5:\n",
    "                id2line[parts[0]] = parts[4]\n",
    "\n",
    "    # Load conversations and extract pairs\n",
    "    pairs = []\n",
    "    with open(conversations_path, encoding='utf-8', errors='ignore') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split(\" +++$+++ \")\n",
    "            if len(parts) == 4:\n",
    "                conv_ids = eval(parts[3])  # List of dialog IDs\n",
    "                for i in range(len(conv_ids) - 1):\n",
    "                    # Check if both dialog IDs exist in id2line\n",
    "                    if conv_ids[i] in id2line and conv_ids[i + 1] in id2line:\n",
    "                        input_line = id2line[conv_ids[i]]\n",
    "                        target_line = id2line[conv_ids[i + 1]]\n",
    "                        pairs.append((preprocess_sentence(input_line), preprocess_sentence(target_line)))\n",
    "    return pairs\n",
    "\n",
    "\n",
    "cornell_pairs = preprocess_cornell(lines_path, conversations_path)\n",
    "sampled_cornell_pairs = cornell_pairs[:1500] \n",
    "print(f\"Number of valid Cornell pairs: {len(sampled_cornell_pairs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total combined pairs: 2028\n"
     ]
    }
   ],
   "source": [
    "# Load intents.json\n",
    "with open(intents_path, \"r\") as file:\n",
    "    intents = json.load(file)\n",
    "\n",
    "# Combine intents.json data with Cornell pairs\n",
    "combined_pairs = []\n",
    "patterns, labels = [], []\n",
    "for intent in intents['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        for response in intent['responses']:\n",
    "            combined_pairs.append((preprocess_sentence(pattern), preprocess_sentence(response)))\n",
    "            patterns.append(preprocess_sentence(pattern))\n",
    "            labels.append(intent['tag'])\n",
    "combined_pairs.extend(sampled_cornell_pairs)\n",
    "print(f\"Total combined pairs: {len(combined_pairs)}\")\n",
    "\n",
    "# Build label mapping for intent classification\n",
    "label2idx = {label: idx for idx, label in enumerate(set(labels))}\n",
    "idx2label = {idx: label for label, idx in label2idx.items()}\n",
    "labels = [label2idx[label] for label in labels]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 4590\n"
     ]
    }
   ],
   "source": [
    "# Build vocabulary\n",
    "def build_vocab(pairs, max_vocab_size=7000):\n",
    "    # Count word frequencies\n",
    "    words = Counter()\n",
    "    for input_text, target_text in pairs:\n",
    "        words.update(input_text.split())\n",
    "        words.update(target_text.split())\n",
    "    \n",
    "    # Select the most common words\n",
    "    most_common_words = {word for word, _ in words.most_common(max_vocab_size)}\n",
    "\n",
    "    # Create mappings with <UNK> token for rare words\n",
    "    word2idx = {'<PAD>': 0, '<SOS>': 1, '<EOS>': 2, '<UNK>': 3}\n",
    "    for word in most_common_words:\n",
    "        if word not in word2idx:\n",
    "            word2idx[word] = len(word2idx)\n",
    "    \n",
    "    idx2word = {idx: word for word, idx in word2idx.items()}\n",
    "    return word2idx, idx2word\n",
    "\n",
    "word2idx, idx2word = build_vocab(combined_pairs)\n",
    "print(f\"Vocabulary size: {len(word2idx)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(patterns).toarray()\n",
    "y = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data for intent classification\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the MLP for intent classification\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the MLP model\n",
    "input_dim = X_train.shape[1]\n",
    "hidden_dim = 128\n",
    "output_dim = len(label2idx)\n",
    "intent_model = MLP(input_dim, hidden_dim, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer for MLP\n",
    "mlp_criterion = nn.CrossEntropyLoss()\n",
    "mlp_optimizer = optim.Adam(intent_model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000, Train Loss: 3.6405, Val Loss: 3.6381, Val Accuracy: 3.77%\n",
      "Epoch 2/1000, Train Loss: 3.6365, Val Loss: 3.6353, Val Accuracy: 3.77%\n",
      "Epoch 3/1000, Train Loss: 3.6325, Val Loss: 3.6324, Val Accuracy: 3.77%\n",
      "Epoch 4/1000, Train Loss: 3.6285, Val Loss: 3.6296, Val Accuracy: 3.77%\n",
      "Epoch 5/1000, Train Loss: 3.6245, Val Loss: 3.6268, Val Accuracy: 3.77%\n",
      "Epoch 6/1000, Train Loss: 3.6205, Val Loss: 3.6239, Val Accuracy: 3.77%\n",
      "Epoch 7/1000, Train Loss: 3.6165, Val Loss: 3.6211, Val Accuracy: 3.77%\n",
      "Epoch 8/1000, Train Loss: 3.6125, Val Loss: 3.6182, Val Accuracy: 5.03%\n",
      "Epoch 9/1000, Train Loss: 3.6085, Val Loss: 3.6154, Val Accuracy: 6.29%\n",
      "Epoch 10/1000, Train Loss: 3.6045, Val Loss: 3.6125, Val Accuracy: 6.29%\n",
      "Epoch 11/1000, Train Loss: 3.6005, Val Loss: 3.6096, Val Accuracy: 8.18%\n",
      "Epoch 12/1000, Train Loss: 3.5965, Val Loss: 3.6067, Val Accuracy: 9.43%\n",
      "Epoch 13/1000, Train Loss: 3.5924, Val Loss: 3.6038, Val Accuracy: 8.81%\n",
      "Epoch 14/1000, Train Loss: 3.5883, Val Loss: 3.6008, Val Accuracy: 8.81%\n",
      "Epoch 15/1000, Train Loss: 3.5842, Val Loss: 3.5978, Val Accuracy: 9.43%\n",
      "Epoch 16/1000, Train Loss: 3.5800, Val Loss: 3.5948, Val Accuracy: 10.06%\n",
      "Epoch 17/1000, Train Loss: 3.5758, Val Loss: 3.5918, Val Accuracy: 10.06%\n",
      "Epoch 18/1000, Train Loss: 3.5715, Val Loss: 3.5887, Val Accuracy: 10.06%\n",
      "Epoch 19/1000, Train Loss: 3.5672, Val Loss: 3.5856, Val Accuracy: 10.69%\n",
      "Epoch 20/1000, Train Loss: 3.5629, Val Loss: 3.5824, Val Accuracy: 11.32%\n",
      "Epoch 21/1000, Train Loss: 3.5584, Val Loss: 3.5792, Val Accuracy: 11.32%\n",
      "Epoch 22/1000, Train Loss: 3.5540, Val Loss: 3.5760, Val Accuracy: 11.32%\n",
      "Epoch 23/1000, Train Loss: 3.5494, Val Loss: 3.5727, Val Accuracy: 12.58%\n",
      "Epoch 24/1000, Train Loss: 3.5448, Val Loss: 3.5694, Val Accuracy: 12.58%\n",
      "Epoch 25/1000, Train Loss: 3.5401, Val Loss: 3.5659, Val Accuracy: 13.21%\n",
      "Epoch 26/1000, Train Loss: 3.5354, Val Loss: 3.5625, Val Accuracy: 13.84%\n",
      "Epoch 27/1000, Train Loss: 3.5305, Val Loss: 3.5589, Val Accuracy: 14.47%\n",
      "Epoch 28/1000, Train Loss: 3.5256, Val Loss: 3.5553, Val Accuracy: 15.09%\n",
      "Epoch 29/1000, Train Loss: 3.5206, Val Loss: 3.5517, Val Accuracy: 16.35%\n",
      "Epoch 30/1000, Train Loss: 3.5155, Val Loss: 3.5480, Val Accuracy: 16.35%\n",
      "Epoch 31/1000, Train Loss: 3.5103, Val Loss: 3.5442, Val Accuracy: 18.24%\n",
      "Epoch 32/1000, Train Loss: 3.5050, Val Loss: 3.5404, Val Accuracy: 18.24%\n",
      "Epoch 33/1000, Train Loss: 3.4997, Val Loss: 3.5364, Val Accuracy: 22.01%\n",
      "Epoch 34/1000, Train Loss: 3.4942, Val Loss: 3.5325, Val Accuracy: 22.64%\n",
      "Epoch 35/1000, Train Loss: 3.4886, Val Loss: 3.5284, Val Accuracy: 22.64%\n",
      "Epoch 36/1000, Train Loss: 3.4830, Val Loss: 3.5243, Val Accuracy: 24.53%\n",
      "Epoch 37/1000, Train Loss: 3.4772, Val Loss: 3.5201, Val Accuracy: 27.04%\n",
      "Epoch 38/1000, Train Loss: 3.4713, Val Loss: 3.5158, Val Accuracy: 27.67%\n",
      "Epoch 39/1000, Train Loss: 3.4653, Val Loss: 3.5114, Val Accuracy: 28.93%\n",
      "Epoch 40/1000, Train Loss: 3.4592, Val Loss: 3.5070, Val Accuracy: 30.82%\n",
      "Epoch 41/1000, Train Loss: 3.4530, Val Loss: 3.5025, Val Accuracy: 30.82%\n",
      "Epoch 42/1000, Train Loss: 3.4467, Val Loss: 3.4979, Val Accuracy: 31.45%\n",
      "Epoch 43/1000, Train Loss: 3.4402, Val Loss: 3.4932, Val Accuracy: 33.33%\n",
      "Epoch 44/1000, Train Loss: 3.4337, Val Loss: 3.4884, Val Accuracy: 34.59%\n",
      "Epoch 45/1000, Train Loss: 3.4270, Val Loss: 3.4836, Val Accuracy: 35.85%\n",
      "Epoch 46/1000, Train Loss: 3.4202, Val Loss: 3.4786, Val Accuracy: 35.85%\n",
      "Epoch 47/1000, Train Loss: 3.4133, Val Loss: 3.4736, Val Accuracy: 37.74%\n",
      "Epoch 48/1000, Train Loss: 3.4062, Val Loss: 3.4684, Val Accuracy: 37.74%\n",
      "Epoch 49/1000, Train Loss: 3.3990, Val Loss: 3.4632, Val Accuracy: 38.99%\n",
      "Epoch 50/1000, Train Loss: 3.3917, Val Loss: 3.4579, Val Accuracy: 39.62%\n",
      "Epoch 51/1000, Train Loss: 3.3842, Val Loss: 3.4525, Val Accuracy: 39.62%\n",
      "Epoch 52/1000, Train Loss: 3.3767, Val Loss: 3.4470, Val Accuracy: 39.62%\n",
      "Epoch 53/1000, Train Loss: 3.3689, Val Loss: 3.4414, Val Accuracy: 40.88%\n",
      "Epoch 54/1000, Train Loss: 3.3611, Val Loss: 3.4357, Val Accuracy: 41.51%\n",
      "Epoch 55/1000, Train Loss: 3.3530, Val Loss: 3.4298, Val Accuracy: 42.77%\n",
      "Epoch 56/1000, Train Loss: 3.3449, Val Loss: 3.4239, Val Accuracy: 42.77%\n",
      "Epoch 57/1000, Train Loss: 3.3366, Val Loss: 3.4179, Val Accuracy: 44.65%\n",
      "Epoch 58/1000, Train Loss: 3.3282, Val Loss: 3.4118, Val Accuracy: 45.28%\n",
      "Epoch 59/1000, Train Loss: 3.3197, Val Loss: 3.4056, Val Accuracy: 45.91%\n",
      "Epoch 60/1000, Train Loss: 3.3110, Val Loss: 3.3993, Val Accuracy: 46.54%\n",
      "Epoch 61/1000, Train Loss: 3.3022, Val Loss: 3.3930, Val Accuracy: 45.91%\n",
      "Epoch 62/1000, Train Loss: 3.2932, Val Loss: 3.3865, Val Accuracy: 47.80%\n",
      "Epoch 63/1000, Train Loss: 3.2841, Val Loss: 3.3799, Val Accuracy: 47.80%\n",
      "Epoch 64/1000, Train Loss: 3.2748, Val Loss: 3.3732, Val Accuracy: 47.80%\n",
      "Epoch 65/1000, Train Loss: 3.2655, Val Loss: 3.3664, Val Accuracy: 47.80%\n",
      "Epoch 66/1000, Train Loss: 3.2559, Val Loss: 3.3595, Val Accuracy: 49.06%\n",
      "Epoch 67/1000, Train Loss: 3.2463, Val Loss: 3.3525, Val Accuracy: 49.06%\n",
      "Epoch 68/1000, Train Loss: 3.2365, Val Loss: 3.3454, Val Accuracy: 50.31%\n",
      "Epoch 69/1000, Train Loss: 3.2265, Val Loss: 3.3382, Val Accuracy: 49.69%\n",
      "Epoch 70/1000, Train Loss: 3.2164, Val Loss: 3.3309, Val Accuracy: 49.69%\n",
      "Epoch 71/1000, Train Loss: 3.2062, Val Loss: 3.3235, Val Accuracy: 49.69%\n",
      "Epoch 72/1000, Train Loss: 3.1959, Val Loss: 3.3160, Val Accuracy: 49.69%\n",
      "Epoch 73/1000, Train Loss: 3.1854, Val Loss: 3.3084, Val Accuracy: 49.69%\n",
      "Epoch 74/1000, Train Loss: 3.1748, Val Loss: 3.3008, Val Accuracy: 49.69%\n",
      "Epoch 75/1000, Train Loss: 3.1640, Val Loss: 3.2930, Val Accuracy: 49.69%\n",
      "Epoch 76/1000, Train Loss: 3.1531, Val Loss: 3.2852, Val Accuracy: 49.69%\n",
      "Epoch 77/1000, Train Loss: 3.1421, Val Loss: 3.2773, Val Accuracy: 51.57%\n",
      "Epoch 78/1000, Train Loss: 3.1310, Val Loss: 3.2693, Val Accuracy: 52.83%\n",
      "Epoch 79/1000, Train Loss: 3.1198, Val Loss: 3.2612, Val Accuracy: 52.83%\n",
      "Epoch 80/1000, Train Loss: 3.1084, Val Loss: 3.2530, Val Accuracy: 52.83%\n",
      "Epoch 81/1000, Train Loss: 3.0969, Val Loss: 3.2448, Val Accuracy: 52.83%\n",
      "Epoch 82/1000, Train Loss: 3.0853, Val Loss: 3.2364, Val Accuracy: 52.83%\n",
      "Epoch 83/1000, Train Loss: 3.0735, Val Loss: 3.2280, Val Accuracy: 51.57%\n",
      "Epoch 84/1000, Train Loss: 3.0617, Val Loss: 3.2195, Val Accuracy: 51.57%\n",
      "Epoch 85/1000, Train Loss: 3.0497, Val Loss: 3.2109, Val Accuracy: 51.57%\n",
      "Epoch 86/1000, Train Loss: 3.0376, Val Loss: 3.2023, Val Accuracy: 51.57%\n",
      "Epoch 87/1000, Train Loss: 3.0254, Val Loss: 3.1935, Val Accuracy: 51.57%\n",
      "Epoch 88/1000, Train Loss: 3.0130, Val Loss: 3.1847, Val Accuracy: 51.57%\n",
      "Epoch 89/1000, Train Loss: 3.0006, Val Loss: 3.1758, Val Accuracy: 51.57%\n",
      "Epoch 90/1000, Train Loss: 2.9880, Val Loss: 3.1668, Val Accuracy: 52.20%\n",
      "Epoch 91/1000, Train Loss: 2.9754, Val Loss: 3.1578, Val Accuracy: 52.20%\n",
      "Epoch 92/1000, Train Loss: 2.9626, Val Loss: 3.1487, Val Accuracy: 52.20%\n",
      "Epoch 93/1000, Train Loss: 2.9497, Val Loss: 3.1395, Val Accuracy: 52.83%\n",
      "Epoch 94/1000, Train Loss: 2.9367, Val Loss: 3.1302, Val Accuracy: 53.46%\n",
      "Epoch 95/1000, Train Loss: 2.9236, Val Loss: 3.1208, Val Accuracy: 53.46%\n",
      "Epoch 96/1000, Train Loss: 2.9104, Val Loss: 3.1114, Val Accuracy: 53.46%\n",
      "Epoch 97/1000, Train Loss: 2.8972, Val Loss: 3.1019, Val Accuracy: 53.46%\n",
      "Epoch 98/1000, Train Loss: 2.8838, Val Loss: 3.0924, Val Accuracy: 53.46%\n",
      "Epoch 99/1000, Train Loss: 2.8703, Val Loss: 3.0828, Val Accuracy: 53.46%\n",
      "Epoch 100/1000, Train Loss: 2.8568, Val Loss: 3.0732, Val Accuracy: 54.72%\n",
      "Epoch 101/1000, Train Loss: 2.8431, Val Loss: 3.0634, Val Accuracy: 54.72%\n",
      "Epoch 102/1000, Train Loss: 2.8294, Val Loss: 3.0537, Val Accuracy: 55.35%\n",
      "Epoch 103/1000, Train Loss: 2.8156, Val Loss: 3.0438, Val Accuracy: 55.35%\n",
      "Epoch 104/1000, Train Loss: 2.8018, Val Loss: 3.0339, Val Accuracy: 55.35%\n",
      "Epoch 105/1000, Train Loss: 2.7878, Val Loss: 3.0240, Val Accuracy: 55.35%\n",
      "Epoch 106/1000, Train Loss: 2.7738, Val Loss: 3.0140, Val Accuracy: 55.35%\n",
      "Epoch 107/1000, Train Loss: 2.7597, Val Loss: 3.0039, Val Accuracy: 55.35%\n",
      "Epoch 108/1000, Train Loss: 2.7455, Val Loss: 2.9938, Val Accuracy: 55.97%\n",
      "Epoch 109/1000, Train Loss: 2.7313, Val Loss: 2.9837, Val Accuracy: 55.97%\n",
      "Epoch 110/1000, Train Loss: 2.7170, Val Loss: 2.9735, Val Accuracy: 56.60%\n",
      "Epoch 111/1000, Train Loss: 2.7027, Val Loss: 2.9633, Val Accuracy: 56.60%\n",
      "Epoch 112/1000, Train Loss: 2.6883, Val Loss: 2.9530, Val Accuracy: 56.60%\n",
      "Epoch 113/1000, Train Loss: 2.6739, Val Loss: 2.9427, Val Accuracy: 56.60%\n",
      "Epoch 114/1000, Train Loss: 2.6593, Val Loss: 2.9323, Val Accuracy: 56.60%\n",
      "Epoch 115/1000, Train Loss: 2.6448, Val Loss: 2.9220, Val Accuracy: 56.60%\n",
      "Epoch 116/1000, Train Loss: 2.6302, Val Loss: 2.9115, Val Accuracy: 56.60%\n",
      "Epoch 117/1000, Train Loss: 2.6155, Val Loss: 2.9011, Val Accuracy: 56.60%\n",
      "Epoch 118/1000, Train Loss: 2.6008, Val Loss: 2.8906, Val Accuracy: 56.60%\n",
      "Epoch 119/1000, Train Loss: 2.5861, Val Loss: 2.8800, Val Accuracy: 56.60%\n",
      "Epoch 120/1000, Train Loss: 2.5713, Val Loss: 2.8695, Val Accuracy: 56.60%\n",
      "Epoch 121/1000, Train Loss: 2.5564, Val Loss: 2.8589, Val Accuracy: 56.60%\n",
      "Epoch 122/1000, Train Loss: 2.5416, Val Loss: 2.8483, Val Accuracy: 56.60%\n",
      "Epoch 123/1000, Train Loss: 2.5267, Val Loss: 2.8376, Val Accuracy: 56.60%\n",
      "Epoch 124/1000, Train Loss: 2.5118, Val Loss: 2.8270, Val Accuracy: 56.60%\n",
      "Epoch 125/1000, Train Loss: 2.4968, Val Loss: 2.8163, Val Accuracy: 56.60%\n",
      "Epoch 126/1000, Train Loss: 2.4819, Val Loss: 2.8056, Val Accuracy: 56.60%\n",
      "Epoch 127/1000, Train Loss: 2.4669, Val Loss: 2.7948, Val Accuracy: 56.60%\n",
      "Epoch 128/1000, Train Loss: 2.4519, Val Loss: 2.7841, Val Accuracy: 56.60%\n",
      "Epoch 129/1000, Train Loss: 2.4369, Val Loss: 2.7733, Val Accuracy: 56.60%\n",
      "Epoch 130/1000, Train Loss: 2.4219, Val Loss: 2.7625, Val Accuracy: 57.23%\n",
      "Epoch 131/1000, Train Loss: 2.4068, Val Loss: 2.7517, Val Accuracy: 57.23%\n",
      "Epoch 132/1000, Train Loss: 2.3918, Val Loss: 2.7409, Val Accuracy: 57.23%\n",
      "Epoch 133/1000, Train Loss: 2.3767, Val Loss: 2.7300, Val Accuracy: 57.23%\n",
      "Epoch 134/1000, Train Loss: 2.3616, Val Loss: 2.7192, Val Accuracy: 57.23%\n",
      "Epoch 135/1000, Train Loss: 2.3466, Val Loss: 2.7083, Val Accuracy: 57.23%\n",
      "Epoch 136/1000, Train Loss: 2.3315, Val Loss: 2.6975, Val Accuracy: 57.23%\n",
      "Epoch 137/1000, Train Loss: 2.3165, Val Loss: 2.6866, Val Accuracy: 59.12%\n",
      "Epoch 138/1000, Train Loss: 2.3014, Val Loss: 2.6757, Val Accuracy: 59.12%\n",
      "Epoch 139/1000, Train Loss: 2.2864, Val Loss: 2.6648, Val Accuracy: 59.12%\n",
      "Epoch 140/1000, Train Loss: 2.2713, Val Loss: 2.6540, Val Accuracy: 59.12%\n",
      "Epoch 141/1000, Train Loss: 2.2563, Val Loss: 2.6430, Val Accuracy: 59.12%\n",
      "Epoch 142/1000, Train Loss: 2.2413, Val Loss: 2.6321, Val Accuracy: 59.12%\n",
      "Epoch 143/1000, Train Loss: 2.2262, Val Loss: 2.6212, Val Accuracy: 59.12%\n",
      "Epoch 144/1000, Train Loss: 2.2113, Val Loss: 2.6103, Val Accuracy: 59.12%\n",
      "Epoch 145/1000, Train Loss: 2.1963, Val Loss: 2.5993, Val Accuracy: 59.75%\n",
      "Epoch 146/1000, Train Loss: 2.1813, Val Loss: 2.5884, Val Accuracy: 59.75%\n",
      "Epoch 147/1000, Train Loss: 2.1664, Val Loss: 2.5774, Val Accuracy: 59.75%\n",
      "Epoch 148/1000, Train Loss: 2.1514, Val Loss: 2.5664, Val Accuracy: 59.75%\n",
      "Epoch 149/1000, Train Loss: 2.1365, Val Loss: 2.5555, Val Accuracy: 59.75%\n",
      "Epoch 150/1000, Train Loss: 2.1216, Val Loss: 2.5445, Val Accuracy: 59.75%\n",
      "Epoch 151/1000, Train Loss: 2.1068, Val Loss: 2.5336, Val Accuracy: 59.75%\n",
      "Epoch 152/1000, Train Loss: 2.0920, Val Loss: 2.5226, Val Accuracy: 59.75%\n",
      "Epoch 153/1000, Train Loss: 2.0772, Val Loss: 2.5116, Val Accuracy: 59.75%\n",
      "Epoch 154/1000, Train Loss: 2.0624, Val Loss: 2.5007, Val Accuracy: 59.75%\n",
      "Epoch 155/1000, Train Loss: 2.0477, Val Loss: 2.4897, Val Accuracy: 60.38%\n",
      "Epoch 156/1000, Train Loss: 2.0330, Val Loss: 2.4788, Val Accuracy: 61.01%\n",
      "Epoch 157/1000, Train Loss: 2.0183, Val Loss: 2.4678, Val Accuracy: 61.01%\n",
      "Epoch 158/1000, Train Loss: 2.0037, Val Loss: 2.4569, Val Accuracy: 61.01%\n",
      "Epoch 159/1000, Train Loss: 1.9891, Val Loss: 2.4460, Val Accuracy: 61.01%\n",
      "Epoch 160/1000, Train Loss: 1.9745, Val Loss: 2.4351, Val Accuracy: 61.01%\n",
      "Epoch 161/1000, Train Loss: 1.9600, Val Loss: 2.4241, Val Accuracy: 61.01%\n",
      "Epoch 162/1000, Train Loss: 1.9455, Val Loss: 2.4132, Val Accuracy: 61.64%\n",
      "Epoch 163/1000, Train Loss: 1.9311, Val Loss: 2.4023, Val Accuracy: 61.64%\n",
      "Epoch 164/1000, Train Loss: 1.9167, Val Loss: 2.3914, Val Accuracy: 61.64%\n",
      "Epoch 165/1000, Train Loss: 1.9023, Val Loss: 2.3805, Val Accuracy: 61.64%\n",
      "Epoch 166/1000, Train Loss: 1.8880, Val Loss: 2.3696, Val Accuracy: 61.64%\n",
      "Epoch 167/1000, Train Loss: 1.8737, Val Loss: 2.3587, Val Accuracy: 61.64%\n",
      "Epoch 168/1000, Train Loss: 1.8595, Val Loss: 2.3479, Val Accuracy: 61.64%\n",
      "Epoch 169/1000, Train Loss: 1.8454, Val Loss: 2.3370, Val Accuracy: 61.64%\n",
      "Epoch 170/1000, Train Loss: 1.8312, Val Loss: 2.3261, Val Accuracy: 61.64%\n",
      "Epoch 171/1000, Train Loss: 1.8172, Val Loss: 2.3153, Val Accuracy: 61.64%\n",
      "Epoch 172/1000, Train Loss: 1.8031, Val Loss: 2.3045, Val Accuracy: 62.89%\n",
      "Epoch 173/1000, Train Loss: 1.7892, Val Loss: 2.2936, Val Accuracy: 63.52%\n",
      "Epoch 174/1000, Train Loss: 1.7752, Val Loss: 2.2828, Val Accuracy: 63.52%\n",
      "Epoch 175/1000, Train Loss: 1.7614, Val Loss: 2.2720, Val Accuracy: 63.52%\n",
      "Epoch 176/1000, Train Loss: 1.7476, Val Loss: 2.2613, Val Accuracy: 63.52%\n",
      "Epoch 177/1000, Train Loss: 1.7338, Val Loss: 2.2505, Val Accuracy: 63.52%\n",
      "Epoch 178/1000, Train Loss: 1.7201, Val Loss: 2.2398, Val Accuracy: 63.52%\n",
      "Epoch 179/1000, Train Loss: 1.7064, Val Loss: 2.2291, Val Accuracy: 64.15%\n",
      "Epoch 180/1000, Train Loss: 1.6928, Val Loss: 2.2184, Val Accuracy: 64.15%\n",
      "Epoch 181/1000, Train Loss: 1.6793, Val Loss: 2.2077, Val Accuracy: 64.15%\n",
      "Epoch 182/1000, Train Loss: 1.6658, Val Loss: 2.1971, Val Accuracy: 64.78%\n",
      "Epoch 183/1000, Train Loss: 1.6524, Val Loss: 2.1864, Val Accuracy: 64.78%\n",
      "Epoch 184/1000, Train Loss: 1.6391, Val Loss: 2.1758, Val Accuracy: 64.78%\n",
      "Epoch 185/1000, Train Loss: 1.6258, Val Loss: 2.1652, Val Accuracy: 64.78%\n",
      "Epoch 186/1000, Train Loss: 1.6126, Val Loss: 2.1547, Val Accuracy: 64.78%\n",
      "Epoch 187/1000, Train Loss: 1.5994, Val Loss: 2.1442, Val Accuracy: 65.41%\n",
      "Epoch 188/1000, Train Loss: 1.5863, Val Loss: 2.1337, Val Accuracy: 66.67%\n",
      "Epoch 189/1000, Train Loss: 1.5733, Val Loss: 2.1232, Val Accuracy: 66.67%\n",
      "Epoch 190/1000, Train Loss: 1.5603, Val Loss: 2.1128, Val Accuracy: 66.67%\n",
      "Epoch 191/1000, Train Loss: 1.5474, Val Loss: 2.1024, Val Accuracy: 66.67%\n",
      "Epoch 192/1000, Train Loss: 1.5345, Val Loss: 2.0920, Val Accuracy: 66.67%\n",
      "Epoch 193/1000, Train Loss: 1.5218, Val Loss: 2.0817, Val Accuracy: 66.67%\n",
      "Epoch 194/1000, Train Loss: 1.5091, Val Loss: 2.0713, Val Accuracy: 66.67%\n",
      "Epoch 195/1000, Train Loss: 1.4964, Val Loss: 2.0611, Val Accuracy: 66.67%\n",
      "Epoch 196/1000, Train Loss: 1.4839, Val Loss: 2.0508, Val Accuracy: 66.67%\n",
      "Epoch 197/1000, Train Loss: 1.4714, Val Loss: 2.0406, Val Accuracy: 66.67%\n",
      "Epoch 198/1000, Train Loss: 1.4589, Val Loss: 2.0304, Val Accuracy: 66.67%\n",
      "Epoch 199/1000, Train Loss: 1.4466, Val Loss: 2.0203, Val Accuracy: 66.67%\n",
      "Epoch 200/1000, Train Loss: 1.4343, Val Loss: 2.0102, Val Accuracy: 67.30%\n",
      "Epoch 201/1000, Train Loss: 1.4221, Val Loss: 2.0001, Val Accuracy: 67.92%\n",
      "Epoch 202/1000, Train Loss: 1.4100, Val Loss: 1.9901, Val Accuracy: 67.92%\n",
      "Epoch 203/1000, Train Loss: 1.3979, Val Loss: 1.9801, Val Accuracy: 69.18%\n",
      "Epoch 204/1000, Train Loss: 1.3859, Val Loss: 1.9702, Val Accuracy: 69.18%\n",
      "Epoch 205/1000, Train Loss: 1.3740, Val Loss: 1.9603, Val Accuracy: 69.18%\n",
      "Epoch 206/1000, Train Loss: 1.3622, Val Loss: 1.9504, Val Accuracy: 69.18%\n",
      "Epoch 207/1000, Train Loss: 1.3504, Val Loss: 1.9406, Val Accuracy: 70.44%\n",
      "Epoch 208/1000, Train Loss: 1.3387, Val Loss: 1.9308, Val Accuracy: 70.44%\n",
      "Epoch 209/1000, Train Loss: 1.3271, Val Loss: 1.9211, Val Accuracy: 71.07%\n",
      "Epoch 210/1000, Train Loss: 1.3156, Val Loss: 1.9114, Val Accuracy: 71.07%\n",
      "Epoch 211/1000, Train Loss: 1.3041, Val Loss: 1.9017, Val Accuracy: 71.07%\n",
      "Epoch 212/1000, Train Loss: 1.2927, Val Loss: 1.8921, Val Accuracy: 71.07%\n",
      "Epoch 213/1000, Train Loss: 1.2814, Val Loss: 1.8826, Val Accuracy: 71.07%\n",
      "Epoch 214/1000, Train Loss: 1.2702, Val Loss: 1.8730, Val Accuracy: 71.70%\n",
      "Epoch 215/1000, Train Loss: 1.2591, Val Loss: 1.8636, Val Accuracy: 71.70%\n",
      "Epoch 216/1000, Train Loss: 1.2480, Val Loss: 1.8541, Val Accuracy: 71.70%\n",
      "Epoch 217/1000, Train Loss: 1.2370, Val Loss: 1.8448, Val Accuracy: 71.70%\n",
      "Epoch 218/1000, Train Loss: 1.2261, Val Loss: 1.8354, Val Accuracy: 71.70%\n",
      "Epoch 219/1000, Train Loss: 1.2153, Val Loss: 1.8261, Val Accuracy: 72.33%\n",
      "Epoch 220/1000, Train Loss: 1.2045, Val Loss: 1.8169, Val Accuracy: 72.33%\n",
      "Epoch 221/1000, Train Loss: 1.1939, Val Loss: 1.8077, Val Accuracy: 72.33%\n",
      "Epoch 222/1000, Train Loss: 1.1833, Val Loss: 1.7986, Val Accuracy: 72.33%\n",
      "Epoch 223/1000, Train Loss: 1.1727, Val Loss: 1.7895, Val Accuracy: 72.96%\n",
      "Epoch 224/1000, Train Loss: 1.1623, Val Loss: 1.7804, Val Accuracy: 73.58%\n",
      "Epoch 225/1000, Train Loss: 1.1519, Val Loss: 1.7714, Val Accuracy: 74.21%\n",
      "Epoch 226/1000, Train Loss: 1.1417, Val Loss: 1.7625, Val Accuracy: 74.21%\n",
      "Epoch 227/1000, Train Loss: 1.1315, Val Loss: 1.7536, Val Accuracy: 74.21%\n",
      "Epoch 228/1000, Train Loss: 1.1213, Val Loss: 1.7447, Val Accuracy: 75.47%\n",
      "Epoch 229/1000, Train Loss: 1.1113, Val Loss: 1.7359, Val Accuracy: 76.10%\n",
      "Epoch 230/1000, Train Loss: 1.1013, Val Loss: 1.7272, Val Accuracy: 76.10%\n",
      "Epoch 231/1000, Train Loss: 1.0915, Val Loss: 1.7185, Val Accuracy: 76.10%\n",
      "Epoch 232/1000, Train Loss: 1.0817, Val Loss: 1.7098, Val Accuracy: 76.10%\n",
      "Epoch 233/1000, Train Loss: 1.0719, Val Loss: 1.7013, Val Accuracy: 76.10%\n",
      "Epoch 234/1000, Train Loss: 1.0623, Val Loss: 1.6927, Val Accuracy: 76.10%\n",
      "Epoch 235/1000, Train Loss: 1.0527, Val Loss: 1.6842, Val Accuracy: 76.10%\n",
      "Epoch 236/1000, Train Loss: 1.0432, Val Loss: 1.6758, Val Accuracy: 76.10%\n",
      "Epoch 237/1000, Train Loss: 1.0338, Val Loss: 1.6674, Val Accuracy: 76.73%\n",
      "Epoch 238/1000, Train Loss: 1.0245, Val Loss: 1.6591, Val Accuracy: 76.73%\n",
      "Epoch 239/1000, Train Loss: 1.0152, Val Loss: 1.6508, Val Accuracy: 77.36%\n",
      "Epoch 240/1000, Train Loss: 1.0060, Val Loss: 1.6425, Val Accuracy: 77.36%\n",
      "Epoch 241/1000, Train Loss: 0.9969, Val Loss: 1.6344, Val Accuracy: 77.36%\n",
      "Epoch 242/1000, Train Loss: 0.9879, Val Loss: 1.6262, Val Accuracy: 77.36%\n",
      "Epoch 243/1000, Train Loss: 0.9789, Val Loss: 1.6182, Val Accuracy: 77.36%\n",
      "Epoch 244/1000, Train Loss: 0.9701, Val Loss: 1.6101, Val Accuracy: 77.36%\n",
      "Epoch 245/1000, Train Loss: 0.9613, Val Loss: 1.6022, Val Accuracy: 77.36%\n",
      "Epoch 246/1000, Train Loss: 0.9526, Val Loss: 1.5943, Val Accuracy: 77.36%\n",
      "Epoch 247/1000, Train Loss: 0.9439, Val Loss: 1.5864, Val Accuracy: 77.36%\n",
      "Epoch 248/1000, Train Loss: 0.9354, Val Loss: 1.5786, Val Accuracy: 77.36%\n",
      "Epoch 249/1000, Train Loss: 0.9269, Val Loss: 1.5709, Val Accuracy: 77.36%\n",
      "Epoch 250/1000, Train Loss: 0.9185, Val Loss: 1.5632, Val Accuracy: 77.99%\n",
      "Epoch 251/1000, Train Loss: 0.9101, Val Loss: 1.5555, Val Accuracy: 77.99%\n",
      "Epoch 252/1000, Train Loss: 0.9018, Val Loss: 1.5479, Val Accuracy: 78.62%\n",
      "Epoch 253/1000, Train Loss: 0.8937, Val Loss: 1.5404, Val Accuracy: 78.62%\n",
      "Epoch 254/1000, Train Loss: 0.8855, Val Loss: 1.5329, Val Accuracy: 78.62%\n",
      "Epoch 255/1000, Train Loss: 0.8775, Val Loss: 1.5255, Val Accuracy: 78.62%\n",
      "Epoch 256/1000, Train Loss: 0.8695, Val Loss: 1.5181, Val Accuracy: 78.62%\n",
      "Epoch 257/1000, Train Loss: 0.8617, Val Loss: 1.5108, Val Accuracy: 78.62%\n",
      "Epoch 258/1000, Train Loss: 0.8538, Val Loss: 1.5035, Val Accuracy: 78.62%\n",
      "Epoch 259/1000, Train Loss: 0.8461, Val Loss: 1.4963, Val Accuracy: 78.62%\n",
      "Epoch 260/1000, Train Loss: 0.8384, Val Loss: 1.4892, Val Accuracy: 78.62%\n",
      "Epoch 261/1000, Train Loss: 0.8308, Val Loss: 1.4821, Val Accuracy: 78.62%\n",
      "Epoch 262/1000, Train Loss: 0.8233, Val Loss: 1.4750, Val Accuracy: 78.62%\n",
      "Epoch 263/1000, Train Loss: 0.8158, Val Loss: 1.4680, Val Accuracy: 78.62%\n",
      "Epoch 264/1000, Train Loss: 0.8085, Val Loss: 1.4611, Val Accuracy: 78.62%\n",
      "Epoch 265/1000, Train Loss: 0.8011, Val Loss: 1.4542, Val Accuracy: 78.62%\n",
      "Epoch 266/1000, Train Loss: 0.7939, Val Loss: 1.4474, Val Accuracy: 78.62%\n",
      "Epoch 267/1000, Train Loss: 0.7867, Val Loss: 1.4406, Val Accuracy: 78.62%\n",
      "Epoch 268/1000, Train Loss: 0.7796, Val Loss: 1.4339, Val Accuracy: 78.62%\n",
      "Epoch 269/1000, Train Loss: 0.7726, Val Loss: 1.4273, Val Accuracy: 78.62%\n",
      "Epoch 270/1000, Train Loss: 0.7656, Val Loss: 1.4207, Val Accuracy: 78.62%\n",
      "Epoch 271/1000, Train Loss: 0.7587, Val Loss: 1.4141, Val Accuracy: 78.62%\n",
      "Epoch 272/1000, Train Loss: 0.7519, Val Loss: 1.4076, Val Accuracy: 78.62%\n",
      "Epoch 273/1000, Train Loss: 0.7451, Val Loss: 1.4012, Val Accuracy: 78.62%\n",
      "Epoch 274/1000, Train Loss: 0.7384, Val Loss: 1.3948, Val Accuracy: 78.62%\n",
      "Epoch 275/1000, Train Loss: 0.7318, Val Loss: 1.3884, Val Accuracy: 78.62%\n",
      "Epoch 276/1000, Train Loss: 0.7252, Val Loss: 1.3822, Val Accuracy: 78.62%\n",
      "Epoch 277/1000, Train Loss: 0.7187, Val Loss: 1.3759, Val Accuracy: 78.62%\n",
      "Epoch 278/1000, Train Loss: 0.7123, Val Loss: 1.3698, Val Accuracy: 78.62%\n",
      "Epoch 279/1000, Train Loss: 0.7059, Val Loss: 1.3636, Val Accuracy: 78.62%\n",
      "Epoch 280/1000, Train Loss: 0.6996, Val Loss: 1.3576, Val Accuracy: 78.62%\n",
      "Epoch 281/1000, Train Loss: 0.6934, Val Loss: 1.3516, Val Accuracy: 78.62%\n",
      "Epoch 282/1000, Train Loss: 0.6872, Val Loss: 1.3456, Val Accuracy: 78.62%\n",
      "Epoch 283/1000, Train Loss: 0.6811, Val Loss: 1.3397, Val Accuracy: 78.62%\n",
      "Epoch 284/1000, Train Loss: 0.6750, Val Loss: 1.3339, Val Accuracy: 78.62%\n",
      "Epoch 285/1000, Train Loss: 0.6690, Val Loss: 1.3280, Val Accuracy: 78.62%\n",
      "Epoch 286/1000, Train Loss: 0.6631, Val Loss: 1.3223, Val Accuracy: 79.25%\n",
      "Epoch 287/1000, Train Loss: 0.6573, Val Loss: 1.3166, Val Accuracy: 79.25%\n",
      "Epoch 288/1000, Train Loss: 0.6515, Val Loss: 1.3110, Val Accuracy: 79.25%\n",
      "Epoch 289/1000, Train Loss: 0.6457, Val Loss: 1.3054, Val Accuracy: 79.25%\n",
      "Epoch 290/1000, Train Loss: 0.6400, Val Loss: 1.2998, Val Accuracy: 79.25%\n",
      "Epoch 291/1000, Train Loss: 0.6344, Val Loss: 1.2943, Val Accuracy: 79.25%\n",
      "Epoch 292/1000, Train Loss: 0.6288, Val Loss: 1.2889, Val Accuracy: 79.25%\n",
      "Epoch 293/1000, Train Loss: 0.6233, Val Loss: 1.2835, Val Accuracy: 79.25%\n",
      "Epoch 294/1000, Train Loss: 0.6179, Val Loss: 1.2781, Val Accuracy: 79.25%\n",
      "Epoch 295/1000, Train Loss: 0.6125, Val Loss: 1.2729, Val Accuracy: 79.25%\n",
      "Epoch 296/1000, Train Loss: 0.6071, Val Loss: 1.2676, Val Accuracy: 79.25%\n",
      "Epoch 297/1000, Train Loss: 0.6019, Val Loss: 1.2624, Val Accuracy: 79.25%\n",
      "Epoch 298/1000, Train Loss: 0.5966, Val Loss: 1.2573, Val Accuracy: 79.25%\n",
      "Epoch 299/1000, Train Loss: 0.5915, Val Loss: 1.2522, Val Accuracy: 79.25%\n",
      "Epoch 300/1000, Train Loss: 0.5864, Val Loss: 1.2472, Val Accuracy: 79.25%\n",
      "Epoch 301/1000, Train Loss: 0.5813, Val Loss: 1.2422, Val Accuracy: 79.87%\n",
      "Epoch 302/1000, Train Loss: 0.5763, Val Loss: 1.2372, Val Accuracy: 79.87%\n",
      "Epoch 303/1000, Train Loss: 0.5713, Val Loss: 1.2323, Val Accuracy: 79.87%\n",
      "Epoch 304/1000, Train Loss: 0.5664, Val Loss: 1.2275, Val Accuracy: 79.87%\n",
      "Epoch 305/1000, Train Loss: 0.5616, Val Loss: 1.2227, Val Accuracy: 79.87%\n",
      "Epoch 306/1000, Train Loss: 0.5568, Val Loss: 1.2180, Val Accuracy: 79.87%\n",
      "Epoch 307/1000, Train Loss: 0.5521, Val Loss: 1.2132, Val Accuracy: 79.87%\n",
      "Epoch 308/1000, Train Loss: 0.5474, Val Loss: 1.2086, Val Accuracy: 79.87%\n",
      "Epoch 309/1000, Train Loss: 0.5427, Val Loss: 1.2040, Val Accuracy: 79.87%\n",
      "Epoch 310/1000, Train Loss: 0.5381, Val Loss: 1.1994, Val Accuracy: 79.87%\n",
      "Epoch 311/1000, Train Loss: 0.5336, Val Loss: 1.1949, Val Accuracy: 79.87%\n",
      "Epoch 312/1000, Train Loss: 0.5291, Val Loss: 1.1904, Val Accuracy: 79.87%\n",
      "Epoch 313/1000, Train Loss: 0.5246, Val Loss: 1.1860, Val Accuracy: 79.87%\n",
      "Epoch 314/1000, Train Loss: 0.5202, Val Loss: 1.1816, Val Accuracy: 79.87%\n",
      "Epoch 315/1000, Train Loss: 0.5159, Val Loss: 1.1772, Val Accuracy: 79.87%\n",
      "Epoch 316/1000, Train Loss: 0.5116, Val Loss: 1.1729, Val Accuracy: 79.87%\n",
      "Epoch 317/1000, Train Loss: 0.5073, Val Loss: 1.1687, Val Accuracy: 79.87%\n",
      "Epoch 318/1000, Train Loss: 0.5031, Val Loss: 1.1645, Val Accuracy: 79.87%\n",
      "Epoch 319/1000, Train Loss: 0.4990, Val Loss: 1.1603, Val Accuracy: 80.50%\n",
      "Epoch 320/1000, Train Loss: 0.4948, Val Loss: 1.1562, Val Accuracy: 80.50%\n",
      "Epoch 321/1000, Train Loss: 0.4908, Val Loss: 1.1521, Val Accuracy: 80.50%\n",
      "Epoch 322/1000, Train Loss: 0.4867, Val Loss: 1.1480, Val Accuracy: 80.50%\n",
      "Epoch 323/1000, Train Loss: 0.4827, Val Loss: 1.1440, Val Accuracy: 80.50%\n",
      "Epoch 324/1000, Train Loss: 0.4788, Val Loss: 1.1401, Val Accuracy: 80.50%\n",
      "Epoch 325/1000, Train Loss: 0.4749, Val Loss: 1.1361, Val Accuracy: 80.50%\n",
      "Epoch 326/1000, Train Loss: 0.4710, Val Loss: 1.1323, Val Accuracy: 80.50%\n",
      "Epoch 327/1000, Train Loss: 0.4672, Val Loss: 1.1284, Val Accuracy: 80.50%\n",
      "Epoch 328/1000, Train Loss: 0.4635, Val Loss: 1.1246, Val Accuracy: 80.50%\n",
      "Epoch 329/1000, Train Loss: 0.4597, Val Loss: 1.1208, Val Accuracy: 80.50%\n",
      "Epoch 330/1000, Train Loss: 0.4560, Val Loss: 1.1171, Val Accuracy: 80.50%\n",
      "Epoch 331/1000, Train Loss: 0.4524, Val Loss: 1.1134, Val Accuracy: 80.50%\n",
      "Epoch 332/1000, Train Loss: 0.4487, Val Loss: 1.1098, Val Accuracy: 81.13%\n",
      "Epoch 333/1000, Train Loss: 0.4452, Val Loss: 1.1061, Val Accuracy: 81.13%\n",
      "Epoch 334/1000, Train Loss: 0.4416, Val Loss: 1.1026, Val Accuracy: 81.13%\n",
      "Epoch 335/1000, Train Loss: 0.4381, Val Loss: 1.0990, Val Accuracy: 81.13%\n",
      "Epoch 336/1000, Train Loss: 0.4347, Val Loss: 1.0955, Val Accuracy: 81.13%\n",
      "Epoch 337/1000, Train Loss: 0.4312, Val Loss: 1.0921, Val Accuracy: 81.13%\n",
      "Epoch 338/1000, Train Loss: 0.4278, Val Loss: 1.0886, Val Accuracy: 81.13%\n",
      "Epoch 339/1000, Train Loss: 0.4245, Val Loss: 1.0852, Val Accuracy: 81.76%\n",
      "Epoch 340/1000, Train Loss: 0.4212, Val Loss: 1.0819, Val Accuracy: 81.76%\n",
      "Epoch 341/1000, Train Loss: 0.4179, Val Loss: 1.0785, Val Accuracy: 81.76%\n",
      "Epoch 342/1000, Train Loss: 0.4146, Val Loss: 1.0752, Val Accuracy: 81.76%\n",
      "Epoch 343/1000, Train Loss: 0.4114, Val Loss: 1.0720, Val Accuracy: 81.76%\n",
      "Epoch 344/1000, Train Loss: 0.4083, Val Loss: 1.0688, Val Accuracy: 81.76%\n",
      "Epoch 345/1000, Train Loss: 0.4051, Val Loss: 1.0656, Val Accuracy: 81.76%\n",
      "Epoch 346/1000, Train Loss: 0.4020, Val Loss: 1.0624, Val Accuracy: 81.76%\n",
      "Epoch 347/1000, Train Loss: 0.3989, Val Loss: 1.0593, Val Accuracy: 81.76%\n",
      "Epoch 348/1000, Train Loss: 0.3959, Val Loss: 1.0562, Val Accuracy: 81.76%\n",
      "Epoch 349/1000, Train Loss: 0.3929, Val Loss: 1.0531, Val Accuracy: 81.76%\n",
      "Epoch 350/1000, Train Loss: 0.3899, Val Loss: 1.0501, Val Accuracy: 81.76%\n",
      "Epoch 351/1000, Train Loss: 0.3869, Val Loss: 1.0471, Val Accuracy: 81.76%\n",
      "Epoch 352/1000, Train Loss: 0.3840, Val Loss: 1.0441, Val Accuracy: 81.76%\n",
      "Epoch 353/1000, Train Loss: 0.3811, Val Loss: 1.0412, Val Accuracy: 81.76%\n",
      "Epoch 354/1000, Train Loss: 0.3783, Val Loss: 1.0383, Val Accuracy: 81.76%\n",
      "Epoch 355/1000, Train Loss: 0.3754, Val Loss: 1.0354, Val Accuracy: 81.76%\n",
      "Epoch 356/1000, Train Loss: 0.3726, Val Loss: 1.0325, Val Accuracy: 81.76%\n",
      "Epoch 357/1000, Train Loss: 0.3699, Val Loss: 1.0297, Val Accuracy: 81.76%\n",
      "Epoch 358/1000, Train Loss: 0.3671, Val Loss: 1.0269, Val Accuracy: 81.76%\n",
      "Epoch 359/1000, Train Loss: 0.3644, Val Loss: 1.0241, Val Accuracy: 81.76%\n",
      "Epoch 360/1000, Train Loss: 0.3617, Val Loss: 1.0214, Val Accuracy: 81.76%\n",
      "Epoch 361/1000, Train Loss: 0.3591, Val Loss: 1.0187, Val Accuracy: 81.76%\n",
      "Epoch 362/1000, Train Loss: 0.3564, Val Loss: 1.0160, Val Accuracy: 81.76%\n",
      "Epoch 363/1000, Train Loss: 0.3538, Val Loss: 1.0133, Val Accuracy: 81.76%\n",
      "Epoch 364/1000, Train Loss: 0.3513, Val Loss: 1.0107, Val Accuracy: 81.76%\n",
      "Epoch 365/1000, Train Loss: 0.3487, Val Loss: 1.0080, Val Accuracy: 81.76%\n",
      "Epoch 366/1000, Train Loss: 0.3462, Val Loss: 1.0055, Val Accuracy: 81.76%\n",
      "Epoch 367/1000, Train Loss: 0.3437, Val Loss: 1.0029, Val Accuracy: 81.76%\n",
      "Epoch 368/1000, Train Loss: 0.3412, Val Loss: 1.0004, Val Accuracy: 81.76%\n",
      "Epoch 369/1000, Train Loss: 0.3388, Val Loss: 0.9979, Val Accuracy: 81.76%\n",
      "Epoch 370/1000, Train Loss: 0.3364, Val Loss: 0.9954, Val Accuracy: 81.76%\n",
      "Epoch 371/1000, Train Loss: 0.3340, Val Loss: 0.9929, Val Accuracy: 81.76%\n",
      "Epoch 372/1000, Train Loss: 0.3316, Val Loss: 0.9905, Val Accuracy: 81.76%\n",
      "Epoch 373/1000, Train Loss: 0.3293, Val Loss: 0.9881, Val Accuracy: 81.76%\n",
      "Epoch 374/1000, Train Loss: 0.3269, Val Loss: 0.9857, Val Accuracy: 81.76%\n",
      "Epoch 375/1000, Train Loss: 0.3247, Val Loss: 0.9834, Val Accuracy: 81.76%\n",
      "Epoch 376/1000, Train Loss: 0.3224, Val Loss: 0.9810, Val Accuracy: 81.76%\n",
      "Epoch 377/1000, Train Loss: 0.3201, Val Loss: 0.9787, Val Accuracy: 81.76%\n",
      "Epoch 378/1000, Train Loss: 0.3179, Val Loss: 0.9764, Val Accuracy: 81.76%\n",
      "Epoch 379/1000, Train Loss: 0.3157, Val Loss: 0.9742, Val Accuracy: 81.76%\n",
      "Epoch 380/1000, Train Loss: 0.3135, Val Loss: 0.9719, Val Accuracy: 81.76%\n",
      "Epoch 381/1000, Train Loss: 0.3114, Val Loss: 0.9697, Val Accuracy: 81.76%\n",
      "Epoch 382/1000, Train Loss: 0.3092, Val Loss: 0.9675, Val Accuracy: 81.76%\n",
      "Epoch 383/1000, Train Loss: 0.3071, Val Loss: 0.9653, Val Accuracy: 81.76%\n",
      "Epoch 384/1000, Train Loss: 0.3050, Val Loss: 0.9632, Val Accuracy: 81.76%\n",
      "Epoch 385/1000, Train Loss: 0.3029, Val Loss: 0.9610, Val Accuracy: 81.76%\n",
      "Epoch 386/1000, Train Loss: 0.3009, Val Loss: 0.9589, Val Accuracy: 81.76%\n",
      "Epoch 387/1000, Train Loss: 0.2988, Val Loss: 0.9568, Val Accuracy: 81.76%\n",
      "Epoch 388/1000, Train Loss: 0.2968, Val Loss: 0.9547, Val Accuracy: 81.76%\n",
      "Epoch 389/1000, Train Loss: 0.2948, Val Loss: 0.9527, Val Accuracy: 81.76%\n",
      "Epoch 390/1000, Train Loss: 0.2929, Val Loss: 0.9506, Val Accuracy: 81.76%\n",
      "Epoch 391/1000, Train Loss: 0.2909, Val Loss: 0.9486, Val Accuracy: 81.76%\n",
      "Epoch 392/1000, Train Loss: 0.2890, Val Loss: 0.9466, Val Accuracy: 81.76%\n",
      "Epoch 393/1000, Train Loss: 0.2871, Val Loss: 0.9446, Val Accuracy: 81.76%\n",
      "Epoch 394/1000, Train Loss: 0.2852, Val Loss: 0.9427, Val Accuracy: 81.76%\n",
      "Epoch 395/1000, Train Loss: 0.2833, Val Loss: 0.9407, Val Accuracy: 81.76%\n",
      "Epoch 396/1000, Train Loss: 0.2814, Val Loss: 0.9388, Val Accuracy: 81.76%\n",
      "Epoch 397/1000, Train Loss: 0.2796, Val Loss: 0.9369, Val Accuracy: 81.76%\n",
      "Epoch 398/1000, Train Loss: 0.2778, Val Loss: 0.9350, Val Accuracy: 81.76%\n",
      "Epoch 399/1000, Train Loss: 0.2760, Val Loss: 0.9331, Val Accuracy: 81.76%\n",
      "Epoch 400/1000, Train Loss: 0.2742, Val Loss: 0.9312, Val Accuracy: 81.76%\n",
      "Epoch 401/1000, Train Loss: 0.2724, Val Loss: 0.9294, Val Accuracy: 81.76%\n",
      "Epoch 402/1000, Train Loss: 0.2707, Val Loss: 0.9276, Val Accuracy: 82.39%\n",
      "Epoch 403/1000, Train Loss: 0.2689, Val Loss: 0.9258, Val Accuracy: 82.39%\n",
      "Epoch 404/1000, Train Loss: 0.2672, Val Loss: 0.9240, Val Accuracy: 82.39%\n",
      "Epoch 405/1000, Train Loss: 0.2655, Val Loss: 0.9222, Val Accuracy: 82.39%\n",
      "Epoch 406/1000, Train Loss: 0.2638, Val Loss: 0.9205, Val Accuracy: 82.39%\n",
      "Epoch 407/1000, Train Loss: 0.2622, Val Loss: 0.9187, Val Accuracy: 82.39%\n",
      "Epoch 408/1000, Train Loss: 0.2605, Val Loss: 0.9170, Val Accuracy: 82.39%\n",
      "Epoch 409/1000, Train Loss: 0.2589, Val Loss: 0.9153, Val Accuracy: 82.39%\n",
      "Epoch 410/1000, Train Loss: 0.2573, Val Loss: 0.9136, Val Accuracy: 81.76%\n",
      "Epoch 411/1000, Train Loss: 0.2556, Val Loss: 0.9119, Val Accuracy: 81.76%\n",
      "Epoch 412/1000, Train Loss: 0.2541, Val Loss: 0.9102, Val Accuracy: 81.76%\n",
      "Epoch 413/1000, Train Loss: 0.2525, Val Loss: 0.9086, Val Accuracy: 81.76%\n",
      "Epoch 414/1000, Train Loss: 0.2509, Val Loss: 0.9070, Val Accuracy: 81.76%\n",
      "Epoch 415/1000, Train Loss: 0.2494, Val Loss: 0.9053, Val Accuracy: 81.76%\n",
      "Epoch 416/1000, Train Loss: 0.2478, Val Loss: 0.9037, Val Accuracy: 81.76%\n",
      "Epoch 417/1000, Train Loss: 0.2463, Val Loss: 0.9021, Val Accuracy: 81.76%\n",
      "Epoch 418/1000, Train Loss: 0.2448, Val Loss: 0.9006, Val Accuracy: 81.76%\n",
      "Epoch 419/1000, Train Loss: 0.2433, Val Loss: 0.8990, Val Accuracy: 81.76%\n",
      "Epoch 420/1000, Train Loss: 0.2419, Val Loss: 0.8975, Val Accuracy: 81.76%\n",
      "Epoch 421/1000, Train Loss: 0.2404, Val Loss: 0.8959, Val Accuracy: 81.76%\n",
      "Epoch 422/1000, Train Loss: 0.2390, Val Loss: 0.8944, Val Accuracy: 81.76%\n",
      "Epoch 423/1000, Train Loss: 0.2375, Val Loss: 0.8929, Val Accuracy: 81.76%\n",
      "Epoch 424/1000, Train Loss: 0.2361, Val Loss: 0.8914, Val Accuracy: 81.76%\n",
      "Epoch 425/1000, Train Loss: 0.2347, Val Loss: 0.8899, Val Accuracy: 81.76%\n",
      "Epoch 426/1000, Train Loss: 0.2333, Val Loss: 0.8884, Val Accuracy: 81.76%\n",
      "Epoch 427/1000, Train Loss: 0.2319, Val Loss: 0.8870, Val Accuracy: 81.76%\n",
      "Epoch 428/1000, Train Loss: 0.2305, Val Loss: 0.8855, Val Accuracy: 81.76%\n",
      "Epoch 429/1000, Train Loss: 0.2292, Val Loss: 0.8841, Val Accuracy: 81.76%\n",
      "Epoch 430/1000, Train Loss: 0.2278, Val Loss: 0.8827, Val Accuracy: 81.76%\n",
      "Epoch 431/1000, Train Loss: 0.2265, Val Loss: 0.8813, Val Accuracy: 81.76%\n",
      "Epoch 432/1000, Train Loss: 0.2252, Val Loss: 0.8799, Val Accuracy: 81.76%\n",
      "Epoch 433/1000, Train Loss: 0.2239, Val Loss: 0.8785, Val Accuracy: 81.76%\n",
      "Epoch 434/1000, Train Loss: 0.2226, Val Loss: 0.8771, Val Accuracy: 81.76%\n",
      "Epoch 435/1000, Train Loss: 0.2213, Val Loss: 0.8758, Val Accuracy: 81.76%\n",
      "Epoch 436/1000, Train Loss: 0.2200, Val Loss: 0.8744, Val Accuracy: 81.76%\n",
      "Epoch 437/1000, Train Loss: 0.2188, Val Loss: 0.8731, Val Accuracy: 81.76%\n",
      "Epoch 438/1000, Train Loss: 0.2175, Val Loss: 0.8717, Val Accuracy: 81.76%\n",
      "Epoch 439/1000, Train Loss: 0.2163, Val Loss: 0.8704, Val Accuracy: 81.76%\n",
      "Epoch 440/1000, Train Loss: 0.2150, Val Loss: 0.8691, Val Accuracy: 81.76%\n",
      "Epoch 441/1000, Train Loss: 0.2138, Val Loss: 0.8678, Val Accuracy: 83.65%\n",
      "Epoch 442/1000, Train Loss: 0.2126, Val Loss: 0.8666, Val Accuracy: 83.65%\n",
      "Epoch 443/1000, Train Loss: 0.2114, Val Loss: 0.8653, Val Accuracy: 83.65%\n",
      "Epoch 444/1000, Train Loss: 0.2102, Val Loss: 0.8640, Val Accuracy: 83.65%\n",
      "Epoch 445/1000, Train Loss: 0.2091, Val Loss: 0.8628, Val Accuracy: 83.65%\n",
      "Epoch 446/1000, Train Loss: 0.2079, Val Loss: 0.8615, Val Accuracy: 83.65%\n",
      "Epoch 447/1000, Train Loss: 0.2067, Val Loss: 0.8603, Val Accuracy: 83.65%\n",
      "Epoch 448/1000, Train Loss: 0.2056, Val Loss: 0.8591, Val Accuracy: 83.65%\n",
      "Epoch 449/1000, Train Loss: 0.2045, Val Loss: 0.8579, Val Accuracy: 83.65%\n",
      "Epoch 450/1000, Train Loss: 0.2033, Val Loss: 0.8567, Val Accuracy: 83.65%\n",
      "Epoch 451/1000, Train Loss: 0.2022, Val Loss: 0.8555, Val Accuracy: 83.65%\n",
      "Epoch 452/1000, Train Loss: 0.2011, Val Loss: 0.8543, Val Accuracy: 83.65%\n",
      "Epoch 453/1000, Train Loss: 0.2000, Val Loss: 0.8531, Val Accuracy: 83.65%\n",
      "Epoch 454/1000, Train Loss: 0.1989, Val Loss: 0.8520, Val Accuracy: 83.65%\n",
      "Epoch 455/1000, Train Loss: 0.1978, Val Loss: 0.8508, Val Accuracy: 83.65%\n",
      "Epoch 456/1000, Train Loss: 0.1968, Val Loss: 0.8497, Val Accuracy: 83.65%\n",
      "Epoch 457/1000, Train Loss: 0.1957, Val Loss: 0.8485, Val Accuracy: 83.65%\n",
      "Epoch 458/1000, Train Loss: 0.1947, Val Loss: 0.8474, Val Accuracy: 83.65%\n",
      "Epoch 459/1000, Train Loss: 0.1936, Val Loss: 0.8463, Val Accuracy: 83.65%\n",
      "Epoch 460/1000, Train Loss: 0.1926, Val Loss: 0.8452, Val Accuracy: 83.65%\n",
      "Epoch 461/1000, Train Loss: 0.1916, Val Loss: 0.8441, Val Accuracy: 83.65%\n",
      "Epoch 462/1000, Train Loss: 0.1905, Val Loss: 0.8430, Val Accuracy: 83.65%\n",
      "Epoch 463/1000, Train Loss: 0.1895, Val Loss: 0.8419, Val Accuracy: 83.65%\n",
      "Epoch 464/1000, Train Loss: 0.1885, Val Loss: 0.8408, Val Accuracy: 83.65%\n",
      "Epoch 465/1000, Train Loss: 0.1875, Val Loss: 0.8398, Val Accuracy: 83.65%\n",
      "Epoch 466/1000, Train Loss: 0.1866, Val Loss: 0.8387, Val Accuracy: 83.65%\n",
      "Epoch 467/1000, Train Loss: 0.1856, Val Loss: 0.8377, Val Accuracy: 83.65%\n",
      "Epoch 468/1000, Train Loss: 0.1846, Val Loss: 0.8366, Val Accuracy: 83.65%\n",
      "Epoch 469/1000, Train Loss: 0.1837, Val Loss: 0.8356, Val Accuracy: 83.65%\n",
      "Epoch 470/1000, Train Loss: 0.1827, Val Loss: 0.8346, Val Accuracy: 83.65%\n",
      "Epoch 471/1000, Train Loss: 0.1818, Val Loss: 0.8336, Val Accuracy: 83.65%\n",
      "Epoch 472/1000, Train Loss: 0.1808, Val Loss: 0.8326, Val Accuracy: 83.65%\n",
      "Epoch 473/1000, Train Loss: 0.1799, Val Loss: 0.8316, Val Accuracy: 83.65%\n",
      "Epoch 474/1000, Train Loss: 0.1790, Val Loss: 0.8306, Val Accuracy: 83.65%\n",
      "Epoch 475/1000, Train Loss: 0.1781, Val Loss: 0.8296, Val Accuracy: 83.65%\n",
      "Epoch 476/1000, Train Loss: 0.1772, Val Loss: 0.8286, Val Accuracy: 83.65%\n",
      "Epoch 477/1000, Train Loss: 0.1763, Val Loss: 0.8276, Val Accuracy: 83.65%\n",
      "Epoch 478/1000, Train Loss: 0.1754, Val Loss: 0.8267, Val Accuracy: 83.65%\n",
      "Epoch 479/1000, Train Loss: 0.1745, Val Loss: 0.8257, Val Accuracy: 83.65%\n",
      "Epoch 480/1000, Train Loss: 0.1736, Val Loss: 0.8248, Val Accuracy: 83.65%\n",
      "Epoch 481/1000, Train Loss: 0.1727, Val Loss: 0.8238, Val Accuracy: 83.65%\n",
      "Epoch 482/1000, Train Loss: 0.1719, Val Loss: 0.8229, Val Accuracy: 83.65%\n",
      "Epoch 483/1000, Train Loss: 0.1710, Val Loss: 0.8220, Val Accuracy: 83.65%\n",
      "Epoch 484/1000, Train Loss: 0.1702, Val Loss: 0.8210, Val Accuracy: 83.65%\n",
      "Epoch 485/1000, Train Loss: 0.1693, Val Loss: 0.8201, Val Accuracy: 83.65%\n",
      "Epoch 486/1000, Train Loss: 0.1685, Val Loss: 0.8192, Val Accuracy: 83.65%\n",
      "Epoch 487/1000, Train Loss: 0.1676, Val Loss: 0.8183, Val Accuracy: 83.65%\n",
      "Epoch 488/1000, Train Loss: 0.1668, Val Loss: 0.8174, Val Accuracy: 83.65%\n",
      "Epoch 489/1000, Train Loss: 0.1660, Val Loss: 0.8165, Val Accuracy: 83.65%\n",
      "Epoch 490/1000, Train Loss: 0.1652, Val Loss: 0.8156, Val Accuracy: 83.65%\n",
      "Epoch 491/1000, Train Loss: 0.1644, Val Loss: 0.8148, Val Accuracy: 83.65%\n",
      "Epoch 492/1000, Train Loss: 0.1636, Val Loss: 0.8139, Val Accuracy: 83.65%\n",
      "Epoch 493/1000, Train Loss: 0.1628, Val Loss: 0.8130, Val Accuracy: 83.65%\n",
      "Epoch 494/1000, Train Loss: 0.1620, Val Loss: 0.8122, Val Accuracy: 84.28%\n",
      "Epoch 495/1000, Train Loss: 0.1612, Val Loss: 0.8113, Val Accuracy: 84.28%\n",
      "Epoch 496/1000, Train Loss: 0.1604, Val Loss: 0.8105, Val Accuracy: 84.28%\n",
      "Epoch 497/1000, Train Loss: 0.1597, Val Loss: 0.8096, Val Accuracy: 84.28%\n",
      "Epoch 498/1000, Train Loss: 0.1589, Val Loss: 0.8088, Val Accuracy: 84.28%\n",
      "Epoch 499/1000, Train Loss: 0.1582, Val Loss: 0.8080, Val Accuracy: 84.28%\n",
      "Epoch 500/1000, Train Loss: 0.1574, Val Loss: 0.8071, Val Accuracy: 84.28%\n",
      "Epoch 501/1000, Train Loss: 0.1567, Val Loss: 0.8063, Val Accuracy: 84.28%\n",
      "Epoch 502/1000, Train Loss: 0.1559, Val Loss: 0.8055, Val Accuracy: 84.28%\n",
      "Epoch 503/1000, Train Loss: 0.1552, Val Loss: 0.8047, Val Accuracy: 84.28%\n",
      "Epoch 504/1000, Train Loss: 0.1544, Val Loss: 0.8039, Val Accuracy: 84.28%\n",
      "Epoch 505/1000, Train Loss: 0.1537, Val Loss: 0.8031, Val Accuracy: 84.28%\n",
      "Epoch 506/1000, Train Loss: 0.1530, Val Loss: 0.8023, Val Accuracy: 84.28%\n",
      "Epoch 507/1000, Train Loss: 0.1523, Val Loss: 0.8016, Val Accuracy: 84.28%\n",
      "Epoch 508/1000, Train Loss: 0.1516, Val Loss: 0.8008, Val Accuracy: 84.28%\n",
      "Epoch 509/1000, Train Loss: 0.1509, Val Loss: 0.8000, Val Accuracy: 84.28%\n",
      "Epoch 510/1000, Train Loss: 0.1502, Val Loss: 0.7992, Val Accuracy: 84.28%\n",
      "Epoch 511/1000, Train Loss: 0.1495, Val Loss: 0.7985, Val Accuracy: 84.28%\n",
      "Epoch 512/1000, Train Loss: 0.1488, Val Loss: 0.7977, Val Accuracy: 84.28%\n",
      "Epoch 513/1000, Train Loss: 0.1481, Val Loss: 0.7970, Val Accuracy: 84.28%\n",
      "Epoch 514/1000, Train Loss: 0.1474, Val Loss: 0.7962, Val Accuracy: 84.28%\n",
      "Epoch 515/1000, Train Loss: 0.1468, Val Loss: 0.7955, Val Accuracy: 84.28%\n",
      "Epoch 516/1000, Train Loss: 0.1461, Val Loss: 0.7947, Val Accuracy: 84.28%\n",
      "Epoch 517/1000, Train Loss: 0.1454, Val Loss: 0.7940, Val Accuracy: 84.28%\n",
      "Epoch 518/1000, Train Loss: 0.1448, Val Loss: 0.7933, Val Accuracy: 84.28%\n",
      "Epoch 519/1000, Train Loss: 0.1441, Val Loss: 0.7926, Val Accuracy: 84.28%\n",
      "Epoch 520/1000, Train Loss: 0.1435, Val Loss: 0.7918, Val Accuracy: 84.28%\n",
      "Epoch 521/1000, Train Loss: 0.1428, Val Loss: 0.7911, Val Accuracy: 84.28%\n",
      "Epoch 522/1000, Train Loss: 0.1422, Val Loss: 0.7904, Val Accuracy: 84.28%\n",
      "Epoch 523/1000, Train Loss: 0.1415, Val Loss: 0.7897, Val Accuracy: 84.28%\n",
      "Epoch 524/1000, Train Loss: 0.1409, Val Loss: 0.7890, Val Accuracy: 84.28%\n",
      "Epoch 525/1000, Train Loss: 0.1403, Val Loss: 0.7883, Val Accuracy: 84.28%\n",
      "Epoch 526/1000, Train Loss: 0.1397, Val Loss: 0.7876, Val Accuracy: 84.28%\n",
      "Epoch 527/1000, Train Loss: 0.1390, Val Loss: 0.7870, Val Accuracy: 84.28%\n",
      "Epoch 528/1000, Train Loss: 0.1384, Val Loss: 0.7863, Val Accuracy: 84.28%\n",
      "Epoch 529/1000, Train Loss: 0.1378, Val Loss: 0.7856, Val Accuracy: 84.28%\n",
      "Epoch 530/1000, Train Loss: 0.1372, Val Loss: 0.7849, Val Accuracy: 84.28%\n",
      "Epoch 531/1000, Train Loss: 0.1366, Val Loss: 0.7843, Val Accuracy: 84.28%\n",
      "Epoch 532/1000, Train Loss: 0.1360, Val Loss: 0.7836, Val Accuracy: 84.28%\n",
      "Epoch 533/1000, Train Loss: 0.1354, Val Loss: 0.7830, Val Accuracy: 84.28%\n",
      "Epoch 534/1000, Train Loss: 0.1348, Val Loss: 0.7823, Val Accuracy: 84.28%\n",
      "Epoch 535/1000, Train Loss: 0.1343, Val Loss: 0.7817, Val Accuracy: 84.28%\n",
      "Epoch 536/1000, Train Loss: 0.1337, Val Loss: 0.7810, Val Accuracy: 84.28%\n",
      "Epoch 537/1000, Train Loss: 0.1331, Val Loss: 0.7804, Val Accuracy: 84.28%\n",
      "Epoch 538/1000, Train Loss: 0.1325, Val Loss: 0.7797, Val Accuracy: 84.28%\n",
      "Epoch 539/1000, Train Loss: 0.1320, Val Loss: 0.7791, Val Accuracy: 84.28%\n",
      "Epoch 540/1000, Train Loss: 0.1314, Val Loss: 0.7785, Val Accuracy: 84.28%\n",
      "Epoch 541/1000, Train Loss: 0.1308, Val Loss: 0.7779, Val Accuracy: 84.28%\n",
      "Epoch 542/1000, Train Loss: 0.1303, Val Loss: 0.7773, Val Accuracy: 84.28%\n",
      "Epoch 543/1000, Train Loss: 0.1297, Val Loss: 0.7766, Val Accuracy: 84.28%\n",
      "Epoch 544/1000, Train Loss: 0.1292, Val Loss: 0.7760, Val Accuracy: 84.28%\n",
      "Epoch 545/1000, Train Loss: 0.1286, Val Loss: 0.7754, Val Accuracy: 84.28%\n",
      "Epoch 546/1000, Train Loss: 0.1281, Val Loss: 0.7748, Val Accuracy: 84.28%\n",
      "Epoch 547/1000, Train Loss: 0.1275, Val Loss: 0.7742, Val Accuracy: 84.28%\n",
      "Epoch 548/1000, Train Loss: 0.1270, Val Loss: 0.7736, Val Accuracy: 84.28%\n",
      "Epoch 549/1000, Train Loss: 0.1265, Val Loss: 0.7731, Val Accuracy: 84.28%\n",
      "Epoch 550/1000, Train Loss: 0.1259, Val Loss: 0.7725, Val Accuracy: 84.28%\n",
      "Epoch 551/1000, Train Loss: 0.1254, Val Loss: 0.7719, Val Accuracy: 84.28%\n",
      "Epoch 552/1000, Train Loss: 0.1249, Val Loss: 0.7713, Val Accuracy: 84.28%\n",
      "Epoch 553/1000, Train Loss: 0.1244, Val Loss: 0.7707, Val Accuracy: 84.28%\n",
      "Epoch 554/1000, Train Loss: 0.1239, Val Loss: 0.7702, Val Accuracy: 84.28%\n",
      "Epoch 555/1000, Train Loss: 0.1233, Val Loss: 0.7696, Val Accuracy: 84.28%\n",
      "Epoch 556/1000, Train Loss: 0.1228, Val Loss: 0.7690, Val Accuracy: 84.28%\n",
      "Epoch 557/1000, Train Loss: 0.1223, Val Loss: 0.7685, Val Accuracy: 84.28%\n",
      "Epoch 558/1000, Train Loss: 0.1218, Val Loss: 0.7679, Val Accuracy: 84.28%\n",
      "Epoch 559/1000, Train Loss: 0.1213, Val Loss: 0.7674, Val Accuracy: 84.28%\n",
      "Epoch 560/1000, Train Loss: 0.1208, Val Loss: 0.7668, Val Accuracy: 84.28%\n",
      "Epoch 561/1000, Train Loss: 0.1204, Val Loss: 0.7663, Val Accuracy: 84.28%\n",
      "Epoch 562/1000, Train Loss: 0.1199, Val Loss: 0.7657, Val Accuracy: 84.28%\n",
      "Epoch 563/1000, Train Loss: 0.1194, Val Loss: 0.7652, Val Accuracy: 84.28%\n",
      "Epoch 564/1000, Train Loss: 0.1189, Val Loss: 0.7647, Val Accuracy: 84.28%\n",
      "Epoch 565/1000, Train Loss: 0.1184, Val Loss: 0.7641, Val Accuracy: 84.28%\n",
      "Epoch 566/1000, Train Loss: 0.1179, Val Loss: 0.7636, Val Accuracy: 84.28%\n",
      "Epoch 567/1000, Train Loss: 0.1175, Val Loss: 0.7631, Val Accuracy: 84.28%\n",
      "Epoch 568/1000, Train Loss: 0.1170, Val Loss: 0.7626, Val Accuracy: 84.28%\n",
      "Epoch 569/1000, Train Loss: 0.1165, Val Loss: 0.7620, Val Accuracy: 84.28%\n",
      "Epoch 570/1000, Train Loss: 0.1161, Val Loss: 0.7615, Val Accuracy: 84.28%\n",
      "Epoch 571/1000, Train Loss: 0.1156, Val Loss: 0.7610, Val Accuracy: 84.28%\n",
      "Epoch 572/1000, Train Loss: 0.1152, Val Loss: 0.7605, Val Accuracy: 84.28%\n",
      "Epoch 573/1000, Train Loss: 0.1147, Val Loss: 0.7600, Val Accuracy: 84.28%\n",
      "Epoch 574/1000, Train Loss: 0.1143, Val Loss: 0.7595, Val Accuracy: 84.28%\n",
      "Epoch 575/1000, Train Loss: 0.1138, Val Loss: 0.7590, Val Accuracy: 84.28%\n",
      "Epoch 576/1000, Train Loss: 0.1134, Val Loss: 0.7585, Val Accuracy: 84.28%\n",
      "Epoch 577/1000, Train Loss: 0.1129, Val Loss: 0.7580, Val Accuracy: 84.28%\n",
      "Epoch 578/1000, Train Loss: 0.1125, Val Loss: 0.7575, Val Accuracy: 84.28%\n",
      "Epoch 579/1000, Train Loss: 0.1121, Val Loss: 0.7570, Val Accuracy: 84.28%\n",
      "Epoch 580/1000, Train Loss: 0.1116, Val Loss: 0.7565, Val Accuracy: 84.28%\n",
      "Epoch 581/1000, Train Loss: 0.1112, Val Loss: 0.7561, Val Accuracy: 84.28%\n",
      "Epoch 582/1000, Train Loss: 0.1108, Val Loss: 0.7556, Val Accuracy: 84.28%\n",
      "Epoch 583/1000, Train Loss: 0.1104, Val Loss: 0.7551, Val Accuracy: 84.91%\n",
      "Epoch 584/1000, Train Loss: 0.1099, Val Loss: 0.7546, Val Accuracy: 84.91%\n",
      "Epoch 585/1000, Train Loss: 0.1095, Val Loss: 0.7542, Val Accuracy: 84.91%\n",
      "Epoch 586/1000, Train Loss: 0.1091, Val Loss: 0.7537, Val Accuracy: 84.91%\n",
      "Epoch 587/1000, Train Loss: 0.1087, Val Loss: 0.7532, Val Accuracy: 84.91%\n",
      "Epoch 588/1000, Train Loss: 0.1083, Val Loss: 0.7528, Val Accuracy: 84.91%\n",
      "Epoch 589/1000, Train Loss: 0.1079, Val Loss: 0.7523, Val Accuracy: 84.91%\n",
      "Epoch 590/1000, Train Loss: 0.1075, Val Loss: 0.7519, Val Accuracy: 84.91%\n",
      "Epoch 591/1000, Train Loss: 0.1071, Val Loss: 0.7514, Val Accuracy: 84.91%\n",
      "Epoch 592/1000, Train Loss: 0.1067, Val Loss: 0.7510, Val Accuracy: 84.91%\n",
      "Epoch 593/1000, Train Loss: 0.1063, Val Loss: 0.7505, Val Accuracy: 84.91%\n",
      "Epoch 594/1000, Train Loss: 0.1059, Val Loss: 0.7501, Val Accuracy: 84.91%\n",
      "Epoch 595/1000, Train Loss: 0.1055, Val Loss: 0.7496, Val Accuracy: 84.91%\n",
      "Epoch 596/1000, Train Loss: 0.1051, Val Loss: 0.7492, Val Accuracy: 84.91%\n",
      "Epoch 597/1000, Train Loss: 0.1047, Val Loss: 0.7487, Val Accuracy: 84.91%\n",
      "Epoch 598/1000, Train Loss: 0.1043, Val Loss: 0.7483, Val Accuracy: 84.91%\n",
      "Epoch 599/1000, Train Loss: 0.1039, Val Loss: 0.7479, Val Accuracy: 84.91%\n",
      "Epoch 600/1000, Train Loss: 0.1036, Val Loss: 0.7474, Val Accuracy: 84.91%\n",
      "Epoch 601/1000, Train Loss: 0.1032, Val Loss: 0.7470, Val Accuracy: 84.91%\n",
      "Epoch 602/1000, Train Loss: 0.1028, Val Loss: 0.7466, Val Accuracy: 84.91%\n",
      "Epoch 603/1000, Train Loss: 0.1024, Val Loss: 0.7462, Val Accuracy: 84.91%\n",
      "Epoch 604/1000, Train Loss: 0.1021, Val Loss: 0.7457, Val Accuracy: 84.91%\n",
      "Epoch 605/1000, Train Loss: 0.1017, Val Loss: 0.7453, Val Accuracy: 84.91%\n",
      "Epoch 606/1000, Train Loss: 0.1013, Val Loss: 0.7449, Val Accuracy: 84.91%\n",
      "Epoch 607/1000, Train Loss: 0.1010, Val Loss: 0.7445, Val Accuracy: 84.91%\n",
      "Epoch 608/1000, Train Loss: 0.1006, Val Loss: 0.7441, Val Accuracy: 84.91%\n",
      "Epoch 609/1000, Train Loss: 0.1002, Val Loss: 0.7437, Val Accuracy: 84.91%\n",
      "Epoch 610/1000, Train Loss: 0.0999, Val Loss: 0.7433, Val Accuracy: 84.91%\n",
      "Epoch 611/1000, Train Loss: 0.0995, Val Loss: 0.7429, Val Accuracy: 84.91%\n",
      "Epoch 612/1000, Train Loss: 0.0992, Val Loss: 0.7425, Val Accuracy: 84.91%\n",
      "Epoch 613/1000, Train Loss: 0.0988, Val Loss: 0.7421, Val Accuracy: 84.91%\n",
      "Epoch 614/1000, Train Loss: 0.0985, Val Loss: 0.7417, Val Accuracy: 84.91%\n",
      "Epoch 615/1000, Train Loss: 0.0981, Val Loss: 0.7413, Val Accuracy: 84.91%\n",
      "Epoch 616/1000, Train Loss: 0.0978, Val Loss: 0.7409, Val Accuracy: 84.91%\n",
      "Epoch 617/1000, Train Loss: 0.0974, Val Loss: 0.7405, Val Accuracy: 84.91%\n",
      "Epoch 618/1000, Train Loss: 0.0971, Val Loss: 0.7401, Val Accuracy: 84.91%\n",
      "Epoch 619/1000, Train Loss: 0.0968, Val Loss: 0.7397, Val Accuracy: 84.91%\n",
      "Epoch 620/1000, Train Loss: 0.0964, Val Loss: 0.7393, Val Accuracy: 84.91%\n",
      "Epoch 621/1000, Train Loss: 0.0961, Val Loss: 0.7390, Val Accuracy: 84.91%\n",
      "Epoch 622/1000, Train Loss: 0.0957, Val Loss: 0.7386, Val Accuracy: 84.91%\n",
      "Epoch 623/1000, Train Loss: 0.0954, Val Loss: 0.7382, Val Accuracy: 84.91%\n",
      "Epoch 624/1000, Train Loss: 0.0951, Val Loss: 0.7378, Val Accuracy: 84.91%\n",
      "Epoch 625/1000, Train Loss: 0.0948, Val Loss: 0.7374, Val Accuracy: 84.91%\n",
      "Epoch 626/1000, Train Loss: 0.0944, Val Loss: 0.7371, Val Accuracy: 84.91%\n",
      "Epoch 627/1000, Train Loss: 0.0941, Val Loss: 0.7367, Val Accuracy: 84.91%\n",
      "Epoch 628/1000, Train Loss: 0.0938, Val Loss: 0.7363, Val Accuracy: 84.91%\n",
      "Epoch 629/1000, Train Loss: 0.0935, Val Loss: 0.7360, Val Accuracy: 84.91%\n",
      "Epoch 630/1000, Train Loss: 0.0931, Val Loss: 0.7356, Val Accuracy: 84.91%\n",
      "Epoch 631/1000, Train Loss: 0.0928, Val Loss: 0.7353, Val Accuracy: 84.91%\n",
      "Epoch 632/1000, Train Loss: 0.0925, Val Loss: 0.7349, Val Accuracy: 84.91%\n",
      "Epoch 633/1000, Train Loss: 0.0922, Val Loss: 0.7345, Val Accuracy: 84.91%\n",
      "Epoch 634/1000, Train Loss: 0.0919, Val Loss: 0.7342, Val Accuracy: 84.91%\n",
      "Epoch 635/1000, Train Loss: 0.0916, Val Loss: 0.7338, Val Accuracy: 84.91%\n",
      "Epoch 636/1000, Train Loss: 0.0913, Val Loss: 0.7335, Val Accuracy: 84.91%\n",
      "Epoch 637/1000, Train Loss: 0.0910, Val Loss: 0.7332, Val Accuracy: 84.91%\n",
      "Epoch 638/1000, Train Loss: 0.0907, Val Loss: 0.7328, Val Accuracy: 84.91%\n",
      "Epoch 639/1000, Train Loss: 0.0904, Val Loss: 0.7325, Val Accuracy: 84.91%\n",
      "Epoch 640/1000, Train Loss: 0.0901, Val Loss: 0.7321, Val Accuracy: 84.91%\n",
      "Epoch 641/1000, Train Loss: 0.0898, Val Loss: 0.7318, Val Accuracy: 84.91%\n",
      "Epoch 642/1000, Train Loss: 0.0895, Val Loss: 0.7314, Val Accuracy: 84.91%\n",
      "Epoch 643/1000, Train Loss: 0.0892, Val Loss: 0.7311, Val Accuracy: 84.91%\n",
      "Epoch 644/1000, Train Loss: 0.0889, Val Loss: 0.7308, Val Accuracy: 84.91%\n",
      "Epoch 645/1000, Train Loss: 0.0886, Val Loss: 0.7305, Val Accuracy: 84.91%\n",
      "Epoch 646/1000, Train Loss: 0.0883, Val Loss: 0.7301, Val Accuracy: 84.91%\n",
      "Epoch 647/1000, Train Loss: 0.0880, Val Loss: 0.7298, Val Accuracy: 84.91%\n",
      "Epoch 648/1000, Train Loss: 0.0877, Val Loss: 0.7295, Val Accuracy: 84.91%\n",
      "Epoch 649/1000, Train Loss: 0.0874, Val Loss: 0.7292, Val Accuracy: 84.91%\n",
      "Epoch 650/1000, Train Loss: 0.0871, Val Loss: 0.7288, Val Accuracy: 84.91%\n",
      "Epoch 651/1000, Train Loss: 0.0869, Val Loss: 0.7285, Val Accuracy: 84.91%\n",
      "Epoch 652/1000, Train Loss: 0.0866, Val Loss: 0.7282, Val Accuracy: 84.91%\n",
      "Epoch 653/1000, Train Loss: 0.0863, Val Loss: 0.7279, Val Accuracy: 84.91%\n",
      "Epoch 654/1000, Train Loss: 0.0860, Val Loss: 0.7276, Val Accuracy: 84.91%\n",
      "Epoch 655/1000, Train Loss: 0.0857, Val Loss: 0.7273, Val Accuracy: 84.91%\n",
      "Epoch 656/1000, Train Loss: 0.0855, Val Loss: 0.7270, Val Accuracy: 84.91%\n",
      "Epoch 657/1000, Train Loss: 0.0852, Val Loss: 0.7266, Val Accuracy: 84.91%\n",
      "Epoch 658/1000, Train Loss: 0.0849, Val Loss: 0.7263, Val Accuracy: 84.91%\n",
      "Epoch 659/1000, Train Loss: 0.0847, Val Loss: 0.7260, Val Accuracy: 84.91%\n",
      "Epoch 660/1000, Train Loss: 0.0844, Val Loss: 0.7257, Val Accuracy: 84.91%\n",
      "Epoch 661/1000, Train Loss: 0.0841, Val Loss: 0.7254, Val Accuracy: 84.91%\n",
      "Epoch 662/1000, Train Loss: 0.0839, Val Loss: 0.7251, Val Accuracy: 84.91%\n",
      "Epoch 663/1000, Train Loss: 0.0836, Val Loss: 0.7248, Val Accuracy: 84.91%\n",
      "Epoch 664/1000, Train Loss: 0.0833, Val Loss: 0.7245, Val Accuracy: 85.53%\n",
      "Epoch 665/1000, Train Loss: 0.0831, Val Loss: 0.7243, Val Accuracy: 85.53%\n",
      "Epoch 666/1000, Train Loss: 0.0828, Val Loss: 0.7240, Val Accuracy: 85.53%\n",
      "Epoch 667/1000, Train Loss: 0.0825, Val Loss: 0.7237, Val Accuracy: 85.53%\n",
      "Epoch 668/1000, Train Loss: 0.0823, Val Loss: 0.7234, Val Accuracy: 85.53%\n",
      "Epoch 669/1000, Train Loss: 0.0820, Val Loss: 0.7231, Val Accuracy: 85.53%\n",
      "Epoch 670/1000, Train Loss: 0.0818, Val Loss: 0.7228, Val Accuracy: 85.53%\n",
      "Epoch 671/1000, Train Loss: 0.0815, Val Loss: 0.7225, Val Accuracy: 85.53%\n",
      "Epoch 672/1000, Train Loss: 0.0813, Val Loss: 0.7222, Val Accuracy: 85.53%\n",
      "Epoch 673/1000, Train Loss: 0.0810, Val Loss: 0.7220, Val Accuracy: 85.53%\n",
      "Epoch 674/1000, Train Loss: 0.0808, Val Loss: 0.7217, Val Accuracy: 85.53%\n",
      "Epoch 675/1000, Train Loss: 0.0805, Val Loss: 0.7214, Val Accuracy: 85.53%\n",
      "Epoch 676/1000, Train Loss: 0.0803, Val Loss: 0.7211, Val Accuracy: 85.53%\n",
      "Epoch 677/1000, Train Loss: 0.0800, Val Loss: 0.7209, Val Accuracy: 85.53%\n",
      "Epoch 678/1000, Train Loss: 0.0798, Val Loss: 0.7206, Val Accuracy: 85.53%\n",
      "Epoch 679/1000, Train Loss: 0.0795, Val Loss: 0.7203, Val Accuracy: 85.53%\n",
      "Epoch 680/1000, Train Loss: 0.0793, Val Loss: 0.7200, Val Accuracy: 85.53%\n",
      "Epoch 681/1000, Train Loss: 0.0790, Val Loss: 0.7198, Val Accuracy: 85.53%\n",
      "Epoch 682/1000, Train Loss: 0.0788, Val Loss: 0.7195, Val Accuracy: 85.53%\n",
      "Epoch 683/1000, Train Loss: 0.0786, Val Loss: 0.7192, Val Accuracy: 85.53%\n",
      "Epoch 684/1000, Train Loss: 0.0783, Val Loss: 0.7190, Val Accuracy: 85.53%\n",
      "Epoch 685/1000, Train Loss: 0.0781, Val Loss: 0.7187, Val Accuracy: 85.53%\n",
      "Epoch 686/1000, Train Loss: 0.0778, Val Loss: 0.7185, Val Accuracy: 85.53%\n",
      "Epoch 687/1000, Train Loss: 0.0776, Val Loss: 0.7182, Val Accuracy: 85.53%\n",
      "Epoch 688/1000, Train Loss: 0.0774, Val Loss: 0.7180, Val Accuracy: 85.53%\n",
      "Epoch 689/1000, Train Loss: 0.0771, Val Loss: 0.7177, Val Accuracy: 85.53%\n",
      "Epoch 690/1000, Train Loss: 0.0769, Val Loss: 0.7174, Val Accuracy: 85.53%\n",
      "Epoch 691/1000, Train Loss: 0.0767, Val Loss: 0.7172, Val Accuracy: 85.53%\n",
      "Epoch 692/1000, Train Loss: 0.0765, Val Loss: 0.7169, Val Accuracy: 85.53%\n",
      "Epoch 693/1000, Train Loss: 0.0762, Val Loss: 0.7167, Val Accuracy: 85.53%\n",
      "Epoch 694/1000, Train Loss: 0.0760, Val Loss: 0.7164, Val Accuracy: 85.53%\n",
      "Epoch 695/1000, Train Loss: 0.0758, Val Loss: 0.7162, Val Accuracy: 85.53%\n",
      "Epoch 696/1000, Train Loss: 0.0756, Val Loss: 0.7160, Val Accuracy: 85.53%\n",
      "Epoch 697/1000, Train Loss: 0.0753, Val Loss: 0.7157, Val Accuracy: 85.53%\n",
      "Epoch 698/1000, Train Loss: 0.0751, Val Loss: 0.7155, Val Accuracy: 85.53%\n",
      "Epoch 699/1000, Train Loss: 0.0749, Val Loss: 0.7152, Val Accuracy: 85.53%\n",
      "Epoch 700/1000, Train Loss: 0.0747, Val Loss: 0.7150, Val Accuracy: 85.53%\n",
      "Epoch 701/1000, Train Loss: 0.0744, Val Loss: 0.7148, Val Accuracy: 85.53%\n",
      "Epoch 702/1000, Train Loss: 0.0742, Val Loss: 0.7145, Val Accuracy: 85.53%\n",
      "Epoch 703/1000, Train Loss: 0.0740, Val Loss: 0.7143, Val Accuracy: 85.53%\n",
      "Epoch 704/1000, Train Loss: 0.0738, Val Loss: 0.7141, Val Accuracy: 85.53%\n",
      "Epoch 705/1000, Train Loss: 0.0736, Val Loss: 0.7138, Val Accuracy: 85.53%\n",
      "Epoch 706/1000, Train Loss: 0.0734, Val Loss: 0.7136, Val Accuracy: 85.53%\n",
      "Epoch 707/1000, Train Loss: 0.0732, Val Loss: 0.7134, Val Accuracy: 85.53%\n",
      "Epoch 708/1000, Train Loss: 0.0729, Val Loss: 0.7132, Val Accuracy: 85.53%\n",
      "Epoch 709/1000, Train Loss: 0.0727, Val Loss: 0.7129, Val Accuracy: 85.53%\n",
      "Epoch 710/1000, Train Loss: 0.0725, Val Loss: 0.7127, Val Accuracy: 85.53%\n",
      "Epoch 711/1000, Train Loss: 0.0723, Val Loss: 0.7125, Val Accuracy: 85.53%\n",
      "Epoch 712/1000, Train Loss: 0.0721, Val Loss: 0.7123, Val Accuracy: 85.53%\n",
      "Epoch 713/1000, Train Loss: 0.0719, Val Loss: 0.7121, Val Accuracy: 85.53%\n",
      "Epoch 714/1000, Train Loss: 0.0717, Val Loss: 0.7118, Val Accuracy: 85.53%\n",
      "Epoch 715/1000, Train Loss: 0.0715, Val Loss: 0.7116, Val Accuracy: 85.53%\n",
      "Epoch 716/1000, Train Loss: 0.0713, Val Loss: 0.7114, Val Accuracy: 85.53%\n",
      "Epoch 717/1000, Train Loss: 0.0711, Val Loss: 0.7112, Val Accuracy: 85.53%\n",
      "Epoch 718/1000, Train Loss: 0.0709, Val Loss: 0.7110, Val Accuracy: 85.53%\n",
      "Epoch 719/1000, Train Loss: 0.0707, Val Loss: 0.7108, Val Accuracy: 85.53%\n",
      "Epoch 720/1000, Train Loss: 0.0705, Val Loss: 0.7106, Val Accuracy: 85.53%\n",
      "Epoch 721/1000, Train Loss: 0.0703, Val Loss: 0.7104, Val Accuracy: 85.53%\n",
      "Epoch 722/1000, Train Loss: 0.0701, Val Loss: 0.7101, Val Accuracy: 85.53%\n",
      "Epoch 723/1000, Train Loss: 0.0699, Val Loss: 0.7099, Val Accuracy: 85.53%\n",
      "Epoch 724/1000, Train Loss: 0.0697, Val Loss: 0.7097, Val Accuracy: 85.53%\n",
      "Epoch 725/1000, Train Loss: 0.0695, Val Loss: 0.7095, Val Accuracy: 85.53%\n",
      "Epoch 726/1000, Train Loss: 0.0693, Val Loss: 0.7093, Val Accuracy: 85.53%\n",
      "Epoch 727/1000, Train Loss: 0.0691, Val Loss: 0.7091, Val Accuracy: 85.53%\n",
      "Epoch 728/1000, Train Loss: 0.0689, Val Loss: 0.7089, Val Accuracy: 85.53%\n",
      "Epoch 729/1000, Train Loss: 0.0687, Val Loss: 0.7087, Val Accuracy: 85.53%\n",
      "Epoch 730/1000, Train Loss: 0.0685, Val Loss: 0.7085, Val Accuracy: 85.53%\n",
      "Epoch 731/1000, Train Loss: 0.0683, Val Loss: 0.7083, Val Accuracy: 85.53%\n",
      "Epoch 732/1000, Train Loss: 0.0681, Val Loss: 0.7081, Val Accuracy: 85.53%\n",
      "Epoch 733/1000, Train Loss: 0.0679, Val Loss: 0.7080, Val Accuracy: 85.53%\n",
      "Epoch 734/1000, Train Loss: 0.0678, Val Loss: 0.7078, Val Accuracy: 85.53%\n",
      "Epoch 735/1000, Train Loss: 0.0676, Val Loss: 0.7076, Val Accuracy: 85.53%\n",
      "Epoch 736/1000, Train Loss: 0.0674, Val Loss: 0.7074, Val Accuracy: 85.53%\n",
      "Epoch 737/1000, Train Loss: 0.0672, Val Loss: 0.7072, Val Accuracy: 85.53%\n",
      "Epoch 738/1000, Train Loss: 0.0670, Val Loss: 0.7070, Val Accuracy: 85.53%\n",
      "Epoch 739/1000, Train Loss: 0.0668, Val Loss: 0.7068, Val Accuracy: 85.53%\n",
      "Epoch 740/1000, Train Loss: 0.0666, Val Loss: 0.7066, Val Accuracy: 85.53%\n",
      "Epoch 741/1000, Train Loss: 0.0665, Val Loss: 0.7065, Val Accuracy: 85.53%\n",
      "Epoch 742/1000, Train Loss: 0.0663, Val Loss: 0.7063, Val Accuracy: 85.53%\n",
      "Epoch 743/1000, Train Loss: 0.0661, Val Loss: 0.7061, Val Accuracy: 85.53%\n",
      "Epoch 744/1000, Train Loss: 0.0659, Val Loss: 0.7059, Val Accuracy: 85.53%\n",
      "Epoch 745/1000, Train Loss: 0.0657, Val Loss: 0.7057, Val Accuracy: 85.53%\n",
      "Epoch 746/1000, Train Loss: 0.0656, Val Loss: 0.7056, Val Accuracy: 85.53%\n",
      "Epoch 747/1000, Train Loss: 0.0654, Val Loss: 0.7054, Val Accuracy: 85.53%\n",
      "Epoch 748/1000, Train Loss: 0.0652, Val Loss: 0.7052, Val Accuracy: 85.53%\n",
      "Epoch 749/1000, Train Loss: 0.0650, Val Loss: 0.7050, Val Accuracy: 85.53%\n",
      "Epoch 750/1000, Train Loss: 0.0648, Val Loss: 0.7049, Val Accuracy: 85.53%\n",
      "Epoch 751/1000, Train Loss: 0.0647, Val Loss: 0.7047, Val Accuracy: 85.53%\n",
      "Epoch 752/1000, Train Loss: 0.0645, Val Loss: 0.7045, Val Accuracy: 85.53%\n",
      "Epoch 753/1000, Train Loss: 0.0643, Val Loss: 0.7044, Val Accuracy: 85.53%\n",
      "Epoch 754/1000, Train Loss: 0.0641, Val Loss: 0.7042, Val Accuracy: 85.53%\n",
      "Epoch 755/1000, Train Loss: 0.0640, Val Loss: 0.7040, Val Accuracy: 85.53%\n",
      "Epoch 756/1000, Train Loss: 0.0638, Val Loss: 0.7039, Val Accuracy: 85.53%\n",
      "Epoch 757/1000, Train Loss: 0.0636, Val Loss: 0.7037, Val Accuracy: 85.53%\n",
      "Epoch 758/1000, Train Loss: 0.0635, Val Loss: 0.7036, Val Accuracy: 85.53%\n",
      "Epoch 759/1000, Train Loss: 0.0633, Val Loss: 0.7034, Val Accuracy: 85.53%\n",
      "Epoch 760/1000, Train Loss: 0.0631, Val Loss: 0.7032, Val Accuracy: 85.53%\n",
      "Epoch 761/1000, Train Loss: 0.0630, Val Loss: 0.7031, Val Accuracy: 85.53%\n",
      "Epoch 762/1000, Train Loss: 0.0628, Val Loss: 0.7029, Val Accuracy: 85.53%\n",
      "Epoch 763/1000, Train Loss: 0.0626, Val Loss: 0.7028, Val Accuracy: 85.53%\n",
      "Epoch 764/1000, Train Loss: 0.0625, Val Loss: 0.7026, Val Accuracy: 85.53%\n",
      "Epoch 765/1000, Train Loss: 0.0623, Val Loss: 0.7025, Val Accuracy: 85.53%\n",
      "Epoch 766/1000, Train Loss: 0.0621, Val Loss: 0.7023, Val Accuracy: 85.53%\n",
      "Epoch 767/1000, Train Loss: 0.0620, Val Loss: 0.7022, Val Accuracy: 85.53%\n",
      "Epoch 768/1000, Train Loss: 0.0618, Val Loss: 0.7020, Val Accuracy: 85.53%\n",
      "Epoch 769/1000, Train Loss: 0.0616, Val Loss: 0.7019, Val Accuracy: 85.53%\n",
      "Epoch 770/1000, Train Loss: 0.0615, Val Loss: 0.7017, Val Accuracy: 85.53%\n",
      "Epoch 771/1000, Train Loss: 0.0613, Val Loss: 0.7016, Val Accuracy: 85.53%\n",
      "Epoch 772/1000, Train Loss: 0.0612, Val Loss: 0.7014, Val Accuracy: 85.53%\n",
      "Epoch 773/1000, Train Loss: 0.0610, Val Loss: 0.7013, Val Accuracy: 85.53%\n",
      "Epoch 774/1000, Train Loss: 0.0608, Val Loss: 0.7012, Val Accuracy: 85.53%\n",
      "Epoch 775/1000, Train Loss: 0.0607, Val Loss: 0.7010, Val Accuracy: 85.53%\n",
      "Epoch 776/1000, Train Loss: 0.0605, Val Loss: 0.7009, Val Accuracy: 85.53%\n",
      "Epoch 777/1000, Train Loss: 0.0604, Val Loss: 0.7008, Val Accuracy: 85.53%\n",
      "Epoch 778/1000, Train Loss: 0.0602, Val Loss: 0.7006, Val Accuracy: 85.53%\n",
      "Epoch 779/1000, Train Loss: 0.0600, Val Loss: 0.7005, Val Accuracy: 86.16%\n",
      "Epoch 780/1000, Train Loss: 0.0599, Val Loss: 0.7004, Val Accuracy: 86.16%\n",
      "Epoch 781/1000, Train Loss: 0.0597, Val Loss: 0.7002, Val Accuracy: 86.16%\n",
      "Epoch 782/1000, Train Loss: 0.0596, Val Loss: 0.7001, Val Accuracy: 86.16%\n",
      "Epoch 783/1000, Train Loss: 0.0594, Val Loss: 0.7000, Val Accuracy: 86.16%\n",
      "Epoch 784/1000, Train Loss: 0.0593, Val Loss: 0.6999, Val Accuracy: 86.16%\n",
      "Epoch 785/1000, Train Loss: 0.0591, Val Loss: 0.6997, Val Accuracy: 86.16%\n",
      "Epoch 786/1000, Train Loss: 0.0590, Val Loss: 0.6996, Val Accuracy: 86.16%\n",
      "Epoch 787/1000, Train Loss: 0.0588, Val Loss: 0.6995, Val Accuracy: 86.16%\n",
      "Epoch 788/1000, Train Loss: 0.0587, Val Loss: 0.6994, Val Accuracy: 86.16%\n",
      "Epoch 789/1000, Train Loss: 0.0585, Val Loss: 0.6993, Val Accuracy: 86.16%\n",
      "Epoch 790/1000, Train Loss: 0.0584, Val Loss: 0.6991, Val Accuracy: 86.16%\n",
      "Epoch 791/1000, Train Loss: 0.0582, Val Loss: 0.6990, Val Accuracy: 86.16%\n",
      "Epoch 792/1000, Train Loss: 0.0581, Val Loss: 0.6989, Val Accuracy: 86.16%\n",
      "Epoch 793/1000, Train Loss: 0.0579, Val Loss: 0.6988, Val Accuracy: 86.16%\n",
      "Epoch 794/1000, Train Loss: 0.0578, Val Loss: 0.6987, Val Accuracy: 86.16%\n",
      "Epoch 795/1000, Train Loss: 0.0576, Val Loss: 0.6986, Val Accuracy: 86.16%\n",
      "Epoch 796/1000, Train Loss: 0.0575, Val Loss: 0.6984, Val Accuracy: 86.16%\n",
      "Epoch 797/1000, Train Loss: 0.0573, Val Loss: 0.6983, Val Accuracy: 86.16%\n",
      "Epoch 798/1000, Train Loss: 0.0572, Val Loss: 0.6982, Val Accuracy: 86.16%\n",
      "Epoch 799/1000, Train Loss: 0.0571, Val Loss: 0.6981, Val Accuracy: 86.16%\n",
      "Epoch 800/1000, Train Loss: 0.0569, Val Loss: 0.6980, Val Accuracy: 86.16%\n",
      "Epoch 801/1000, Train Loss: 0.0568, Val Loss: 0.6979, Val Accuracy: 86.16%\n",
      "Epoch 802/1000, Train Loss: 0.0566, Val Loss: 0.6978, Val Accuracy: 86.16%\n",
      "Epoch 803/1000, Train Loss: 0.0565, Val Loss: 0.6977, Val Accuracy: 86.16%\n",
      "Epoch 804/1000, Train Loss: 0.0563, Val Loss: 0.6976, Val Accuracy: 86.16%\n",
      "Epoch 805/1000, Train Loss: 0.0562, Val Loss: 0.6975, Val Accuracy: 86.16%\n",
      "Epoch 806/1000, Train Loss: 0.0561, Val Loss: 0.6974, Val Accuracy: 86.16%\n",
      "Epoch 807/1000, Train Loss: 0.0559, Val Loss: 0.6973, Val Accuracy: 86.16%\n",
      "Epoch 808/1000, Train Loss: 0.0558, Val Loss: 0.6972, Val Accuracy: 86.16%\n",
      "Epoch 809/1000, Train Loss: 0.0556, Val Loss: 0.6971, Val Accuracy: 86.16%\n",
      "Epoch 810/1000, Train Loss: 0.0555, Val Loss: 0.6970, Val Accuracy: 86.16%\n",
      "Epoch 811/1000, Train Loss: 0.0554, Val Loss: 0.6969, Val Accuracy: 86.16%\n",
      "Epoch 812/1000, Train Loss: 0.0552, Val Loss: 0.6968, Val Accuracy: 86.16%\n",
      "Epoch 813/1000, Train Loss: 0.0551, Val Loss: 0.6967, Val Accuracy: 86.16%\n",
      "Epoch 814/1000, Train Loss: 0.0550, Val Loss: 0.6966, Val Accuracy: 86.16%\n",
      "Epoch 815/1000, Train Loss: 0.0548, Val Loss: 0.6966, Val Accuracy: 86.16%\n",
      "Epoch 816/1000, Train Loss: 0.0547, Val Loss: 0.6965, Val Accuracy: 86.16%\n",
      "Epoch 817/1000, Train Loss: 0.0546, Val Loss: 0.6964, Val Accuracy: 86.16%\n",
      "Epoch 818/1000, Train Loss: 0.0544, Val Loss: 0.6963, Val Accuracy: 86.16%\n",
      "Epoch 819/1000, Train Loss: 0.0543, Val Loss: 0.6962, Val Accuracy: 86.16%\n",
      "Epoch 820/1000, Train Loss: 0.0542, Val Loss: 0.6961, Val Accuracy: 86.16%\n",
      "Epoch 821/1000, Train Loss: 0.0540, Val Loss: 0.6960, Val Accuracy: 86.16%\n",
      "Epoch 822/1000, Train Loss: 0.0539, Val Loss: 0.6960, Val Accuracy: 86.16%\n",
      "Epoch 823/1000, Train Loss: 0.0538, Val Loss: 0.6959, Val Accuracy: 86.16%\n",
      "Epoch 824/1000, Train Loss: 0.0536, Val Loss: 0.6958, Val Accuracy: 86.16%\n",
      "Epoch 825/1000, Train Loss: 0.0535, Val Loss: 0.6957, Val Accuracy: 86.16%\n",
      "Epoch 826/1000, Train Loss: 0.0534, Val Loss: 0.6956, Val Accuracy: 86.16%\n",
      "Epoch 827/1000, Train Loss: 0.0532, Val Loss: 0.6956, Val Accuracy: 86.16%\n",
      "Epoch 828/1000, Train Loss: 0.0531, Val Loss: 0.6955, Val Accuracy: 86.16%\n",
      "Epoch 829/1000, Train Loss: 0.0530, Val Loss: 0.6954, Val Accuracy: 86.16%\n",
      "Epoch 830/1000, Train Loss: 0.0528, Val Loss: 0.6953, Val Accuracy: 86.16%\n",
      "Epoch 831/1000, Train Loss: 0.0527, Val Loss: 0.6953, Val Accuracy: 86.16%\n",
      "Epoch 832/1000, Train Loss: 0.0526, Val Loss: 0.6952, Val Accuracy: 86.16%\n",
      "Epoch 833/1000, Train Loss: 0.0525, Val Loss: 0.6951, Val Accuracy: 86.16%\n",
      "Epoch 834/1000, Train Loss: 0.0523, Val Loss: 0.6950, Val Accuracy: 86.16%\n",
      "Epoch 835/1000, Train Loss: 0.0522, Val Loss: 0.6950, Val Accuracy: 86.16%\n",
      "Epoch 836/1000, Train Loss: 0.0521, Val Loss: 0.6949, Val Accuracy: 86.16%\n",
      "Epoch 837/1000, Train Loss: 0.0520, Val Loss: 0.6948, Val Accuracy: 86.16%\n",
      "Epoch 838/1000, Train Loss: 0.0518, Val Loss: 0.6948, Val Accuracy: 86.16%\n",
      "Epoch 839/1000, Train Loss: 0.0517, Val Loss: 0.6947, Val Accuracy: 86.16%\n",
      "Epoch 840/1000, Train Loss: 0.0516, Val Loss: 0.6946, Val Accuracy: 86.16%\n",
      "Epoch 841/1000, Train Loss: 0.0515, Val Loss: 0.6946, Val Accuracy: 86.16%\n",
      "Epoch 842/1000, Train Loss: 0.0513, Val Loss: 0.6945, Val Accuracy: 86.16%\n",
      "Epoch 843/1000, Train Loss: 0.0512, Val Loss: 0.6944, Val Accuracy: 86.16%\n",
      "Epoch 844/1000, Train Loss: 0.0511, Val Loss: 0.6944, Val Accuracy: 86.16%\n",
      "Epoch 845/1000, Train Loss: 0.0510, Val Loss: 0.6943, Val Accuracy: 86.16%\n",
      "Epoch 846/1000, Train Loss: 0.0509, Val Loss: 0.6943, Val Accuracy: 86.16%\n",
      "Epoch 847/1000, Train Loss: 0.0507, Val Loss: 0.6942, Val Accuracy: 86.16%\n",
      "Epoch 848/1000, Train Loss: 0.0506, Val Loss: 0.6941, Val Accuracy: 86.16%\n",
      "Epoch 849/1000, Train Loss: 0.0505, Val Loss: 0.6941, Val Accuracy: 86.16%\n",
      "Epoch 850/1000, Train Loss: 0.0504, Val Loss: 0.6940, Val Accuracy: 86.16%\n",
      "Epoch 851/1000, Train Loss: 0.0503, Val Loss: 0.6940, Val Accuracy: 86.16%\n",
      "Epoch 852/1000, Train Loss: 0.0501, Val Loss: 0.6939, Val Accuracy: 86.16%\n",
      "Epoch 853/1000, Train Loss: 0.0500, Val Loss: 0.6939, Val Accuracy: 86.16%\n",
      "Epoch 854/1000, Train Loss: 0.0499, Val Loss: 0.6938, Val Accuracy: 86.16%\n",
      "Epoch 855/1000, Train Loss: 0.0498, Val Loss: 0.6938, Val Accuracy: 86.16%\n",
      "Epoch 856/1000, Train Loss: 0.0497, Val Loss: 0.6937, Val Accuracy: 86.16%\n",
      "Epoch 857/1000, Train Loss: 0.0496, Val Loss: 0.6937, Val Accuracy: 86.16%\n",
      "Epoch 858/1000, Train Loss: 0.0494, Val Loss: 0.6936, Val Accuracy: 86.16%\n",
      "Epoch 859/1000, Train Loss: 0.0493, Val Loss: 0.6936, Val Accuracy: 86.16%\n",
      "Epoch 860/1000, Train Loss: 0.0492, Val Loss: 0.6935, Val Accuracy: 86.16%\n",
      "Epoch 861/1000, Train Loss: 0.0491, Val Loss: 0.6935, Val Accuracy: 86.16%\n",
      "Epoch 862/1000, Train Loss: 0.0490, Val Loss: 0.6935, Val Accuracy: 86.16%\n",
      "Epoch 863/1000, Train Loss: 0.0489, Val Loss: 0.6934, Val Accuracy: 86.16%\n",
      "Epoch 864/1000, Train Loss: 0.0487, Val Loss: 0.6934, Val Accuracy: 86.16%\n",
      "Epoch 865/1000, Train Loss: 0.0486, Val Loss: 0.6933, Val Accuracy: 86.16%\n",
      "Epoch 866/1000, Train Loss: 0.0485, Val Loss: 0.6933, Val Accuracy: 86.16%\n",
      "Epoch 867/1000, Train Loss: 0.0484, Val Loss: 0.6933, Val Accuracy: 86.16%\n",
      "Epoch 868/1000, Train Loss: 0.0483, Val Loss: 0.6932, Val Accuracy: 86.16%\n",
      "Epoch 869/1000, Train Loss: 0.0482, Val Loss: 0.6932, Val Accuracy: 86.16%\n",
      "Epoch 870/1000, Train Loss: 0.0481, Val Loss: 0.6931, Val Accuracy: 86.16%\n",
      "Epoch 871/1000, Train Loss: 0.0480, Val Loss: 0.6931, Val Accuracy: 86.16%\n",
      "Epoch 872/1000, Train Loss: 0.0479, Val Loss: 0.6931, Val Accuracy: 86.16%\n",
      "Epoch 873/1000, Train Loss: 0.0477, Val Loss: 0.6930, Val Accuracy: 86.16%\n",
      "Epoch 874/1000, Train Loss: 0.0476, Val Loss: 0.6930, Val Accuracy: 86.16%\n",
      "Epoch 875/1000, Train Loss: 0.0475, Val Loss: 0.6930, Val Accuracy: 86.16%\n",
      "Epoch 876/1000, Train Loss: 0.0474, Val Loss: 0.6930, Val Accuracy: 86.16%\n",
      "Epoch 877/1000, Train Loss: 0.0473, Val Loss: 0.6929, Val Accuracy: 86.16%\n",
      "Epoch 878/1000, Train Loss: 0.0472, Val Loss: 0.6929, Val Accuracy: 86.16%\n",
      "Epoch 879/1000, Train Loss: 0.0471, Val Loss: 0.6929, Val Accuracy: 86.16%\n",
      "Epoch 880/1000, Train Loss: 0.0470, Val Loss: 0.6928, Val Accuracy: 86.16%\n",
      "Epoch 881/1000, Train Loss: 0.0469, Val Loss: 0.6928, Val Accuracy: 86.16%\n",
      "Epoch 882/1000, Train Loss: 0.0468, Val Loss: 0.6928, Val Accuracy: 86.16%\n",
      "Epoch 883/1000, Train Loss: 0.0467, Val Loss: 0.6928, Val Accuracy: 86.16%\n",
      "Epoch 884/1000, Train Loss: 0.0466, Val Loss: 0.6927, Val Accuracy: 86.16%\n",
      "Epoch 885/1000, Train Loss: 0.0465, Val Loss: 0.6927, Val Accuracy: 86.16%\n",
      "Epoch 886/1000, Train Loss: 0.0463, Val Loss: 0.6927, Val Accuracy: 86.16%\n",
      "Epoch 887/1000, Train Loss: 0.0462, Val Loss: 0.6927, Val Accuracy: 86.16%\n",
      "Epoch 888/1000, Train Loss: 0.0461, Val Loss: 0.6927, Val Accuracy: 86.16%\n",
      "Epoch 889/1000, Train Loss: 0.0460, Val Loss: 0.6926, Val Accuracy: 86.16%\n",
      "Epoch 890/1000, Train Loss: 0.0459, Val Loss: 0.6926, Val Accuracy: 86.16%\n",
      "Epoch 891/1000, Train Loss: 0.0458, Val Loss: 0.6926, Val Accuracy: 86.16%\n",
      "Epoch 892/1000, Train Loss: 0.0457, Val Loss: 0.6926, Val Accuracy: 86.16%\n",
      "Epoch 893/1000, Train Loss: 0.0456, Val Loss: 0.6926, Val Accuracy: 86.16%\n",
      "Epoch 894/1000, Train Loss: 0.0455, Val Loss: 0.6925, Val Accuracy: 86.16%\n",
      "Epoch 895/1000, Train Loss: 0.0454, Val Loss: 0.6925, Val Accuracy: 86.16%\n",
      "Epoch 896/1000, Train Loss: 0.0453, Val Loss: 0.6925, Val Accuracy: 86.16%\n",
      "Epoch 897/1000, Train Loss: 0.0452, Val Loss: 0.6925, Val Accuracy: 86.16%\n",
      "Epoch 898/1000, Train Loss: 0.0451, Val Loss: 0.6925, Val Accuracy: 86.16%\n",
      "Epoch 899/1000, Train Loss: 0.0450, Val Loss: 0.6925, Val Accuracy: 86.16%\n",
      "Epoch 900/1000, Train Loss: 0.0449, Val Loss: 0.6925, Val Accuracy: 86.16%\n",
      "Epoch 901/1000, Train Loss: 0.0448, Val Loss: 0.6925, Val Accuracy: 86.16%\n",
      "Epoch 902/1000, Train Loss: 0.0447, Val Loss: 0.6924, Val Accuracy: 86.16%\n",
      "Epoch 903/1000, Train Loss: 0.0446, Val Loss: 0.6924, Val Accuracy: 86.16%\n",
      "Epoch 904/1000, Train Loss: 0.0445, Val Loss: 0.6924, Val Accuracy: 86.16%\n",
      "Epoch 905/1000, Train Loss: 0.0444, Val Loss: 0.6924, Val Accuracy: 86.16%\n",
      "Epoch 906/1000, Train Loss: 0.0443, Val Loss: 0.6924, Val Accuracy: 86.16%\n",
      "Epoch 907/1000, Train Loss: 0.0442, Val Loss: 0.6924, Val Accuracy: 86.16%\n",
      "Epoch 908/1000, Train Loss: 0.0441, Val Loss: 0.6924, Val Accuracy: 86.16%\n",
      "Epoch 909/1000, Train Loss: 0.0440, Val Loss: 0.6924, Val Accuracy: 86.16%\n",
      "Epoch 910/1000, Train Loss: 0.0439, Val Loss: 0.6924, Val Accuracy: 86.16%\n",
      "Epoch 911/1000, Train Loss: 0.0438, Val Loss: 0.6924, Val Accuracy: 86.16%\n",
      "Epoch 912/1000, Train Loss: 0.0437, Val Loss: 0.6924, Val Accuracy: 86.16%\n",
      "Epoch 913/1000, Train Loss: 0.0436, Val Loss: 0.6924, Val Accuracy: 86.16%\n",
      "Epoch 914/1000, Train Loss: 0.0435, Val Loss: 0.6924, Val Accuracy: 86.16%\n",
      "Epoch 915/1000, Train Loss: 0.0434, Val Loss: 0.6924, Val Accuracy: 86.16%\n",
      "Epoch 916/1000, Train Loss: 0.0433, Val Loss: 0.6924, Val Accuracy: 86.16%\n",
      "Epoch 917/1000, Train Loss: 0.0432, Val Loss: 0.6924, Val Accuracy: 86.16%\n",
      "Epoch 918/1000, Train Loss: 0.0431, Val Loss: 0.6924, Val Accuracy: 86.16%\n",
      "Epoch 919/1000, Train Loss: 0.0431, Val Loss: 0.6924, Val Accuracy: 86.16%\n",
      "Early stopping triggered.\n"
     ]
    }
   ],
   "source": [
    "# Define number of epochs and an optional early stopping patience\n",
    "EPOCHS = 1000\n",
    "patience = 5\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # Initialize train loss\n",
    "    train_loss = 0\n",
    "\n",
    "    # Training Phase\n",
    "    intent_model.train()\n",
    "    mlp_optimizer.zero_grad()\n",
    "    outputs = intent_model(X_train)\n",
    "    loss = mlp_criterion(outputs, y_train)\n",
    "    loss.backward()\n",
    "    mlp_optimizer.step()\n",
    "    train_loss = loss.item()  # Track train loss\n",
    "\n",
    "    # Validation Phase\n",
    "    intent_model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = intent_model(X_test)\n",
    "        val_loss = mlp_criterion(val_outputs, y_test)\n",
    "        val_predictions = torch.argmax(val_outputs, dim=1)\n",
    "        val_accuracy = (val_predictions == y_test).float().mean()\n",
    "\n",
    "    # Logging\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}, Train Loss: {train_loss:.4f}, \"\n",
    "          f\"Val Loss: {val_loss.item():.4f}, Val Accuracy: {val_accuracy.item() * 100:.2f}%\")\n",
    "\n",
    "    # Early Stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 86.16%\n",
      "Input: Hi, Predicted Intent: greeting\n",
      "Input: Hello, Predicted Intent: greeting\n",
      "Input: Howdy, Predicted Intent: greeting\n",
      "Input: Greetings, Predicted Intent: greeting\n",
      "Input: What's up?, Predicted Intent: greeting\n",
      "Input: Goodbye, Predicted Intent: goodbye\n",
      "Input: Thanks, Predicted Intent: salutaion\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model for intent classification\n",
    "intent_model.eval()\n",
    "outputs = intent_model(X_test)\n",
    "predictions = torch.argmax(outputs, dim=1)\n",
    "intent_accuracy = (predictions == y_test).float().mean()\n",
    "intent_result = intent_accuracy.item() * 100\n",
    "print(f\"Test Accuracy: {intent_result:.2f}%\")\n",
    "\n",
    "# Example Prediction\n",
    "sample_inputs = [\"Hi\", \"Hello\", \"Howdy\", \"Greetings\", \"What's up?\", \"Goodbye\", \"Thanks\"]\n",
    "for sample in sample_inputs:\n",
    "    sample_vector = vectorizer.transform([sample]).toarray()\n",
    "    sample_tensor = torch.tensor(sample_vector, dtype=torch.float32)\n",
    "    output = intent_model(sample_tensor)\n",
    "    predicted_label = idx2label[torch.argmax(output).item()]\n",
    "    print(f\"Input: {sample}, Predicted Intent: {predicted_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensor shape: torch.Size([2028, 20])\n",
      "Target tensor shape: torch.Size([2028, 20])\n"
     ]
    }
   ],
   "source": [
    "# Convert pairs to indices\n",
    "def convert_to_indices(pairs, word2idx):\n",
    "    input_indices = [\n",
    "        [word2idx.get(word, word2idx['<UNK>']) for word in inp.split()] for inp, _ in pairs\n",
    "    ]\n",
    "    target_indices = [\n",
    "        [word2idx.get(word, word2idx['<UNK>']) for word in out.split()] for _, out in pairs\n",
    "    ]\n",
    "    return input_indices, target_indices\n",
    "\n",
    "input_indices, target_indices = convert_to_indices(combined_pairs, word2idx)\n",
    "\n",
    "# Pad sequences\n",
    "input_tensors = pad_sequence(\n",
    "    [torch.tensor(seq[:TRUNCATE_LENGTH]) for seq in input_indices],\n",
    "    batch_first=True, padding_value=word2idx['<PAD>']\n",
    ")\n",
    "target_tensors = pad_sequence(\n",
    "    [torch.tensor(seq[:TRUNCATE_LENGTH]) for seq in target_indices],\n",
    "    batch_first=True, padding_value=word2idx['<PAD>']\n",
    ")\n",
    "\n",
    "# Create TensorDataset and DataLoader\n",
    "dataset = TensorDataset(input_tensors, target_tensors)\n",
    "data_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "print(f\"Input tensor shape: {input_tensors.shape}\")\n",
    "print(f\"Target tensor shape: {target_tensors.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hidden_dim, n_layers, dropout=0.3):\n",
    "        super(RNNEncoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.rnn = nn.LSTM(emb_dim, hidden_dim, n_layers, batch_first=True, dropout=dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        embedded = self.dropout(self.embedding(src))  # Embed input\n",
    "        encoder_outputs, (hidden, cell) = self.rnn(embedded)  # RNN forward pass\n",
    "        return encoder_outputs, (hidden, cell)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(Attention, self).__init__()\n",
    "        self.attn = nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "        self.v = nn.Parameter(torch.rand(hidden_dim))\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        batch_size, seq_len, hidden_dim = encoder_outputs.shape\n",
    "\n",
    "        # Expand hidden to match encoder_outputs\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, seq_len, 1)  # (batch_size, seq_len, hidden_dim)\n",
    "\n",
    "        # Compute energy scores\n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))  # (batch_size, seq_len, hidden_dim)\n",
    "        attention = torch.sum(self.v * energy, dim=2)  # (batch_size, seq_len)\n",
    "\n",
    "        # Normalize along sequence length\n",
    "        return torch.softmax(attention, dim=1)  # (batch_size, seq_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNDecoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hidden_dim, n_layers, dropout=0.3):\n",
    "        super(RNNDecoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.rnn = nn.LSTM(emb_dim + hidden_dim, hidden_dim, n_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc_out = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        self.attention = Attention(hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, trg, hidden, cell, encoder_outputs):\n",
    "        trg = trg.unsqueeze(1)  # Ensure trg has shape (batch_size, 1)\n",
    "        embedded = self.dropout(self.embedding(trg)).squeeze(2)  # Remove extra dimension\n",
    "\n",
    "        # Compute attention weights and context vector\n",
    "        attention_weights = self.attention(hidden[-1], encoder_outputs)  # (batch_size, seq_len)\n",
    "        attention_weights = attention_weights.unsqueeze(1)  # (batch_size, 1, seq_len)\n",
    "\n",
    "        context = torch.bmm(attention_weights, encoder_outputs)  # (batch_size, 1, hidden_dim)\n",
    "\n",
    "        # Concatenate embedded input and context vector\n",
    "        rnn_input = torch.cat((embedded, context), dim=2)  # (batch_size, 1, emb_dim + hidden_dim)\n",
    "\n",
    "        # Forward pass through RNN\n",
    "        outputs, (hidden, cell) = self.rnn(rnn_input, (hidden, cell))  # (batch_size, 1, hidden_dim)\n",
    "\n",
    "        # Generate predictions\n",
    "        predictions = self.fc_out(torch.cat((outputs.squeeze(1), context.squeeze(1)), dim=1))  # (batch_size, output_dim)\n",
    "        return predictions, hidden, cell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hidden_dim, kernel_size, dropout=0.5):\n",
    "        super(CNNEncoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.conv = nn.Conv1d(emb_dim, hidden_dim, kernel_size, padding=kernel_size//2)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        embedded = self.dropout(self.embedding(src))  # (batch_size, seq_len, emb_dim)\n",
    "        embedded = embedded.permute(0, 2, 1)  # (batch_size, emb_dim, seq_len)\n",
    "        conv_output = self.conv(embedded)  # (batch_size, hidden_dim, seq_len)\n",
    "        conv_output = conv_output.permute(0, 2, 1)  # Back to (batch_size, seq_len, hidden_dim)\n",
    "        return conv_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNDecoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hidden_dim, kernel_size, dropout=0.5):\n",
    "        super(CNNDecoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.conv = nn.Conv1d(\n",
    "            in_channels=emb_dim + hidden_dim,  # Concatenate embedded + encoder output\n",
    "            out_channels=hidden_dim,\n",
    "            kernel_size=kernel_size,\n",
    "            padding=kernel_size // 2  # Ensure output has the same sequence length\n",
    "        )\n",
    "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, trg, encoder_output):\n",
    "        # Fix trg shape\n",
    "        if trg.dim() == 2:  # Shape: (batch_size, seq_len)\n",
    "            trg = trg.unsqueeze(2)  # Add channel dimension: (batch_size, seq_len, 1)\n",
    "        elif trg.dim() == 3 and trg.size(2) != 1:\n",
    "            trg = trg[:, :, :1]  # Slice to retain only 1 channel\n",
    "\n",
    "        # Embed the target sequence\n",
    "        embedded = self.dropout(self.embedding(trg.squeeze(2)))  # (batch_size, seq_len, emb_dim)\n",
    "        embedded = embedded.permute(0, 2, 1)  # (batch_size, emb_dim, seq_len)\n",
    "\n",
    "        # Permute encoder_output to match channel dimension\n",
    "        encoder_output = encoder_output.permute(0, 2, 1)  # (batch_size, hidden_dim, seq_len)\n",
    "\n",
    "        # Ensure sequence length consistency\n",
    "        seq_len = max(embedded.size(2), encoder_output.size(2))\n",
    "        if encoder_output.size(2) < seq_len:\n",
    "            pad_size = seq_len - encoder_output.size(2)\n",
    "            encoder_output = torch.cat(\n",
    "                (encoder_output, torch.zeros(encoder_output.size(0), encoder_output.size(1), pad_size).to(encoder_output.device)),\n",
    "                dim=2,\n",
    "            )\n",
    "        elif embedded.size(2) < seq_len:\n",
    "            pad_size = seq_len - embedded.size(2)\n",
    "            embedded = torch.cat(\n",
    "                (embedded, torch.zeros(embedded.size(0), embedded.size(1), pad_size).to(embedded.device)),\n",
    "                dim=2,\n",
    "            )\n",
    "\n",
    "        # Concatenate along the feature dimension\n",
    "        combined = torch.cat((embedded, encoder_output), dim=1)  # (batch_size, emb_dim + hidden_dim, seq_len)\n",
    "\n",
    "        # Apply convolution\n",
    "        conv_output = torch.tanh(self.conv(combined))  # (batch_size, hidden_dim, seq_len)\n",
    "        conv_output = conv_output.permute(0, 2, 1)  # Back to (batch_size, seq_len, hidden_dim)\n",
    "\n",
    "        # Generate predictions\n",
    "        predictions = self.fc_out(conv_output)  # (batch_size, seq_len, output_dim)\n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(word2idx)\n",
    "OUTPUT_DIM = len(word2idx)\n",
    "\n",
    "# Models Initialization\n",
    "\n",
    "# RNN Models\n",
    "rnn_encoder = RNNEncoder(INPUT_DIM, EMB_DIM, HIDDEN_DIM, N_LAYERS)\n",
    "rnn_decoder = RNNDecoder(OUTPUT_DIM, EMB_DIM, HIDDEN_DIM, N_LAYERS)\n",
    "\n",
    "# CNN Models\n",
    "cnn_encoder = CNNEncoder(INPUT_DIM, EMB_DIM, HIDDEN_DIM, KERNEL_SIZE)\n",
    "cnn_decoder = CNNDecoder(OUTPUT_DIM, EMB_DIM, HIDDEN_DIM, KERNEL_SIZE)\n",
    "\n",
    "# Move to device\n",
    "rnn_encoder, rnn_decoder = rnn_encoder.to(device), rnn_decoder.to(device)\n",
    "cnn_encoder, cnn_decoder = cnn_encoder.to(device), cnn_decoder.to(device)\n",
    "\n",
    "# Optimizers\n",
    "rnn_enc_optimizer = optim.Adam(rnn_encoder.parameters(), lr=LR)\n",
    "rnn_dec_optimizer = optim.Adam(rnn_decoder.parameters(), lr=LR)\n",
    "cnn_enc_optimizer = optim.Adam(cnn_encoder.parameters(), lr=LR)\n",
    "cnn_dec_optimizer = optim.Adam(cnn_decoder.parameters(), lr=LR)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=word2idx['<PAD>'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_perplexity(loss):\n",
    "    return math.exp(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_bleu(model, dataset, word2idx, idx2word, max_len=10):\n",
    "    encoder, decoder = model\n",
    "    bleu_scores = []\n",
    "\n",
    "    for input_indices, target_indices in dataset:\n",
    "        # Convert target indices to words for reference\n",
    "        reference = [\n",
    "            [\n",
    "                idx2word[idx]\n",
    "                for idx in target_indices\n",
    "                if idx not in {word2idx['<PAD>'], word2idx['<SOS>'], word2idx['<EOS>']}\n",
    "            ]\n",
    "        ]\n",
    "\n",
    "        # Prepare input tensor\n",
    "        input_tensor = torch.tensor([input_indices]).to(device)\n",
    "\n",
    "        if isinstance(encoder, RNNEncoder):\n",
    "            # RNN Encoder: Get encoder_outputs and hidden states\n",
    "            encoder_outputs, (hidden, cell) = encoder(input_tensor)\n",
    "\n",
    "            # Decoder starts with <SOS>\n",
    "            decoder_input = torch.tensor([[word2idx['<SOS>']]]).to(device)\n",
    "            output_sentence = []\n",
    "\n",
    "            for _ in range(max_len):\n",
    "                outputs, hidden, cell = decoder(decoder_input, hidden, cell, encoder_outputs)\n",
    "                prediction = outputs.argmax(1)  # Get the next word index\n",
    "                next_word = idx2word[prediction.item()]\n",
    "                if next_word == '<EOS>':\n",
    "                    break\n",
    "                output_sentence.append(next_word)\n",
    "                decoder_input = prediction.unsqueeze(0)  # Update decoder input\n",
    "\n",
    "        elif isinstance(encoder, CNNEncoder):\n",
    "            # CNN Encoder: Get only encoder_outputs\n",
    "            encoder_outputs = encoder(input_tensor)\n",
    "\n",
    "            # Decoder starts with <SOS>\n",
    "            decoder_input = torch.tensor([[word2idx['<SOS>']]]).to(device)\n",
    "            output_sentence = []\n",
    "\n",
    "            for _ in range(max_len):\n",
    "                outputs = decoder(decoder_input, encoder_outputs)\n",
    "                prediction = outputs.argmax(2)  # Shape: (batch_size, 1)\n",
    "                next_word_idx = prediction[0, 0].item()  # Extract scalar index for the next word\n",
    "                next_word = idx2word[next_word_idx]\n",
    "                if next_word == '<EOS>':\n",
    "                    break\n",
    "                output_sentence.append(next_word)\n",
    "                decoder_input = prediction[0, 0].unsqueeze(0).unsqueeze(0)  # Update decoder input\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported encoder type!\")\n",
    "\n",
    "        # Compute BLEU score\n",
    "        bleu_score = sentence_bleu(reference, output_sentence, smoothing_function=SmoothingFunction().method1)\n",
    "        bleu_scores.append(bleu_score)\n",
    "\n",
    "    # Return average BLEU score\n",
    "    return sum(bleu_scores) / len(bleu_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare test dataset in index form\n",
    "# Convert tensors to numpy-compatible CPU tensors\n",
    "test_dataset = [\n",
    "    (input_indices.cpu().tolist(), target_indices.cpu().tolist())  # Use .tolist() to convert\n",
    "    for input_indices, target_indices in zip(input_tensors, target_tensors)\n",
    "]\n",
    "\n",
    "# Initialize or load metrics\n",
    "if os.path.exists(\"training_metrics.json\"):\n",
    "    with open(\"training_metrics.json\", \"r\") as f:\n",
    "        metrics = json.load(f)\n",
    "else:\n",
    "    metrics = {\"train_losses\": [], \"token_accuracy\": [], \"intent_accuracy\": [], \"bleu\": [], \"perplexity\": []}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics Initialization\n",
    "metrics = {\n",
    "    \"epoch\": [],\n",
    "    \"rnn_loss\": [],\n",
    "    \"cnn_loss\": [],\n",
    "    \"rnn_token_accuracy\": [],\n",
    "    \"cnn_token_accuracy\": [],\n",
    "    \"bleu_score_rnn\": [],\n",
    "    \"bleu_score_cnn\": [],\n",
    "    \"rnn_perplexity\": [],\n",
    "    \"cnn_perplexity\": [],\n",
    "}\n",
    "\n",
    "def save_metrics(metrics, filepath=\"training_metrics.json\"):\n",
    "    \"\"\"Save metrics to a JSON file.\"\"\"\n",
    "    with open(filepath, \"w\") as f:\n",
    "        json.dump(metrics, f, indent=4)\n",
    "\n",
    "def plot_metric(metrics, metric_key, title, ylabel):\n",
    "    \"\"\"Plot a metric over epochs.\"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(metrics[\"epoch\"], metrics[metric_key], marker=\"o\", label=title, color=\"blue\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"{metric_key}_curve.png\")  # Save the plot as an image\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 0/50...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "  Batch 2/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "  Batch 3/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.54s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 4/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "  Batch 5/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "  Batch 6/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.55s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "  Batch 7/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.53s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "  Batch 8/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.52s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "  Batch 9/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.52s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 10/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.52s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "  Batch 11/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.52s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "  Batch 12/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "  Batch 13/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.52s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "  Batch 14/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.54s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "  Batch 15/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.52s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 16/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.55s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "  Batch 17/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.53s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 18/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "  Batch 19/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.52s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "  Batch 20/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.55s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 21/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "  Batch 22/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.58s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 23/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 24/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "  Batch 25/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.53s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "  Batch 26/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.52s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "  Batch 27/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.57s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 28/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.53s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "  Batch 29/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "  Batch 30/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.57s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "  Batch 31/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.55s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "  Batch 32/32:\n",
      "    input_batch shape: torch.Size([44, 20])\n",
      "    target_batch shape: torch.Size([44, 20])\n",
      "    RNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([44, 19, 4590])\n",
      "    RNN Forward pass time: 0.48s\n",
      "    CNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([44, 20, 4590])\n",
      "    CNN Forward pass time: 0.04s\n",
      "Epoch 0/50 Completed | RNN Loss: 7.0032, CNN Loss: 7.1600, RNN Accuracy: 0.0152, CNN Accuracy: 0.0147, RNN Perplexity: 1100.1035, CNN Perplexity: 1286.8853, BLEU (RNN): 0.0075, BLEU (CNN): 0.0092, Time: 254.39s\n",
      "Starting Epoch 1/50...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.61s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 2/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 3/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.61s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 4/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 5/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 6/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 7/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.69s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 8/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 9/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.67s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 10/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.69s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 11/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.69s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 12/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.68s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 13/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 14/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 15/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 16/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 17/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 18/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 19/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.67s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 20/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.69s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 21/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.72s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.22s\n",
      "  Batch 22/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.68s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 23/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.71s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 24/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.92s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.16s\n",
      "  Batch 25/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.98s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.11s\n",
      "  Batch 26/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.89s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 27/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.84s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.11s\n",
      "  Batch 28/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.84s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.12s\n",
      "  Batch 29/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.88s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 30/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.76s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 31/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.76s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 32/32:\n",
      "    input_batch shape: torch.Size([44, 20])\n",
      "    target_batch shape: torch.Size([44, 20])\n",
      "    RNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([44, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([44, 20, 4590])\n",
      "    CNN Forward pass time: 0.05s\n",
      "Epoch 1/50 Completed | RNN Loss: 6.2860, CNN Loss: 6.1582, RNN Accuracy: 0.0173, CNN Accuracy: 0.0290, RNN Perplexity: 536.9787, CNN Perplexity: 472.5727, BLEU (RNN): 0.0105, BLEU (CNN): 0.0079, Time: 302.39s\n",
      "Starting Epoch 2/50...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.73s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 2/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.70s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 3/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.72s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 4/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.73s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 5/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.76s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 6/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.81s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 7/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.86s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.11s\n",
      "  Batch 8/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.89s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.11s\n",
      "  Batch 9/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.87s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.11s\n",
      "  Batch 10/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.98s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.11s\n",
      "  Batch 11/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.82s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 12/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.79s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 13/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.76s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 14/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.69s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 15/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.67s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 16/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.67s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 17/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 18/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.67s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 19/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.71s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 20/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.72s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 21/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.75s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 22/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.79s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 23/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.82s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 24/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.80s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 25/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.84s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 26/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.81s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 27/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.82s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 28/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.82s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 29/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.78s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 30/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.77s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 31/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.76s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 32/32:\n",
      "    input_batch shape: torch.Size([44, 20])\n",
      "    target_batch shape: torch.Size([44, 20])\n",
      "    RNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([44, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([44, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "Epoch 2/50 Completed | RNN Loss: 6.1153, CNN Loss: 5.7469, RNN Accuracy: 0.0198, CNN Accuracy: 0.0376, RNN Perplexity: 452.7421, CNN Perplexity: 313.2145, BLEU (RNN): 0.0088, BLEU (CNN): 0.0073, Time: 314.11s\n",
      "Starting Epoch 3/50...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.83s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 2/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.82s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 3/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.87s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 4/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.83s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 5/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.78s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.14s\n",
      "  Batch 6/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.80s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 7/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.80s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 8/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.80s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 9/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.80s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 10/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.75s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 11/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.76s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 12/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.75s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 13/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.74s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.11s\n",
      "  Batch 14/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.86s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.11s\n",
      "  Batch 15/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.92s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.12s\n",
      "  Batch 16/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.03s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.14s\n",
      "  Batch 17/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.16s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.15s\n",
      "  Batch 18/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.31s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.16s\n",
      "  Batch 19/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.14s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.12s\n",
      "  Batch 20/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.96s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 21/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.81s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 22/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.71s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 23/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.69s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 24/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 25/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.61s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 26/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 27/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.69s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 28/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.69s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 29/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.75s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 30/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.78s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 31/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.78s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.11s\n",
      "  Batch 32/32:\n",
      "    input_batch shape: torch.Size([44, 20])\n",
      "    target_batch shape: torch.Size([44, 20])\n",
      "    RNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([44, 19, 4590])\n",
      "    RNN Forward pass time: 0.74s\n",
      "    CNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([44, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "Epoch 3/50 Completed | RNN Loss: 5.9142, CNN Loss: 5.4059, RNN Accuracy: 0.0268, CNN Accuracy: 0.0450, RNN Perplexity: 370.2762, CNN Perplexity: 222.7137, BLEU (RNN): 0.0145, BLEU (CNN): 0.0070, Time: 322.49s\n",
      "Starting Epoch 4/50...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.08s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 2/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.80s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 3/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.78s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 4/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.70s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 5/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.70s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 6/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.69s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 7/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.70s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 8/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.70s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 9/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.70s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 10/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.69s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 11/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.71s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 12/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.77s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 13/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.77s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 14/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.80s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 15/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.81s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 16/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.80s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 17/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.79s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 18/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.82s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 19/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.83s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 20/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.82s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 21/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.76s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 22/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.76s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 23/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.74s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 24/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.77s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 25/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.77s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 26/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.75s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 27/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.76s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 28/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.75s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 29/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.76s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 30/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.75s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 31/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.75s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 32/32:\n",
      "    input_batch shape: torch.Size([44, 20])\n",
      "    target_batch shape: torch.Size([44, 20])\n",
      "    RNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([44, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([44, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "Epoch 4/50 Completed | RNN Loss: 5.6731, CNN Loss: 5.0121, RNN Accuracy: 0.0359, CNN Accuracy: 0.0577, RNN Perplexity: 290.9320, CNN Perplexity: 150.2162, BLEU (RNN): 0.0099, BLEU (CNN): 0.0076, Time: 320.23s\n",
      "Starting Epoch 5/50...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.80s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 2/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.76s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 3/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.79s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 4/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.74s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 5/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.70s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 6/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.70s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 7/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.68s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 8/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.69s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 9/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.68s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 10/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.82s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 11/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.70s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 12/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.74s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 13/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.90s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 14/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.78s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 15/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.79s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 16/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.82s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 17/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.77s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 18/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.77s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 19/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.75s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 20/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.77s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 21/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.68s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 22/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.67s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 23/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 24/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 25/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.70s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 26/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.75s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 27/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.74s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 28/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.78s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 29/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.78s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 30/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.80s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 31/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.79s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 32/32:\n",
      "    input_batch shape: torch.Size([44, 20])\n",
      "    target_batch shape: torch.Size([44, 20])\n",
      "    RNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([44, 19, 4590])\n",
      "    RNN Forward pass time: 0.70s\n",
      "    CNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([44, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "Epoch 5/50 Completed | RNN Loss: 5.4496, CNN Loss: 4.6430, RNN Accuracy: 0.0464, CNN Accuracy: 0.0752, RNN Perplexity: 232.6677, CNN Perplexity: 103.8507, BLEU (RNN): 0.0087, BLEU (CNN): 0.0077, Time: 308.89s\n",
      "Starting Epoch 6/50...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.73s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 2/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.73s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 3/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.81s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 4/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.82s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.11s\n",
      "  Batch 5/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.92s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.12s\n",
      "  Batch 6/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.00s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.13s\n",
      "  Batch 7/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.02s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.12s\n",
      "  Batch 8/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.01s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.11s\n",
      "  Batch 9/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.07s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 10/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.81s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 11/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.71s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 12/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.71s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 13/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.61s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 14/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.61s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 15/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 16/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 17/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 18/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.68s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 19/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.73s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 20/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.79s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 21/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.79s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 22/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.77s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 23/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.77s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 24/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.78s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 25/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.73s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 26/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.71s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 27/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.68s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 28/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.69s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 29/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.69s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 30/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.68s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 31/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.71s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 32/32:\n",
      "    input_batch shape: torch.Size([44, 20])\n",
      "    target_batch shape: torch.Size([44, 20])\n",
      "    RNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([44, 19, 4590])\n",
      "    RNN Forward pass time: 0.71s\n",
      "    CNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([44, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "Epoch 6/50 Completed | RNN Loss: 5.2254, CNN Loss: 4.2531, RNN Accuracy: 0.0583, CNN Accuracy: 0.0965, RNN Perplexity: 185.9288, CNN Perplexity: 70.3250, BLEU (RNN): 0.0110, BLEU (CNN): 0.0081, Time: 323.39s\n",
      "Starting Epoch 7/50...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.93s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 2/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.93s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.12s\n",
      "  Batch 3/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.12s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.13s\n",
      "  Batch 4/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.90s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 5/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.80s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 6/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.82s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 7/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.86s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 8/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.05s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.11s\n",
      "  Batch 9/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.85s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 10/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.83s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.11s\n",
      "  Batch 11/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.83s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 12/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.73s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 13/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.71s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 14/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.67s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 15/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.67s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 16/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.67s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 17/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.71s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 18/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.77s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 19/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.77s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 20/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.78s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 21/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.90s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 22/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.81s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 23/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.83s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 24/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.82s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 25/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.85s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 26/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.80s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 27/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.81s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 28/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.77s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.11s\n",
      "  Batch 29/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.74s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 30/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.71s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 31/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.70s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 32/32:\n",
      "    input_batch shape: torch.Size([44, 20])\n",
      "    target_batch shape: torch.Size([44, 20])\n",
      "    RNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([44, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([44, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "Epoch 7/50 Completed | RNN Loss: 5.0226, CNN Loss: 3.9747, RNN Accuracy: 0.0677, CNN Accuracy: 0.1198, RNN Perplexity: 151.8011, CNN Perplexity: 53.2335, BLEU (RNN): 0.0101, BLEU (CNN): 0.0094, Time: 324.18s\n",
      "Starting Epoch 8/50...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.71s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 2/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.69s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 3/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.72s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 4/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.68s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 5/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.69s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 6/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.69s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 7/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.71s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 8/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.72s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 9/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.80s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 10/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.77s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 11/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.76s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.11s\n",
      "  Batch 12/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.77s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 13/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.77s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 14/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.74s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 15/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.74s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 16/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.71s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 17/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.70s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 18/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.70s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 19/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.71s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 20/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.70s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 21/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.71s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 22/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.73s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 23/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.77s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 24/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.79s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 25/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.77s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 26/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.78s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 27/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.77s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 28/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.74s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 29/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.70s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 30/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.70s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 31/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.70s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 32/32:\n",
      "    input_batch shape: torch.Size([44, 20])\n",
      "    target_batch shape: torch.Size([44, 20])\n",
      "    RNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([44, 19, 4590])\n",
      "    RNN Forward pass time: 0.61s\n",
      "    CNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([44, 20, 4590])\n",
      "    CNN Forward pass time: 0.05s\n",
      "Epoch 8/50 Completed | RNN Loss: 4.8230, CNN Loss: 3.6946, RNN Accuracy: 0.0813, CNN Accuracy: 0.1399, RNN Perplexity: 124.3344, CNN Perplexity: 40.2299, BLEU (RNN): 0.0106, BLEU (CNN): 0.0099, Time: 320.61s\n",
      "Starting Epoch 9/50...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.71s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 2/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.67s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 3/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.68s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 4/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.84s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 5/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.68s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 6/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.95s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.13s\n",
      "  Batch 7/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.98s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 8/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.82s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 9/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 2.16s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.18s\n",
      "  Batch 10/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 2.27s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.18s\n",
      "  Batch 11/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.43s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.15s\n",
      "  Batch 12/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.06s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.12s\n",
      "  Batch 13/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.99s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 14/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.89s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.13s\n",
      "  Batch 15/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.75s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 16/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.71s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 17/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.79s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 18/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.67s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 19/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.74s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 20/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.73s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 21/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.83s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.11s\n",
      "  Batch 22/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.89s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.11s\n",
      "  Batch 23/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.17s\n",
      "  Batch 24/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.11s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.12s\n",
      "  Batch 25/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.03s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.12s\n",
      "  Batch 26/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.98s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 27/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.94s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 28/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.77s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 29/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.78s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 30/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.72s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 31/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.72s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 32/32:\n",
      "    input_batch shape: torch.Size([44, 20])\n",
      "    target_batch shape: torch.Size([44, 20])\n",
      "    RNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([44, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([44, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "Epoch 9/50 Completed | RNN Loss: 4.6314, CNN Loss: 3.4814, RNN Accuracy: 0.0928, CNN Accuracy: 0.1560, RNN Perplexity: 102.6530, CNN Perplexity: 32.5041, BLEU (RNN): 0.0109, BLEU (CNN): 0.0102, Time: 386.91s\n",
      "Starting Epoch 10/50...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.83s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 2/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.77s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 3/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.68s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 4/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.68s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 5/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.75s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 6/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.78s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 7/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.86s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.11s\n",
      "  Batch 8/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.84s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 9/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.84s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 10/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.84s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 11/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 2.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 12/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.85s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.15s\n",
      "  Batch 13/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.70s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.11s\n",
      "  Batch 14/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.13s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.11s\n",
      "  Batch 15/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.24s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.19s\n",
      "  Batch 16/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.36s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.11s\n",
      "  Batch 17/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.54s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 18/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.85s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 19/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.79s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 20/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.70s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 21/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 22/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 23/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.85s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 24/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 25/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.67s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 26/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.73s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 27/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.72s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 28/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.71s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 29/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.76s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 30/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.71s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 31/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.72s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 32/32:\n",
      "    input_batch shape: torch.Size([44, 20])\n",
      "    target_batch shape: torch.Size([44, 20])\n",
      "    RNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([44, 19, 4590])\n",
      "    RNN Forward pass time: 0.61s\n",
      "    CNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([44, 20, 4590])\n",
      "    CNN Forward pass time: 0.05s\n",
      "Epoch 10/50 Completed | RNN Loss: 4.4780, CNN Loss: 3.2913, RNN Accuracy: 0.1039, CNN Accuracy: 0.1680, RNN Perplexity: 88.0622, CNN Perplexity: 26.8783, BLEU (RNN): 0.0113, BLEU (CNN): 0.0104, Time: 306.25s\n",
      "Starting Epoch 11/50...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.79s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 2/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.74s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 3/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.72s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 4/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 5/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 6/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 7/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 8/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.70s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 9/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 10/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 11/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 12/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 13/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 14/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 15/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 16/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.72s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 17/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.71s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 18/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.68s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 19/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.69s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 20/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.75s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 21/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.68s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 22/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.83s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 23/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.70s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 24/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 25/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 26/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 27/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 28/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.61s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 29/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 30/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 31/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 32/32:\n",
      "    input_batch shape: torch.Size([44, 20])\n",
      "    target_batch shape: torch.Size([44, 20])\n",
      "    RNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([44, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([44, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "Epoch 11/50 Completed | RNN Loss: 4.3103, CNN Loss: 3.1502, RNN Accuracy: 0.1164, CNN Accuracy: 0.1803, RNN Perplexity: 74.4615, CNN Perplexity: 23.3413, BLEU (RNN): 0.0114, BLEU (CNN): 0.0115, Time: 280.70s\n",
      "Starting Epoch 12/50...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.73s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 2/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.67s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 3/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 4/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 5/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.68s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 6/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 7/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 8/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 9/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.11s\n",
      "  Batch 10/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 11/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 12/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.67s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 13/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 14/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.73s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 15/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.68s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 16/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 17/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.61s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 18/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.61s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 19/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.61s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 20/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.61s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 21/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.61s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 22/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 23/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.70s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 24/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.72s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 25/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.68s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 26/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.71s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 27/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.69s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 28/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 29/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 30/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.61s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 31/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 32/32:\n",
      "    input_batch shape: torch.Size([44, 20])\n",
      "    target_batch shape: torch.Size([44, 20])\n",
      "    RNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([44, 19, 4590])\n",
      "    RNN Forward pass time: 0.52s\n",
      "    CNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([44, 20, 4590])\n",
      "    CNN Forward pass time: 0.05s\n",
      "Epoch 12/50 Completed | RNN Loss: 4.1360, CNN Loss: 3.0323, RNN Accuracy: 0.1262, CNN Accuracy: 0.1899, RNN Perplexity: 62.5549, CNN Perplexity: 20.7458, BLEU (RNN): 0.0107, BLEU (CNN): 0.0114, Time: 274.32s\n",
      "Starting Epoch 13/50...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.67s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 2/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.71s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 3/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 4/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 5/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 6/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 7/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 8/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 9/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.71s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.15s\n",
      "  Batch 10/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.67s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 11/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 12/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 13/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 14/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 15/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 16/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 17/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 18/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 19/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.61s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 20/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.14s\n",
      "  Batch 21/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.45s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.11s\n",
      "  Batch 22/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.30s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.33s\n",
      "  Batch 23/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.88s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.44s\n",
      "  Batch 24/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 3.24s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.14s\n",
      "  Batch 25/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.29s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.13s\n",
      "  Batch 26/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.96s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 27/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.89s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 28/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.94s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.11s\n",
      "  Batch 29/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.86s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.14s\n",
      "  Batch 30/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.80s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 31/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.96s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 32/32:\n",
      "    input_batch shape: torch.Size([44, 20])\n",
      "    target_batch shape: torch.Size([44, 20])\n",
      "    RNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([44, 19, 4590])\n",
      "    RNN Forward pass time: 0.75s\n",
      "    CNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([44, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "Epoch 13/50 Completed | RNN Loss: 3.9942, CNN Loss: 2.9334, RNN Accuracy: 0.1336, CNN Accuracy: 0.2006, RNN Perplexity: 54.2813, CNN Perplexity: 18.7908, BLEU (RNN): 0.0099, BLEU (CNN): 0.0121, Time: 352.91s\n",
      "Starting Epoch 14/50...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.82s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 2/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.69s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 3/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 4/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.67s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 5/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.69s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 6/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.72s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 7/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.77s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 8/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.12s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 9/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.87s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 10/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.11s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 11/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.74s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 12/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.71s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 13/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.93s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 14/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.84s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 15/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.74s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 16/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.69s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 17/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.70s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 18/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.71s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 19/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.72s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 20/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.75s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 21/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.73s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 22/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.90s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 23/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.80s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 24/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.69s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.13s\n",
      "  Batch 25/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.11s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 26/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.74s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 27/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.82s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 28/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.72s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 29/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.72s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 30/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.74s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 31/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.79s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 32/32:\n",
      "    input_batch shape: torch.Size([44, 20])\n",
      "    target_batch shape: torch.Size([44, 20])\n",
      "    RNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([44, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([44, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "Epoch 14/50 Completed | RNN Loss: 3.8225, CNN Loss: 2.8489, RNN Accuracy: 0.1389, CNN Accuracy: 0.2050, RNN Perplexity: 45.7181, CNN Perplexity: 17.2695, BLEU (RNN): 0.0115, BLEU (CNN): 0.0119, Time: 296.41s\n",
      "Starting Epoch 15/50...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 2/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 3/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.58s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "  Batch 4/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 5/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.57s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 6/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 7/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.68s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 8/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.72s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 9/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.11s\n",
      "  Batch 10/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 11/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.71s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 12/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.02s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.18s\n",
      "  Batch 13/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.87s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 14/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.70s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 15/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.75s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 16/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.47s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.14s\n",
      "  Batch 17/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.19s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.11s\n",
      "  Batch 18/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.83s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 19/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.92s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.11s\n",
      "  Batch 20/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.78s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 21/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.72s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 22/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.68s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 23/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.68s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 24/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 25/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 26/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 27/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.82s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 28/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.73s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 29/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.79s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 30/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.78s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 31/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.77s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 32/32:\n",
      "    input_batch shape: torch.Size([44, 20])\n",
      "    target_batch shape: torch.Size([44, 20])\n",
      "    RNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([44, 19, 4590])\n",
      "    RNN Forward pass time: 0.75s\n",
      "    CNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([44, 20, 4590])\n",
      "    CNN Forward pass time: 0.05s\n",
      "Epoch 15/50 Completed | RNN Loss: 3.7085, CNN Loss: 2.7537, RNN Accuracy: 0.1426, CNN Accuracy: 0.2134, RNN Perplexity: 40.7934, CNN Perplexity: 15.7005, BLEU (RNN): 0.0112, BLEU (CNN): 0.0123, Time: 326.90s\n",
      "Starting Epoch 16/50...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.95s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 2/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.97s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 3/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.76s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 4/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.90s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 5/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.75s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 6/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.76s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 7/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.72s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 8/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.72s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 9/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.71s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 10/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 11/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 12/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.13s\n",
      "  Batch 13/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.73s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 14/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.92s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.11s\n",
      "  Batch 15/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.37s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.13s\n",
      "  Batch 16/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.09s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.11s\n",
      "  Batch 17/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.03s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.12s\n",
      "  Batch 18/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.93s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 19/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.77s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 20/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.67s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 21/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 22/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 23/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 24/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 25/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 26/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.69s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.11s\n",
      "  Batch 27/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.84s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 28/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.69s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 29/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.83s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 30/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.80s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 31/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 32/32:\n",
      "    input_batch shape: torch.Size([44, 20])\n",
      "    target_batch shape: torch.Size([44, 20])\n",
      "    RNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([44, 19, 4590])\n",
      "    RNN Forward pass time: 0.55s\n",
      "    CNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([44, 20, 4590])\n",
      "    CNN Forward pass time: 0.05s\n",
      "Epoch 16/50 Completed | RNN Loss: 3.5876, CNN Loss: 2.7230, RNN Accuracy: 0.1482, CNN Accuracy: 0.2167, RNN Perplexity: 36.1462, CNN Perplexity: 15.2265, BLEU (RNN): 0.0111, BLEU (CNN): 0.0126, Time: 347.49s\n",
      "Starting Epoch 17/50...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.79s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 2/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.67s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 3/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 4/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.69s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 5/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.61s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 6/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 7/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 8/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.75s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.12s\n",
      "  Batch 9/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.69s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.18s\n",
      "  Batch 10/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.06s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 11/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.72s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 12/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.75s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 13/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.84s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 14/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.67s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 15/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.81s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 16/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.91s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 17/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.67s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 18/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.71s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 19/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.71s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 20/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.92s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 21/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.36s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.23s\n",
      "  Batch 22/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.68s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 23/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 24/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.01s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 25/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 26/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 27/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 28/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.99s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.18s\n",
      "  Batch 29/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.76s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 30/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.82s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 31/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.76s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 32/32:\n",
      "    input_batch shape: torch.Size([44, 20])\n",
      "    target_batch shape: torch.Size([44, 20])\n",
      "    RNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([44, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([44, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "Epoch 17/50 Completed | RNN Loss: 3.4031, CNN Loss: 2.6391, RNN Accuracy: 0.1578, CNN Accuracy: 0.2226, RNN Perplexity: 30.0564, CNN Perplexity: 14.0007, BLEU (RNN): 0.0123, BLEU (CNN): 0.0130, Time: 297.87s\n",
      "Starting Epoch 18/50...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.77s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 2/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 3/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 4/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 5/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 6/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.61s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 7/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 8/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 9/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 10/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.68s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 11/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.71s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 12/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.69s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 13/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.68s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 14/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.69s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 15/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 16/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.76s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 17/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 18/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.11s\n",
      "  Batch 19/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.76s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 20/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.68s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 21/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.93s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.19s\n",
      "  Batch 22/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.19s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 23/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.00s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 24/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.86s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 25/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.75s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.12s\n",
      "  Batch 26/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.71s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 27/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.78s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 28/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 29/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.86s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 30/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.73s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 31/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.67s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 32/32:\n",
      "    input_batch shape: torch.Size([44, 20])\n",
      "    target_batch shape: torch.Size([44, 20])\n",
      "    RNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([44, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([44, 20, 4590])\n",
      "    CNN Forward pass time: 0.05s\n",
      "Epoch 18/50 Completed | RNN Loss: 3.3076, CNN Loss: 2.5908, RNN Accuracy: 0.1603, CNN Accuracy: 0.2275, RNN Perplexity: 27.3189, CNN Perplexity: 13.3407, BLEU (RNN): 0.0126, BLEU (CNN): 0.0129, Time: 308.27s\n",
      "Starting Epoch 19/50...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.79s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 2/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 3/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.73s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 4/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 5/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.61s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 6/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 7/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 8/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.70s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 9/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.69s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 10/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.70s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 11/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.70s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 12/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.72s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 13/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.74s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 14/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.73s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 15/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 16/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.92s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 17/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.81s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 18/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 19/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.61s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 20/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 21/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 22/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.69s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 23/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 24/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 25/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.67s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.12s\n",
      "  Batch 26/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 27/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 28/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 29/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.67s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.24s\n",
      "  Batch 30/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.89s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.28s\n",
      "  Batch 31/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.14s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.13s\n",
      "  Batch 32/32:\n",
      "    input_batch shape: torch.Size([44, 20])\n",
      "    target_batch shape: torch.Size([44, 20])\n",
      "    RNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([44, 19, 4590])\n",
      "    RNN Forward pass time: 0.90s\n",
      "    CNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([44, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "Epoch 19/50 Completed | RNN Loss: 3.1407, CNN Loss: 2.5452, RNN Accuracy: 0.1702, CNN Accuracy: 0.2313, RNN Perplexity: 23.1210, CNN Perplexity: 12.7458, BLEU (RNN): 0.0143, BLEU (CNN): 0.0129, Time: 293.17s\n",
      "Starting Epoch 20/50...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.58s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 2/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.54s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "  Batch 3/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.55s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "  Batch 4/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 5/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 6/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 7/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.61s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 8/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 9/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.96s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.12s\n",
      "  Batch 10/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.40s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.15s\n",
      "  Batch 11/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.13s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.23s\n",
      "  Batch 12/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.84s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.44s\n",
      "  Batch 13/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.40s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 14/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.86s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 15/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.71s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 16/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.69s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 17/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 18/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.00s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.16s\n",
      "  Batch 19/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.11s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 20/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.72s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 21/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.75s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 22/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.76s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 23/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.75s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 24/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.85s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 25/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.76s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 26/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.89s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 27/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.76s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 28/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 29/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 30/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 31/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 32/32:\n",
      "    input_batch shape: torch.Size([44, 20])\n",
      "    target_batch shape: torch.Size([44, 20])\n",
      "    RNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([44, 19, 4590])\n",
      "    RNN Forward pass time: 0.57s\n",
      "    CNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([44, 20, 4590])\n",
      "    CNN Forward pass time: 0.05s\n",
      "Epoch 20/50 Completed | RNN Loss: 2.9891, CNN Loss: 2.5111, RNN Accuracy: 0.1790, CNN Accuracy: 0.2314, RNN Perplexity: 19.8672, CNN Perplexity: 12.3191, BLEU (RNN): 0.0157, BLEU (CNN): 0.0132, Time: 327.90s\n",
      "Starting Epoch 21/50...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.68s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 2/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 3/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 4/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.69s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 5/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 6/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.68s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 7/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.73s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 8/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.70s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 9/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.70s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 10/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.70s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 11/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.69s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 12/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.67s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 13/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 14/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 15/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.96s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 16/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 17/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.70s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 18/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.71s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 19/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.69s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 20/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.73s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 21/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.80s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 22/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.17s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.17s\n",
      "  Batch 23/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.70s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 24/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.70s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 25/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.75s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 26/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.67s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 27/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.70s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 28/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 29/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.90s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 30/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 31/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 32/32:\n",
      "    input_batch shape: torch.Size([44, 20])\n",
      "    target_batch shape: torch.Size([44, 20])\n",
      "    RNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([44, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([44, 20, 4590])\n",
      "    CNN Forward pass time: 0.05s\n",
      "Epoch 21/50 Completed | RNN Loss: 2.8615, CNN Loss: 2.4836, RNN Accuracy: 0.1896, CNN Accuracy: 0.2379, RNN Perplexity: 17.4880, CNN Perplexity: 11.9849, BLEU (RNN): 0.0167, BLEU (CNN): 0.0134, Time: 307.40s\n",
      "Starting Epoch 22/50...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.77s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 2/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.70s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 3/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.70s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 4/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 5/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.87s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 6/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.67s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 7/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.73s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 8/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.70s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 9/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.72s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 10/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.07s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 11/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.73s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 12/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.76s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 13/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.69s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 14/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.69s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 15/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.68s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 16/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 17/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 18/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.70s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 19/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.74s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 20/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.70s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 21/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.68s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 22/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.70s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 23/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.72s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 24/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.71s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 25/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.68s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 26/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.70s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 27/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.71s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 28/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 29/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 30/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 31/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.11s\n",
      "  Batch 32/32:\n",
      "    input_batch shape: torch.Size([44, 20])\n",
      "    target_batch shape: torch.Size([44, 20])\n",
      "    RNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([44, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([44, 20, 4590])\n",
      "    CNN Forward pass time: 0.05s\n",
      "Epoch 22/50 Completed | RNN Loss: 2.6950, CNN Loss: 2.4412, RNN Accuracy: 0.2036, CNN Accuracy: 0.2390, RNN Perplexity: 14.8050, CNN Perplexity: 11.4873, BLEU (RNN): 0.0184, BLEU (CNN): 0.0134, Time: 303.57s\n",
      "Starting Epoch 23/50...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.69s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 2/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 3/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.61s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 4/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 5/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.61s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 6/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 7/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.69s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 8/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.69s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.16s\n",
      "  Batch 9/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.68s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 10/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.68s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 11/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.67s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 12/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.69s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 13/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.73s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 14/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.71s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 15/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.76s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 16/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.72s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 17/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.75s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 18/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.71s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.38s\n",
      "  Batch 19/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.25s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 20/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.86s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.11s\n",
      "  Batch 21/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.87s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.11s\n",
      "  Batch 22/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.32s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 23/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.68s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.11s\n",
      "  Batch 24/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.11s\n",
      "  Batch 25/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.89s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 26/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.89s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 27/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.73s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 28/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.73s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 29/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.69s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 30/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 31/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.12s\n",
      "  Batch 32/32:\n",
      "    input_batch shape: torch.Size([44, 20])\n",
      "    target_batch shape: torch.Size([44, 20])\n",
      "    RNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([44, 19, 4590])\n",
      "    RNN Forward pass time: 0.55s\n",
      "    CNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([44, 20, 4590])\n",
      "    CNN Forward pass time: 0.05s\n",
      "Epoch 23/50 Completed | RNN Loss: 2.5289, CNN Loss: 2.4033, RNN Accuracy: 0.2172, CNN Accuracy: 0.2427, RNN Perplexity: 12.5394, CNN Perplexity: 11.0597, BLEU (RNN): 0.0198, BLEU (CNN): 0.0132, Time: 310.37s\n",
      "Starting Epoch 24/50...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.67s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 2/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.67s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 3/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.61s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 4/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 5/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 6/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 7/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 8/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.06s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 9/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.69s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 10/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.74s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 11/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.90s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 12/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.73s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 13/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.69s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 14/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.67s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 15/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 16/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.68s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 17/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 18/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 19/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 20/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 21/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.67s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 22/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.70s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 23/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.77s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 24/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.69s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 25/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.71s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 26/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.70s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 27/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.69s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 28/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.86s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 29/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.69s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 30/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 31/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 32/32:\n",
      "    input_batch shape: torch.Size([44, 20])\n",
      "    target_batch shape: torch.Size([44, 20])\n",
      "    RNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([44, 19, 4590])\n",
      "    RNN Forward pass time: 0.55s\n",
      "    CNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([44, 20, 4590])\n",
      "    CNN Forward pass time: 0.05s\n",
      "Epoch 24/50 Completed | RNN Loss: 2.4021, CNN Loss: 2.3922, RNN Accuracy: 0.2266, CNN Accuracy: 0.2448, RNN Perplexity: 11.0463, CNN Perplexity: 10.9379, BLEU (RNN): 0.0232, BLEU (CNN): 0.0138, Time: 291.61s\n",
      "Starting Epoch 25/50...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.68s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 2/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 3/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.61s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 4/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.61s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 5/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 6/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 7/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 8/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.69s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 9/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 10/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.88s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 11/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.69s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 12/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.67s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 13/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.67s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 14/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 15/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.69s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 16/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 17/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 18/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 19/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 20/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.85s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 21/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.67s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.12s\n",
      "  Batch 22/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.70s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 23/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.82s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 24/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 25/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.67s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 26/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 27/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 28/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.67s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 29/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 30/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 31/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 32/32:\n",
      "    input_batch shape: torch.Size([44, 20])\n",
      "    target_batch shape: torch.Size([44, 20])\n",
      "    RNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([44, 19, 4590])\n",
      "    RNN Forward pass time: 0.61s\n",
      "    CNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([44, 20, 4590])\n",
      "    CNN Forward pass time: 0.05s\n",
      "Epoch 25/50 Completed | RNN Loss: 2.2357, CNN Loss: 2.3499, RNN Accuracy: 0.2399, CNN Accuracy: 0.2470, RNN Perplexity: 9.3532, CNN Perplexity: 10.4843, BLEU (RNN): 0.0264, BLEU (CNN): 0.0138, Time: 290.52s\n",
      "Starting Epoch 26/50...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.71s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 2/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.67s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 3/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.67s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 4/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.75s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 5/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.74s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 6/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 7/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.71s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 8/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.71s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 9/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.72s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 10/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.73s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 11/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.67s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 12/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.67s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 13/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 14/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 15/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 16/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 17/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 18/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.68s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 19/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.69s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 20/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.88s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 21/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.71s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 22/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.69s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 23/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.84s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 24/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 25/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 26/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 27/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.81s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 28/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 29/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 30/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 31/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 32/32:\n",
      "    input_batch shape: torch.Size([44, 20])\n",
      "    target_batch shape: torch.Size([44, 20])\n",
      "    RNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([44, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([44, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "Epoch 26/50 Completed | RNN Loss: 2.1251, CNN Loss: 2.3196, RNN Accuracy: 0.2480, CNN Accuracy: 0.2519, RNN Perplexity: 8.3741, CNN Perplexity: 10.1718, BLEU (RNN): 0.0285, BLEU (CNN): 0.0139, Time: 304.18s\n",
      "Starting Epoch 27/50...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.94s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.12s\n",
      "  Batch 2/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 3/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 4/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.15s\n",
      "  Batch 5/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.86s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.13s\n",
      "  Batch 6/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.83s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 7/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.78s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 8/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.70s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 9/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 10/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 11/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 12/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.61s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 13/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 14/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.58s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 15/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 16/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.20s\n",
      "  Batch 17/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.61s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 18/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 19/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.71s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 20/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.61s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 21/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "  Batch 22/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.54s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "  Batch 23/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.55s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "  Batch 24/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.54s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "  Batch 25/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.52s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "  Batch 26/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.52s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "  Batch 27/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.52s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "  Batch 28/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.54s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 29/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.55s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 30/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.57s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 31/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.58s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 32/32:\n",
      "    input_batch shape: torch.Size([44, 20])\n",
      "    target_batch shape: torch.Size([44, 20])\n",
      "    RNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([44, 19, 4590])\n",
      "    RNN Forward pass time: 0.50s\n",
      "    CNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([44, 20, 4590])\n",
      "    CNN Forward pass time: 0.05s\n",
      "Epoch 27/50 Completed | RNN Loss: 1.9763, CNN Loss: 2.3096, RNN Accuracy: 0.2614, CNN Accuracy: 0.2521, RNN Perplexity: 7.2159, CNN Perplexity: 10.0708, BLEU (RNN): 0.0321, BLEU (CNN): 0.0140, Time: 271.32s\n",
      "Starting Epoch 28/50...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.67s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 2/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.61s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 3/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.61s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 4/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 5/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.58s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 6/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.61s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 7/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 8/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 9/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 10/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 11/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 12/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 13/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 14/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 15/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 16/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 17/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 18/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 19/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 20/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 21/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 22/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.58s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 23/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 24/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.57s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 25/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 26/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 27/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.61s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 28/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 29/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 30/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 31/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 32/32:\n",
      "    input_batch shape: torch.Size([44, 20])\n",
      "    target_batch shape: torch.Size([44, 20])\n",
      "    RNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([44, 19, 4590])\n",
      "    RNN Forward pass time: 0.54s\n",
      "    CNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([44, 20, 4590])\n",
      "    CNN Forward pass time: 0.05s\n",
      "Epoch 28/50 Completed | RNN Loss: 1.8304, CNN Loss: 2.2621, RNN Accuracy: 0.2702, CNN Accuracy: 0.2547, RNN Perplexity: 6.2366, CNN Perplexity: 9.6033, BLEU (RNN): 0.0346, BLEU (CNN): 0.0142, Time: 290.22s\n",
      "Starting Epoch 29/50...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.71s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 2/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.80s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 3/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 4/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 5/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 6/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 7/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 8/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.67s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 9/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.72s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 10/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.68s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 11/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.71s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 12/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.69s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 13/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.72s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 14/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.67s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 15/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 16/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 17/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 18/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.13s\n",
      "  Batch 19/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.97s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 20/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.77s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 21/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 22/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.69s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 23/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.81s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 24/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.67s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 25/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.68s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 26/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.67s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 27/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.68s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 28/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.70s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 29/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.70s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 30/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.70s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 31/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.69s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 32/32:\n",
      "    input_batch shape: torch.Size([44, 20])\n",
      "    target_batch shape: torch.Size([44, 20])\n",
      "    RNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([44, 19, 4590])\n",
      "    RNN Forward pass time: 0.58s\n",
      "    CNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([44, 20, 4590])\n",
      "    CNN Forward pass time: 0.05s\n",
      "Epoch 29/50 Completed | RNN Loss: 1.7232, CNN Loss: 2.2754, RNN Accuracy: 0.2827, CNN Accuracy: 0.2537, RNN Perplexity: 5.6022, CNN Perplexity: 9.7320, BLEU (RNN): 0.0395, BLEU (CNN): 0.0141, Time: 319.24s\n",
      "Starting Epoch 30/50...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 2/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 3/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 4/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 5/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 6/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.05s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 7/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.92s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 8/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.77s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 9/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.73s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 10/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 11/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 12/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 13/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.26s\n",
      "  Batch 14/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.74s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.11s\n",
      "  Batch 15/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.14s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 16/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.88s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 17/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.74s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 18/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 19/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 20/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 21/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.56s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "  Batch 22/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.56s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "  Batch 23/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.53s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "  Batch 24/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.52s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "  Batch 25/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.54s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "  Batch 26/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.56s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 27/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 28/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.54s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "  Batch 29/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.71s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 30/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.67s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 31/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.80s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 32/32:\n",
      "    input_batch shape: torch.Size([44, 20])\n",
      "    target_batch shape: torch.Size([44, 20])\n",
      "    RNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([44, 19, 4590])\n",
      "    RNN Forward pass time: 0.53s\n",
      "    CNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([44, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "Epoch 30/50 Completed | RNN Loss: 1.6191, CNN Loss: 2.2489, RNN Accuracy: 0.2898, CNN Accuracy: 0.2565, RNN Perplexity: 5.0483, CNN Perplexity: 9.4778, BLEU (RNN): 0.0430, BLEU (CNN): 0.0142, Time: 376.68s\n",
      "Starting Epoch 31/50...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.95s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 2/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.88s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.11s\n",
      "  Batch 3/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.05s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 4/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.81s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 5/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.75s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 6/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.89s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 7/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.82s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 8/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.78s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 9/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.81s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 10/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.82s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 11/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.77s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 12/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.68s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 13/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.70s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 14/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.58s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "  Batch 15/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 16/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.57s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "  Batch 17/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.55s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 18/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.56s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 19/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.95s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 20/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.74s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.14s\n",
      "  Batch 21/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 2.34s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.20s\n",
      "  Batch 22/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.40s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 23/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.77s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.13s\n",
      "  Batch 24/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.03s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.13s\n",
      "  Batch 25/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.77s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 26/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.81s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 27/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.89s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.15s\n",
      "  Batch 28/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.21s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.18s\n",
      "  Batch 29/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.30s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.11s\n",
      "  Batch 30/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.91s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.16s\n",
      "  Batch 31/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.15s\n",
      "  Batch 32/32:\n",
      "    input_batch shape: torch.Size([44, 20])\n",
      "    target_batch shape: torch.Size([44, 20])\n",
      "    RNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([44, 19, 4590])\n",
      "    RNN Forward pass time: 1.02s\n",
      "    CNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([44, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "Epoch 31/50 Completed | RNN Loss: 1.4989, CNN Loss: 2.2002, RNN Accuracy: 0.3012, CNN Accuracy: 0.2604, RNN Perplexity: 4.4766, CNN Perplexity: 9.0265, BLEU (RNN): 0.0472, BLEU (CNN): 0.0143, Time: 334.39s\n",
      "Starting Epoch 32/50...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 2/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 3/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.58s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 4/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.68s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 5/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.71s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.16s\n",
      "  Batch 6/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.70s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 7/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 2.00s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.11s\n",
      "  Batch 8/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.25s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.13s\n",
      "  Batch 9/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.23s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.13s\n",
      "  Batch 10/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.69s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.34s\n",
      "  Batch 11/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.24s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.15s\n",
      "  Batch 12/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.31s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.11s\n",
      "  Batch 13/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.85s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.11s\n",
      "  Batch 14/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.85s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 15/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.94s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 16/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.80s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 17/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.80s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 18/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.79s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 19/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.76s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 20/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.82s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 21/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.79s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 22/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.88s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 23/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.70s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 24/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.76s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 25/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.69s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 26/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.78s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 27/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.69s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 28/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.68s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 29/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.75s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 30/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.76s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 31/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.72s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 32/32:\n",
      "    input_batch shape: torch.Size([44, 20])\n",
      "    target_batch shape: torch.Size([44, 20])\n",
      "    RNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([44, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([44, 20, 4590])\n",
      "    CNN Forward pass time: 0.05s\n",
      "Epoch 32/50 Completed | RNN Loss: 1.3875, CNN Loss: 2.2218, RNN Accuracy: 0.3124, CNN Accuracy: 0.2573, RNN Perplexity: 4.0047, CNN Perplexity: 9.2244, BLEU (RNN): 0.0499, BLEU (CNN): 0.0145, Time: 351.84s\n",
      "Starting Epoch 33/50...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 2/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 3/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.72s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 4/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 5/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 6/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 7/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.70s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 8/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.67s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 9/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.91s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 10/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.77s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 11/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.17s\n",
      "  Batch 12/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 13/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 14/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 15/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 16/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 17/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.61s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 18/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.72s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 19/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.73s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 20/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 21/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 22/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.75s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 23/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.70s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 24/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.71s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 25/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.68s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 26/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.80s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 27/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.71s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 28/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.67s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 29/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.68s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 30/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.74s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 31/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.69s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 32/32:\n",
      "    input_batch shape: torch.Size([44, 20])\n",
      "    target_batch shape: torch.Size([44, 20])\n",
      "    RNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([44, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([44, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "Epoch 33/50 Completed | RNN Loss: 1.3039, CNN Loss: 2.1925, RNN Accuracy: 0.3192, CNN Accuracy: 0.2618, RNN Perplexity: 3.6835, CNN Perplexity: 8.9578, BLEU (RNN): 0.0575, BLEU (CNN): 0.0145, Time: 273.67s\n",
      "Starting Epoch 34/50...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 1.11s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 2/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 3/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.94s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 4/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 5/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 6/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.61s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 7/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "  Batch 8/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 9/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.78s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 10/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.61s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 11/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 12/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 13/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.80s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 14/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 15/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 16/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.74s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 17/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 18/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.69s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 19/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.67s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "  Batch 20/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.83s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 21/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.61s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 22/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 23/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.61s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 24/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 25/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 26/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.68s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 27/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.73s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 28/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 29/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 30/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.68s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 31/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 32/32:\n",
      "    input_batch shape: torch.Size([44, 20])\n",
      "    target_batch shape: torch.Size([44, 20])\n",
      "    RNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([44, 19, 4590])\n",
      "    RNN Forward pass time: 0.54s\n",
      "    CNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([44, 20, 4590])\n",
      "    CNN Forward pass time: 0.05s\n",
      "Epoch 34/50 Completed | RNN Loss: 1.2169, CNN Loss: 2.1741, RNN Accuracy: 0.3270, CNN Accuracy: 0.2615, RNN Perplexity: 3.3769, CNN Perplexity: 8.7944, BLEU (RNN): 0.0595, BLEU (CNN): 0.0144, Time: 289.43s\n",
      "Starting Epoch 35/50...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.53s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "  Batch 2/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.50s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "  Batch 3/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.51s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "  Batch 4/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.49s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "  Batch 5/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.79s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 6/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.61s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 7/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 8/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.70s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 9/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.70s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 10/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.68s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 11/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.67s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 12/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.61s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 13/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 14/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.20s\n",
      "  Batch 15/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 16/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 17/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 18/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 19/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 20/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 21/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.71s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 22/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 23/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 24/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 25/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "  Batch 26/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 27/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 28/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.67s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 29/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.78s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 30/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.73s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.11s\n",
      "  Batch 31/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.70s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 32/32:\n",
      "    input_batch shape: torch.Size([44, 20])\n",
      "    target_batch shape: torch.Size([44, 20])\n",
      "    RNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([44, 19, 4590])\n",
      "    RNN Forward pass time: 0.73s\n",
      "    CNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([44, 20, 4590])\n",
      "    CNN Forward pass time: 0.21s\n",
      "Epoch 35/50 Completed | RNN Loss: 1.1293, CNN Loss: 2.1533, RNN Accuracy: 0.3356, CNN Accuracy: 0.2621, RNN Perplexity: 3.0936, CNN Perplexity: 8.6134, BLEU (RNN): 0.0672, BLEU (CNN): 0.0145, Time: 279.58s\n",
      "Starting Epoch 36/50...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 2/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 3/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 4/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.58s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 5/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.58s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 6/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 7/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.58s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 8/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 9/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 10/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 11/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 12/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 13/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.61s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 14/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.58s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 15/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 16/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 17/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.57s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 18/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.58s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 19/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 20/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 21/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.70s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 22/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 23/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 24/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 25/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 26/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 27/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.58s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 28/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.58s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 29/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.58s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 30/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.58s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 31/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 32/32:\n",
      "    input_batch shape: torch.Size([44, 20])\n",
      "    target_batch shape: torch.Size([44, 20])\n",
      "    RNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([44, 19, 4590])\n",
      "    RNN Forward pass time: 0.68s\n",
      "    CNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([44, 20, 4590])\n",
      "    CNN Forward pass time: 0.05s\n",
      "Epoch 36/50 Completed | RNN Loss: 1.0587, CNN Loss: 2.1495, RNN Accuracy: 0.3439, CNN Accuracy: 0.2635, RNN Perplexity: 2.8826, CNN Perplexity: 8.5802, BLEU (RNN): 0.0692, BLEU (CNN): 0.0143, Time: 267.72s\n",
      "Starting Epoch 37/50...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.86s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 2/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 3/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 4/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 5/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 6/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 7/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.67s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 8/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 9/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 10/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 11/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 12/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 13/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 14/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 15/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.68s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 16/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 17/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 18/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 19/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.71s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 20/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.71s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 21/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 22/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 23/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.67s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 24/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.67s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 25/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 26/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 27/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.58s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 28/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 29/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 30/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.58s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 31/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 32/32:\n",
      "    input_batch shape: torch.Size([44, 20])\n",
      "    target_batch shape: torch.Size([44, 20])\n",
      "    RNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([44, 19, 4590])\n",
      "    RNN Forward pass time: 0.57s\n",
      "    CNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([44, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "Epoch 37/50 Completed | RNN Loss: 0.9710, CNN Loss: 2.1333, RNN Accuracy: 0.3544, CNN Accuracy: 0.2642, RNN Perplexity: 2.6407, CNN Perplexity: 8.4429, BLEU (RNN): 0.0760, BLEU (CNN): 0.0144, Time: 274.54s\n",
      "Starting Epoch 38/50...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 2/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 3/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 4/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 5/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.58s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 6/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.67s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 7/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 8/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 9/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 10/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 11/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 12/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 13/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 14/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 15/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 16/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 17/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 18/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 19/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 20/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 21/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 22/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 23/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 24/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 25/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 26/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 27/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 28/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.68s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 29/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 30/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.21s\n",
      "  Batch 31/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.58s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 32/32:\n",
      "    input_batch shape: torch.Size([44, 20])\n",
      "    target_batch shape: torch.Size([44, 20])\n",
      "    RNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([44, 19, 4590])\n",
      "    RNN Forward pass time: 0.51s\n",
      "    CNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([44, 20, 4590])\n",
      "    CNN Forward pass time: 0.05s\n",
      "Epoch 38/50 Completed | RNN Loss: 0.9189, CNN Loss: 2.1537, RNN Accuracy: 0.3607, CNN Accuracy: 0.2663, RNN Perplexity: 2.5065, CNN Perplexity: 8.6165, BLEU (RNN): 0.0791, BLEU (CNN): 0.0145, Time: 278.30s\n",
      "Starting Epoch 39/50...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 2/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 3/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 4/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 5/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 6/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 7/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 8/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.61s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 9/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 10/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 11/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 12/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 13/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 14/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.70s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 15/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 16/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.75s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 17/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 18/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 19/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.71s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 20/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 21/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 22/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 23/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.61s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 24/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 25/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 26/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.21s\n",
      "  Batch 27/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 28/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.80s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 29/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 30/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 31/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 32/32:\n",
      "    input_batch shape: torch.Size([44, 20])\n",
      "    target_batch shape: torch.Size([44, 20])\n",
      "    RNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([44, 19, 4590])\n",
      "    RNN Forward pass time: 0.50s\n",
      "    CNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([44, 20, 4590])\n",
      "    CNN Forward pass time: 0.05s\n",
      "Epoch 39/50 Completed | RNN Loss: 0.8343, CNN Loss: 2.1061, RNN Accuracy: 0.3716, CNN Accuracy: 0.2692, RNN Perplexity: 2.3033, CNN Perplexity: 8.2164, BLEU (RNN): 0.0838, BLEU (CNN): 0.0145, Time: 273.30s\n",
      "Starting Epoch 40/50...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.70s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 2/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 3/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 4/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 5/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.58s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 6/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.58s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 7/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.58s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.22s\n",
      "  Batch 8/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 9/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 10/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 11/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.61s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 12/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 13/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.80s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 14/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 15/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 16/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 17/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 18/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 19/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 20/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 21/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 22/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.61s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 23/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 24/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 25/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.61s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 26/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 27/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 28/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 29/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.84s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 30/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.58s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 31/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 32/32:\n",
      "    input_batch shape: torch.Size([44, 20])\n",
      "    target_batch shape: torch.Size([44, 20])\n",
      "    RNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([44, 19, 4590])\n",
      "    RNN Forward pass time: 0.54s\n",
      "    CNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([44, 20, 4590])\n",
      "    CNN Forward pass time: 0.05s\n",
      "Epoch 40/50 Completed | RNN Loss: 0.7725, CNN Loss: 2.0995, RNN Accuracy: 0.3776, CNN Accuracy: 0.2706, RNN Perplexity: 2.1652, CNN Perplexity: 8.1623, BLEU (RNN): 0.0927, BLEU (CNN): 0.0148, Time: 273.22s\n",
      "Starting Epoch 41/50...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 2/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 3/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 4/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.58s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 5/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 6/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 7/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.61s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 8/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 9/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 10/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 11/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 12/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 13/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 14/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 15/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.58s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 16/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 17/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 18/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 19/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 20/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 21/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 22/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 23/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 24/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 25/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 26/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.57s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 27/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.57s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 28/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.57s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 29/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.61s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 30/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 31/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 32/32:\n",
      "    input_batch shape: torch.Size([44, 20])\n",
      "    target_batch shape: torch.Size([44, 20])\n",
      "    RNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([44, 19, 4590])\n",
      "    RNN Forward pass time: 0.55s\n",
      "    CNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([44, 20, 4590])\n",
      "    CNN Forward pass time: 0.05s\n",
      "Epoch 41/50 Completed | RNN Loss: 0.7366, CNN Loss: 2.0746, RNN Accuracy: 0.3816, CNN Accuracy: 0.2726, RNN Perplexity: 2.0889, CNN Perplexity: 7.9615, BLEU (RNN): 0.0943, BLEU (CNN): 0.0146, Time: 270.87s\n",
      "Starting Epoch 42/50...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.77s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 2/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.72s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.11s\n",
      "  Batch 3/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 4/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 5/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.56s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 6/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.58s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 7/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.56s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 8/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.58s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 9/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 10/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 11/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.61s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 12/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 13/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 14/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 15/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 16/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.61s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 17/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.73s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 18/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 19/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.58s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 20/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 21/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.58s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 22/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 23/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 24/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 25/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 26/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 27/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 28/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 29/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "  Batch 30/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.56s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 31/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.56s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 32/32:\n",
      "    input_batch shape: torch.Size([44, 20])\n",
      "    target_batch shape: torch.Size([44, 20])\n",
      "    RNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([44, 19, 4590])\n",
      "    RNN Forward pass time: 0.49s\n",
      "    CNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([44, 20, 4590])\n",
      "    CNN Forward pass time: 0.04s\n",
      "Epoch 42/50 Completed | RNN Loss: 0.6525, CNN Loss: 2.0927, RNN Accuracy: 0.3912, CNN Accuracy: 0.2703, RNN Perplexity: 1.9204, CNN Perplexity: 8.1064, BLEU (RNN): 0.0949, BLEU (CNN): 0.0145, Time: 267.96s\n",
      "Starting Epoch 43/50...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.58s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 2/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.57s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 3/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.56s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 4/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.56s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 5/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.57s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 6/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.58s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 7/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 8/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.61s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 9/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 10/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 11/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 12/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 13/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 14/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.61s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 15/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 16/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 17/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.57s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 18/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 19/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.58s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 20/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.58s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 21/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 22/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 23/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 24/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 25/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.58s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 26/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 27/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 28/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 29/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 30/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.61s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 31/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.57s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 32/32:\n",
      "    input_batch shape: torch.Size([44, 20])\n",
      "    target_batch shape: torch.Size([44, 20])\n",
      "    RNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([44, 19, 4590])\n",
      "    RNN Forward pass time: 0.49s\n",
      "    CNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([44, 20, 4590])\n",
      "    CNN Forward pass time: 0.05s\n",
      "Epoch 43/50 Completed | RNN Loss: 0.6080, CNN Loss: 2.0543, RNN Accuracy: 0.3978, CNN Accuracy: 0.2728, RNN Perplexity: 1.8368, CNN Perplexity: 7.8013, BLEU (RNN): 0.1040, BLEU (CNN): 0.0145, Time: 264.38s\n",
      "Starting Epoch 44/50...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 2/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.57s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 3/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.58s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 4/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.57s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 5/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.58s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 6/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.56s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 7/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 8/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 9/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 10/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 11/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 12/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 13/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 14/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.57s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 15/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.56s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 16/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.57s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 17/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 18/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 19/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 20/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 21/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 22/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.61s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 23/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.58s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 24/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 25/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.56s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "  Batch 26/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.56s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 27/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.57s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 28/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 29/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 30/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 31/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.58s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 32/32:\n",
      "    input_batch shape: torch.Size([44, 20])\n",
      "    target_batch shape: torch.Size([44, 20])\n",
      "    RNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([44, 19, 4590])\n",
      "    RNN Forward pass time: 0.53s\n",
      "    CNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([44, 20, 4590])\n",
      "    CNN Forward pass time: 0.05s\n",
      "Epoch 44/50 Completed | RNN Loss: 0.5724, CNN Loss: 2.0516, RNN Accuracy: 0.4004, CNN Accuracy: 0.2727, RNN Perplexity: 1.7725, CNN Perplexity: 7.7806, BLEU (RNN): 0.1037, BLEU (CNN): 0.0144, Time: 264.31s\n",
      "Starting Epoch 45/50...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.69s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 2/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.58s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 3/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "  Batch 4/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.56s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "  Batch 5/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.55s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 6/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.58s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 7/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.57s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 8/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 9/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 10/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.61s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 11/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.73s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 12/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.58s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 13/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 14/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 15/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 16/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.56s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 17/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.56s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 18/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.56s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 19/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.56s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 20/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.61s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 21/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.57s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 22/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 23/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 24/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 25/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 26/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 27/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 28/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 29/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 30/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 31/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.58s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 32/32:\n",
      "    input_batch shape: torch.Size([44, 20])\n",
      "    target_batch shape: torch.Size([44, 20])\n",
      "    RNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([44, 19, 4590])\n",
      "    RNN Forward pass time: 0.49s\n",
      "    CNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([44, 20, 4590])\n",
      "    CNN Forward pass time: 0.05s\n",
      "Epoch 45/50 Completed | RNN Loss: 0.5185, CNN Loss: 2.0434, RNN Accuracy: 0.4074, CNN Accuracy: 0.2743, RNN Perplexity: 1.6795, CNN Perplexity: 7.7170, BLEU (RNN): 0.1095, BLEU (CNN): 0.0146, Time: 264.40s\n",
      "Starting Epoch 46/50...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 2/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "  Batch 3/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.58s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 4/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.56s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 5/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.55s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 6/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.55s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 7/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.55s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 8/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.58s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 9/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 10/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 11/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.64s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 12/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 13/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 14/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 15/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.57s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 16/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.56s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 17/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.56s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 18/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.57s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 19/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.57s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 20/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.58s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 21/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.57s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 22/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 23/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 24/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 25/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 26/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 27/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 28/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.61s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 29/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 30/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.56s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 31/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.56s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "  Batch 32/32:\n",
      "    input_batch shape: torch.Size([44, 20])\n",
      "    target_batch shape: torch.Size([44, 20])\n",
      "    RNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([44, 19, 4590])\n",
      "    RNN Forward pass time: 0.49s\n",
      "    CNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([44, 20, 4590])\n",
      "    CNN Forward pass time: 0.04s\n",
      "Epoch 46/50 Completed | RNN Loss: 0.4831, CNN Loss: 2.0306, RNN Accuracy: 0.4116, CNN Accuracy: 0.2766, RNN Perplexity: 1.6212, CNN Perplexity: 7.6184, BLEU (RNN): 0.1087, BLEU (CNN): 0.0145, Time: 260.16s\n",
      "Starting Epoch 47/50...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.73s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 2/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.55s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 3/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.57s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "  Batch 4/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.58s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "  Batch 5/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.55s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 6/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.56s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 7/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.57s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 8/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.61s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 9/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 10/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.66s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.11s\n",
      "  Batch 11/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.70s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 12/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.62s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 13/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.58s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 14/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.57s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 15/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.58s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 16/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.77s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 17/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.57s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 18/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.57s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 19/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.58s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 20/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 21/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.61s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 22/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 23/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 24/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 25/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.61s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 26/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.74s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 27/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.57s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 28/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.56s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 29/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.56s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 30/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.56s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 31/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.56s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 32/32:\n",
      "    input_batch shape: torch.Size([44, 20])\n",
      "    target_batch shape: torch.Size([44, 20])\n",
      "    RNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([44, 19, 4590])\n",
      "    RNN Forward pass time: 0.48s\n",
      "    CNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([44, 20, 4590])\n",
      "    CNN Forward pass time: 0.04s\n",
      "Epoch 47/50 Completed | RNN Loss: 0.4418, CNN Loss: 2.0221, RNN Accuracy: 0.4168, CNN Accuracy: 0.2763, RNN Perplexity: 1.5556, CNN Perplexity: 7.5545, BLEU (RNN): 0.1180, BLEU (CNN): 0.0147, Time: 261.28s\n",
      "Starting Epoch 48/50...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.78s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 2/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.57s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 3/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.56s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 4/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.58s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 5/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 6/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.56s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 7/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.57s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.10s\n",
      "  Batch 8/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.58s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 9/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 10/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.61s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 11/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 12/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 13/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 14/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.58s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 15/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.57s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 16/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.57s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 17/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.57s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 18/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.57s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 19/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 20/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.56s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 21/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.57s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 22/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.57s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 23/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.56s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 24/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.58s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 25/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 26/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 27/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 28/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 29/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.61s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 30/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 31/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.55s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 32/32:\n",
      "    input_batch shape: torch.Size([44, 20])\n",
      "    target_batch shape: torch.Size([44, 20])\n",
      "    RNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([44, 19, 4590])\n",
      "    RNN Forward pass time: 0.50s\n",
      "    CNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([44, 20, 4590])\n",
      "    CNN Forward pass time: 0.05s\n",
      "Epoch 48/50 Completed | RNN Loss: 0.4100, CNN Loss: 2.0334, RNN Accuracy: 0.4202, CNN Accuracy: 0.2769, RNN Perplexity: 1.5068, CNN Perplexity: 7.6398, BLEU (RNN): 0.1205, BLEU (CNN): 0.0147, Time: 262.52s\n",
      "Starting Epoch 49/50...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/local/Cellar/python@3.9/3.9.20/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/umairasif/Documents/Personal/Univeristy/Bock 1/Assignment block 2/NLP Chatbot Project/.venv/lib/python3.9/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 1/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.71s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 2/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.56s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 3/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.58s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 4/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 5/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.56s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.09s\n",
      "  Batch 6/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.58s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 7/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 8/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.61s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 9/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 10/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 11/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.63s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 12/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.58s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 13/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.57s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 14/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.56s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 15/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.55s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 16/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.56s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 17/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.58s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 18/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 19/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.60s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 20/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.65s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 21/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.61s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 22/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.61s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 23/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.57s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 24/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.56s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 25/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.55s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "  Batch 26/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.58s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.06s\n",
      "  Batch 27/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.55s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 28/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.56s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 29/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 30/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.57s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.07s\n",
      "  Batch 31/32:\n",
      "    input_batch shape: torch.Size([64, 20])\n",
      "    target_batch shape: torch.Size([64, 20])\n",
      "    RNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([64, 19, 4590])\n",
      "    RNN Forward pass time: 0.59s\n",
      "    CNN Encoder output shape: torch.Size([64, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([64, 20, 4590])\n",
      "    CNN Forward pass time: 0.08s\n",
      "  Batch 32/32:\n",
      "    input_batch shape: torch.Size([44, 20])\n",
      "    target_batch shape: torch.Size([44, 20])\n",
      "    RNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    RNN Decoder output shape: torch.Size([44, 19, 4590])\n",
      "    RNN Forward pass time: 0.53s\n",
      "    CNN Encoder output shape: torch.Size([44, 20, 512])\n",
      "    CNN Decoder output shape: torch.Size([44, 20, 4590])\n",
      "    CNN Forward pass time: 0.05s\n",
      "Epoch 49/50 Completed | RNN Loss: 0.3696, CNN Loss: 2.0106, RNN Accuracy: 0.4255, CNN Accuracy: 0.2775, RNN Perplexity: 1.4472, CNN Perplexity: 7.4679, BLEU (RNN): 0.1278, BLEU (CNN): 0.0145, Time: 258.60s\n"
     ]
    }
   ],
   "source": [
    "# Define RNN Training Loop with Attention\n",
    "scaler = GradScaler()\n",
    "\n",
    "for epoch in range(RNN_EPOCHS):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Initialize Loss and Accuracy Counters\n",
    "    rnn_epoch_loss, cnn_epoch_loss = 0, 0\n",
    "    rnn_correct, cnn_correct, total = 0, 0, 0\n",
    "    \n",
    "    # Set Models to Training Mode\n",
    "    rnn_encoder.train()\n",
    "    rnn_decoder.train()\n",
    "    cnn_encoder.train()\n",
    "    cnn_decoder.train()\n",
    "    \n",
    "    print(f\"Starting Epoch {epoch}/{RNN_EPOCHS}...\")  # Progress tracking\n",
    "    \n",
    "    \n",
    "    for batch_idx, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        batch_start_time = time.time()\n",
    "        input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "        \n",
    "        print(f\"  Batch {batch_idx + 1}/{len(data_loader)}:\")  # Batch progress\n",
    "        print(f\"    input_batch shape: {input_batch.shape}\")\n",
    "        print(f\"    target_batch shape: {target_batch.shape}\")\n",
    "\n",
    "        # =================== RNN ===================\n",
    "        rnn_forward_start = time.time()\n",
    "\n",
    "        rnn_enc_outputs, (rnn_hidden, rnn_cell) = rnn_encoder(input_batch)\n",
    "        print(f\"    RNN Encoder output shape: {rnn_enc_outputs.shape}\")\n",
    "        rnn_outputs = torch.zeros(\n",
    "            target_batch.size(0), TRUNCATE_LENGTH - 1, OUTPUT_DIM\n",
    "        ).to(device)\n",
    "        decoder_input = target_batch[:, 0].unsqueeze(1)  # Start with <SOS>\n",
    "        \n",
    "\n",
    "        for t in range(1, TRUNCATE_LENGTH):\n",
    "            rnn_output, rnn_hidden, rnn_cell = rnn_decoder(\n",
    "                decoder_input, rnn_hidden, rnn_cell, rnn_enc_outputs\n",
    "            )\n",
    "            rnn_outputs[:, t - 1] = rnn_output\n",
    "            \n",
    "            # Teacher Forcing\n",
    "            use_teacher_forcing = random.random() < 0.5\n",
    "\n",
    "            decoder_input = (\n",
    "                target_batch[:, t].unsqueeze(1)\n",
    "                if use_teacher_forcing \n",
    "                else rnn_output.argmax(1).unsqueeze(1)\n",
    "            )\n",
    "            \n",
    "        print(f\"    RNN Decoder output shape: {rnn_outputs.shape}\")\n",
    "        print(f\"    RNN Forward pass time: {time.time() - rnn_forward_start:.2f}s\")\n",
    "        \n",
    "        # Compute RNN Loss\n",
    "        rnn_loss = criterion(\n",
    "            rnn_outputs.view(-1, OUTPUT_DIM), target_batch[:, 1:].contiguous().view(-1)\n",
    "        )\n",
    "        rnn_epoch_loss += rnn_loss.item()\n",
    "        \n",
    "        # Backpropagation for RNN\n",
    "        rnn_enc_optimizer.zero_grad()\n",
    "        rnn_dec_optimizer.zero_grad()\n",
    "        rnn_loss.backward()\n",
    "        nn.utils.clip_grad_norm_(rnn_encoder.parameters(), max_norm=1)\n",
    "        nn.utils.clip_grad_norm_(rnn_decoder.parameters(), max_norm=1)\n",
    "        rnn_enc_optimizer.step()\n",
    "        rnn_dec_optimizer.step()\n",
    "        \n",
    "        # Compute RNN Accuracy\n",
    "        rnn_predictions = rnn_outputs.argmax(2)\n",
    "        rnn_correct += (rnn_predictions == target_batch[:, 1:]).sum().item()\n",
    "        \n",
    "        \n",
    "        # =================== CNN ===================\n",
    "        cnn_forward_start = time.time()\n",
    "        cnn_enc_outputs = cnn_encoder(input_batch)\n",
    "        print(f\"    CNN Encoder output shape: {cnn_enc_outputs.shape}\")\n",
    "        cnn_outputs = cnn_decoder(decoder_input, cnn_enc_outputs)\n",
    "        print(f\"    CNN Decoder output shape: {cnn_outputs.shape}\")\n",
    "        print(f\"    CNN Forward pass time: {time.time() - cnn_forward_start:.2f}s\")\n",
    "                \n",
    "        # Adjust sequence lengths\n",
    "        seq_len = min(cnn_outputs.size(1), target_batch.size(1) - 1)\n",
    "        \n",
    "        # Truncate cnn_outputs and target_batch to the same sequence length\n",
    "        cnn_outputs = cnn_outputs[:, :seq_len, :]  # Shape: (batch_size, seq_len, vocab_size)\n",
    "        target_batch = target_batch[:, :seq_len + 1]  # Include one extra token for alignment\n",
    "\n",
    "        # Compute CNN Loss\n",
    "        cnn_loss = criterion(\n",
    "            cnn_outputs.contiguous().view(-1, OUTPUT_DIM),  # Flatten to (batch_size * seq_len, vocab_size)\n",
    "            target_batch[:, 1:].contiguous().view(-1)       # Flatten to (batch_size * seq_len)\n",
    "        )\n",
    "\n",
    "        cnn_epoch_loss += cnn_loss.item()\n",
    "        \n",
    "        # Backpropagation for CNN\n",
    "        cnn_enc_optimizer.zero_grad()\n",
    "        cnn_dec_optimizer.zero_grad()\n",
    "        cnn_loss.backward()\n",
    "        nn.utils.clip_grad_norm_(cnn_encoder.parameters(), max_norm=1)\n",
    "        nn.utils.clip_grad_norm_(cnn_decoder.parameters(), max_norm=1)\n",
    "        cnn_enc_optimizer.step()\n",
    "        cnn_dec_optimizer.step()\n",
    "        \n",
    "        # Compute CNN Accuracy\n",
    "        cnn_predictions = cnn_outputs.argmax(2)\n",
    "        cnn_correct += (cnn_predictions == target_batch[:, 1:]).sum().item()\n",
    "\n",
    "        total += target_batch[:, 1:].numel()\n",
    "        \n",
    "    # Calculate Metrics for the Epoch\n",
    "    avg_rnn_loss = rnn_epoch_loss / len(data_loader)\n",
    "    avg_cnn_loss = cnn_epoch_loss / len(data_loader)\n",
    "    rnn_accuracy = rnn_correct / total\n",
    "    cnn_accuracy = cnn_correct / total\n",
    "    rnn_perplexity = math.exp(avg_rnn_loss)\n",
    "    cnn_perplexity = math.exp(avg_cnn_loss)\n",
    "    bleu_rnn = evaluate_bleu((rnn_encoder, rnn_decoder), test_dataset, word2idx, idx2word)\n",
    "    bleu_cnn = evaluate_bleu((cnn_encoder, cnn_decoder), test_dataset, word2idx, idx2word)\n",
    "\n",
    "    # Save Metrics\n",
    "    metrics[\"epoch\"].append(epoch)\n",
    "    metrics[\"rnn_loss\"].append(avg_rnn_loss)\n",
    "    metrics[\"cnn_loss\"].append(avg_cnn_loss)\n",
    "    metrics[\"rnn_token_accuracy\"].append(rnn_accuracy)\n",
    "    metrics[\"cnn_token_accuracy\"].append(cnn_accuracy)\n",
    "    metrics[\"rnn_perplexity\"].append(rnn_perplexity)\n",
    "    metrics[\"cnn_perplexity\"].append(cnn_perplexity)\n",
    "    metrics[\"bleu_score_rnn\"].append(bleu_rnn)\n",
    "    metrics[\"bleu_score_cnn\"].append(bleu_cnn)\n",
    "\n",
    "    save_metrics(metrics)\n",
    "    \n",
    "    # Logging\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\n",
    "        f\"Epoch {epoch}/{RNN_EPOCHS} Completed | RNN Loss: {avg_rnn_loss:.4f}, CNN Loss: {avg_cnn_loss:.4f}, \"\n",
    "        f\"RNN Accuracy: {rnn_accuracy:.4f}, CNN Accuracy: {cnn_accuracy:.4f}, \"\n",
    "        f\"RNN Perplexity: {rnn_perplexity:.4f}, CNN Perplexity: {cnn_perplexity:.4f}, \"\n",
    "        f\"BLEU (RNN): {bleu_rnn:.4f}, BLEU (CNN): {bleu_cnn:.4f}, Time: {elapsed_time:.2f}s\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Results\n",
    "plot_metric(metrics, \"rnn_loss\", \"RNN Loss per Epoch\", \"Loss\")\n",
    "plot_metric(metrics, \"cnn_loss\", \"CNN Loss per Epoch\", \"Loss\")\n",
    "plot_metric(metrics, \"rnn_token_accuracy\", \"RNN Accuracy per Epoch\", \"Accuracy\")\n",
    "plot_metric(metrics, \"cnn_token_accuracy\", \"CNN Accuracy per Epoch\", \"Accuracy\")\n",
    "plot_metric(metrics, \"rnn_perplexity\", \"RNN Perplexity per Epoch\", \"Perplexity\")\n",
    "plot_metric(metrics, \"cnn_perplexity\", \"CNN Perplexity per Epoch\", \"Perplexity\")\n",
    "plot_metric(metrics, \"bleu_score_rnn\", \"RNN BLEU Score per Epoch\", \"BLEU Score\")\n",
    "plot_metric(metrics, \"bleu_score_cnn\", \"CNN BLEU Score per Epoch\", \"BLEU Score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_with_both(input_text, rnn_encoder, rnn_decoder, cnn_encoder, cnn_decoder, word2idx, idx2word, intents, max_len=10):\n",
    "    # Step 1: Fallback to intent-based patterns in intents.json\n",
    "    for intent in intents[\"intents\"]:\n",
    "        for pattern in intent[\"patterns\"]:\n",
    "            if pattern.lower() in input_text.lower():\n",
    "                return {\n",
    "                    \"RNN Response\": np.random.choice(intent[\"responses\"]),\n",
    "                    \"CNN Response\": np.random.choice(intent[\"responses\"]),\n",
    "                }\n",
    "\n",
    "    # Step 2: Convert input text to indices\n",
    "    input_indices = [word2idx.get(word, word2idx[\"<UNK>\"]) for word in input_text.split()]\n",
    "    input_tensor = torch.tensor([input_indices]).to(device)\n",
    "\n",
    "    # Step 3: Inference with RNN\n",
    "    rnn_encoder.eval()\n",
    "    rnn_decoder.eval()\n",
    "    with torch.no_grad():\n",
    "        rnn_enc_outputs, (hidden, cell) = rnn_encoder(input_tensor)\n",
    "        rnn_response = generate_response(rnn_decoder, hidden, cell, rnn_enc_outputs, idx2word, max_len)\n",
    "\n",
    "    # Step 4: Inference with CNN\n",
    "    cnn_encoder.eval()\n",
    "    cnn_decoder.eval()\n",
    "    with torch.no_grad():\n",
    "        cnn_enc_outputs = cnn_encoder(input_tensor)\n",
    "        cnn_response = generate_response(cnn_decoder, None, None, cnn_enc_outputs, idx2word, max_len, is_rnn=False)\n",
    "\n",
    "    # Final Step: Return responses\n",
    "    return {\n",
    "        \"RNN Response\": rnn_response,\n",
    "        \"CNN Response\": cnn_response,\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_response(decoder, hidden, cell, encoder_outputs, idx2word, max_len=10, is_rnn=True):\n",
    "    decoder_input = torch.tensor([[word2idx['<SOS>']]]).to(device)  # Start with <SOS>\n",
    "    output_sentence = []\n",
    "\n",
    "    for step in range(max_len):\n",
    "        if is_rnn:\n",
    "            # RNN Decoder\n",
    "            outputs, hidden, cell = decoder(decoder_input, hidden, cell, encoder_outputs)\n",
    "        else:\n",
    "            # CNN Decoder\n",
    "            outputs = decoder(decoder_input, encoder_outputs)\n",
    "\n",
    "        # Apply argmax to get the predicted word index\n",
    "        prediction = outputs.argmax(dim=-1)  # Ensure argmax is applied on the vocab dimension\n",
    "\n",
    "        # Extract next word index based on shape\n",
    "        if prediction.dim() == 2:  # Shape: (batch_size, seq_len)\n",
    "            next_word_idx = prediction[0, -1].item()\n",
    "        elif prediction.dim() == 1:  # Shape: (batch_size)\n",
    "            next_word_idx = prediction[0].item()\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected prediction shape: {prediction.shape}\")\n",
    "\n",
    "        # Convert index to word\n",
    "        next_word = idx2word[next_word_idx]\n",
    "\n",
    "        # Break on <EOS>\n",
    "        if next_word == '<EOS>':\n",
    "            break\n",
    "\n",
    "        # Append to output sentence and update decoder input\n",
    "        output_sentence.append(next_word)\n",
    "        decoder_input = prediction.unsqueeze(1)  # Ensure decoder input has shape (batch_size, 1)\n",
    "\n",
    "    return ' '.join(output_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: How are you?\n",
      "RNN Response: Good to see you again!\n",
      "CNN Response: Hi there, how can I help?\n"
     ]
    }
   ],
   "source": [
    "# Example User Input\n",
    "user_input = \"How are you?\"\n",
    "\n",
    "# Generate Responses\n",
    "responses = infer_with_both(user_input, rnn_encoder, rnn_decoder, cnn_encoder, cnn_decoder, word2idx, idx2word, intents)\n",
    "print(f\"User: {user_input}\")\n",
    "\n",
    "# Print Responses\n",
    "print(f\"RNN Response: {responses['RNN Response']}\")\n",
    "print(f\"CNN Response: {responses['CNN Response']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
